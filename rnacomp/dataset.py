# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_dataset.ipynb.

# %% auto 0
__all__ = ['good_luck', 'LenMatchBatchSampler', 'dict_to', 'to_device', 'DeviceDataLoader', 'encode_rna_sequence',
           'generate_edge_data', 'RNA_DatasetBaseline', 'RNA_DatasetBaselineSplit', 'RNA_DatasetV0', 'RNA_DatasetV1',
           'RNA_DatasetV0G', 'generate_base_pair_matrix', 'RNA_DatasetBaselineSplitbppV0',
           'generate_base_pair_matrixv1', 'RNA_DatasetBaselineSplitbppV1', 'dot_to_adjacency',
           'RNA_DatasetBaselineSplitssV0', 'RNA_DatasetBaselineSplitssV1', 'RNA_DatasetBaselineSplitbppV2',
           'dot_to_adjacencyv0', 'RNA_DatasetBaselineSplitssbppV0Conv', 'RNA_DatasetBaselineSplitssbppV0',
           'RNA_DatasetBaselineSplitssbppV1', 'load_rnafm', 'extra_bpp_from_numpy', 'RNA_DatasetBaselineSplitssbppV1R',
           'RNA_DatasetBaselineSplitssbppV2', 'RNA_DatasetBaselineSplitssbppV3', 'RNA_DatasetBaselineSplitssbppV4',
           'RNA_DatasetBaselineSplitssbppV5', 'RNA_DatasetBaselineSplitssbppV5BTTA', 'RNA_DatasetBaselineSplitssbppV6',
           'RNA_DatasetBaselineFM', 'RNA_DatasetBaselineSplitssbppV7Flip', 'RNA_DatasetBaselineSplitssbppV6SAVED',
           'RNA_DatasetBaselineSplitssbppV6SAVEDwithFM', 'RNA_DatasetBaselineSplitssbppV6SAVEDwithFMFlip',
           'RNA_DatasetBaselineSplitssbppV6SAVEDwithoutFM', 'RNA_DatasetBaselineSplitssbppV7SAVED',
           'RNA_DatasetBaselineSplitssbppV6SAVEDFM', 'RNA_DatasetBaselineSplitssbppV8SAVED', 'RNA_DatasetEXV0',
           'RNA_DatasetEXV0Flip', 'RNA_DatasetBaselineSplitssbppV6SAVEDwithFMPSD',
           'RNA_DatasetBaselineSplitssbppV6SAVEDwithFMPSDExternal', 'RNA_Dataset_Test', 'RNA_Dataset_TestBpp',
           'RNA_Dataset_Testss', 'RNA_Dataset_TestBppSS', 'RNA_Dataset_TestBppSSFullV0', 'RNA_Dataset_TestBppSSFullV1',
           'RNA_Dataset_TestBppSSFullV2', 'RNA_Dataset_TestBppSSFullV3', 'RNA_Dataset_TestBppSSFullV4',
           'RNA_Dataset_TestBppSSFullV5', 'RNA_Dataset_TestSavedV0']

# %% ../nbs/00_dataset.ipynb 1
import pandas as pd
import numpy as np
from pathlib import Path
from torch.utils.data import Dataset, DataLoader
from torch_geometric.data import Data, DataLoader, Batch
import torch
import seaborn as sbn
import torch.nn.functional as F
from tqdm import tqdm
from sklearn.model_selection import KFold
import random
from copy import deepcopy   
import pickle


import matplotlib.pyplot as plt
import gc

# %% ../nbs/00_dataset.ipynb 2
def good_luck():
    return True

# %% ../nbs/00_dataset.ipynb 3
class LenMatchBatchSampler(torch.utils.data.BatchSampler):
    def __iter__(self):
        buckets = [[]] * 100
        yielded = 0

        for idx in self.sampler:
            s = self.sampler.data_source[idx]
            if isinstance(s,tuple): L = s[0]["mask"].sum()
            else: L = s["mask"].sum()
            L = max(1,L // 16) 
            if len(buckets[L]) == 0:  buckets[L] = []
            buckets[L].append(idx)
            
            if len(buckets[L]) == self.batch_size:
                batch = list(buckets[L])
                yield batch
                yielded += 1
                buckets[L] = []
                
        batch = []
        leftover = [idx for bucket in buckets for idx in bucket]

        for idx in leftover:
            batch.append(idx)
            if len(batch) == self.batch_size:
                yielded += 1
                yield batch
                batch = []

        if len(batch) > 0 and not self.drop_last:
            yielded += 1
            yield batch
            
def dict_to(x, device='cuda'):
    return {k:x[k].to(device) for k in x}

def to_device(x, device='cuda'):
    return tuple(dict_to(e,device) for e in x)

class DeviceDataLoader:
    def __init__(self, dataloader, device='cuda'):
        self.dataloader = dataloader
        self.device = device
    
    def __len__(self):
        return len(self.dataloader)
    
    def __iter__(self):
        for batch in self.dataloader:
            yield tuple(dict_to(x, self.device) for x in batch)

# %% ../nbs/00_dataset.ipynb 4
def encode_rna_sequence(seq):
    L = len(seq)

    # Initialize the tensor with zeros
    tensor = np.zeros((L, L, 8))

    # Define valid base pairs
    valid_pairs = [
        ("A", "U"),
        ("U", "A"),
        ("U", "G"),
        ("G", "U"),
        ("G", "C"),
        ("C", "G"),
    ]

    for i in range(L):
        for j in range(L):
            # Check for valid base pairs
            if (seq[i], seq[j]) in valid_pairs:
                channel = valid_pairs.index((seq[i], seq[j]))
                tensor[i, j, channel] = 1
            # Check for diagonal
            elif i == j:
                tensor[i, j, 6] = 1
            # If not a valid pair and not on the diagonal, set the last channel
            else:
                tensor[i, j, 7] = 1

    return tensor


def generate_edge_data(file_path):
    # Read the file into a DataFrame
    data = pd.read_csv(file_path, sep=" ", header=None, names=["pos1", "pos2", "prob"])

    # Convert the pos1 and pos2 columns to 0-based indices and then to a tensor for edge index
    edge_index = torch.tensor(
        [data["pos1"].values - 1, data["pos2"].values - 1], dtype=torch.long
    )

    # Convert the prob column to a tensor for edge features
    edge_features = torch.tensor(data["prob"].values, dtype=torch.float).unsqueeze(
        1
    )  # Adding an extra dimension

    return edge_index, edge_features


class RNA_DatasetBaseline(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        **kwargs,
    ):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"]
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"]

        split = list(
            KFold(n_splits=nfolds, random_state=seed, shuffle=True).split(df_2A3)
        )[fold][0 if mode == "train" else 1]
        df_2A3 = df_2A3.iloc[split].reset_index(drop=True)
        df_DMS = df_DMS.iloc[split].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.seq = df_2A3["sequence"].values
        self.L = df_2A3["L"].values

        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return {"seq": torch.from_numpy(seq), "mask": mask}, {
            "react": react,
            "react_err": react_err,
            "sn": sn,
            "mask": mask,
        }


class RNA_DatasetBaselineSplit(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        **kwargs,
    ):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.seq = df_2A3["sequence"].values
        self.L = df_2A3["L"].values

        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return {"seq": torch.from_numpy(seq), "mask": mask}, {
            "react": react,
            "react_err": react_err,
            "sn": sn,
            "mask": mask,
        }


class RNA_DatasetBaseline(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        **kwargs,
    ):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"]
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"]

        split = list(
            KFold(n_splits=nfolds, random_state=seed, shuffle=True).split(df_2A3)
        )[fold][0 if mode == "train" else 1]
        df_2A3 = df_2A3.iloc[split].reset_index(drop=True)
        df_DMS = df_DMS.iloc[split].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.seq = df_2A3["sequence"].values
        self.L = df_2A3["L"].values

        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return {"seq": torch.from_numpy(seq), "mask": mask}, {
            "react": react,
            "react_err": react_err,
            "sn": sn,
            "mask": mask,
        }


class RNA_DatasetV0(Dataset):
    def __init__(self, df, mask_only=False, prob_for_adj=0.5, **kwargs):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        self.prob_for_adj = prob_for_adj
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        self.seq = df_2A3["sequence"].values
        self.L = df_2A3["L"].values

        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.bpp = df_2A3["bpp"].values
        self.mask_only = mask_only

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        adj_matrix = generate_adj_matrix(self.bpp[idx], self.Lmax, self.prob_for_adj)
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        return {"seq": torch.from_numpy(seq), "mask": mask, "adj_matrix": adj_matrix}, {
            "react": react,
            "react_err": react_err,
            "mask": mask,
        }


class RNA_DatasetV1(Dataset):
    # same as v0 but not adj matrix
    def __init__(self, df, mask_only=False, **kwargs):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        self.seq = df_2A3["sequence"].values
        self.L = df_2A3["L"].values

        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.bpp = df_2A3["bpp"].values
        self.mask_only = mask_only

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        return {"seq": torch.from_numpy(seq), "mask": mask}, {
            "react": react,
            "react_err": react_err,
            "mask": mask,
        }


class RNA_DatasetV0G(Dataset):
    def __init__(self, df, path_to_bpp_folder, mask_only=False, **kwargs):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        self.seq = df_2A3["sequence"].values
        self.L = df_2A3["L"].values

        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.bpp = df_2A3["bpp"].values
        self.mask_only = mask_only

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        edge_index, edge_features = generate_edge_data(self.bpp[idx])
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        return Data(
            x=torch.from_numpy(seq),
            edge_index=edge_index,
            edge_features=edge_features,
            y=react,
            y_err=react_err,
        )


class LenMatchBatchSampler(torch.utils.data.BatchSampler):
    def __iter__(self):
        buckets = [[]] * 100
        yielded = 0

        for idx in self.sampler:
            s = self.sampler.data_source[idx]
            if isinstance(s, tuple):
                L = s[0]["mask"].sum()
            else:
                L = s["mask"].sum()
            L = max(1, L // 16)
            if len(buckets[L]) == 0:
                buckets[L] = []
            buckets[L].append(idx)

            if len(buckets[L]) == self.batch_size:
                batch = list(buckets[L])
                yield batch
                yielded += 1
                buckets[L] = []

        batch = []
        leftover = [idx for bucket in buckets for idx in bucket]

        for idx in leftover:
            batch.append(idx)
            if len(batch) == self.batch_size:
                yielded += 1
                yield batch
                batch = []

        if len(batch) > 0 and not self.drop_last:
            yielded += 1
            yield batch


def generate_base_pair_matrix(file_path, L):
    """
    Reads a TXT file of base pair probabilities and generates an n x n matrix.

    Args:
    - file_path (str): Path to the TXT file.

    Returns:
    - np.array: An n x n matrix of base pair probabilities.
    """
    # Read the data using pandas
    data = pd.read_csv(file_path, sep=" ", header=None, names=["pos1", "pos2", "prob"])

    # Find the largest position in the 'pos1' column
    largest_position = data["pos1"].max()

    ids = torch.from_numpy(data[["pos1", "pos2"]].values)
    matrix = torch.zeros((L, L))
    matrix[ids[:, 0] - 1, ids[:, 1] - 1] = torch.from_numpy(data["prob"].values).float()
    matrix[ids[:, 1] - 1, ids[:, 0] - 1] = torch.from_numpy(data["prob"].values).float()

    matrix[:26, :] = 0
    matrix[:, :26] = 0

    # Adjust the end based on the largest_position and set the last 21 positions to 0
    adjusted_end = largest_position - 21
    matrix[adjusted_end:, :] = 0
    matrix[:, adjusted_end:] = 0

    return matrix


class RNA_DatasetBaselineSplitbppV0(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        **kwargs,
    ):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.seq = df_2A3["sequence"].values
        self.bpp = df_2A3["bpp"].values
        self.L = df_2A3["L"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))
        bpp = (generate_base_pair_matrix(self.bpp[idx], self.Lmax) > 0.5).int()

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return {"seq": torch.from_numpy(seq), "mask": mask, "adj_matrix": bpp}, {
            "react": react,
            "react_err": react_err,
            "sn": sn,
            "mask": mask,
        }


def generate_base_pair_matrixv1(file_path, L):
    """
    Reads a TXT file of base pair probabilities and generates an n x n matrix.

    Args:
    - file_path (str): Path to the TXT file.

    Returns:
    - np.array: An n x n matrix of base pair probabilities.
    """
    # Read the data using pandas
    data = pd.read_csv(file_path, sep=" ", header=None, names=["pos1", "pos2", "prob"])

    # Find the largest position in the 'pos1' column
    largest_position = data["pos1"].max()

    ids = torch.from_numpy(data[["pos1", "pos2"]].values.astype(int))
    matrix = torch.zeros((L, L))
    matrix[ids[:, 0] - 1, ids[:, 1] - 1] = torch.from_numpy(data["prob"].values).float()
    matrix[ids[:, 1] - 1, ids[:, 0] - 1] = torch.from_numpy(data["prob"].values).float()

    return matrix


class RNA_DatasetBaselineSplitbppV1(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        **kwargs,
    ):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.seq = df_2A3["sequence"].values
        self.bpp = df_2A3["bpp"].values
        self.L = df_2A3["L"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))
        bpp = (generate_base_pair_matrixv1(self.bpp[idx], self.Lmax) > 0.5).int()

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return {"seq": torch.from_numpy(seq), "mask": mask, "adj_matrix": bpp}, {
            "react": react,
            "react_err": react_err,
            "sn": sn,
            "mask": mask,
        }


def dot_to_adjacency(dot_notation, n):
    adjacency_matrix = np.zeros((n, n), dtype=int)
    dot_notation = (26 * ".") + dot_notation + (21 * ".")
    stack = []
    for i, char in enumerate(dot_notation):
        if char == "(":
            stack.append(i)
        elif char == ")":
            j = stack.pop()
            adjacency_matrix[i][j] = adjacency_matrix[j][i] = 1

    return adjacency_matrix


class RNA_DatasetBaselineSplitssV0(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.seq = df_2A3["sequence"].values
        self.ss = df_2A3["ss_roi"].values
        self.L = df_2A3["L"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))
        bpp = torch.tensor(dot_to_adjacency(self.ss[idx], self.Lmax)).int()

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return {"seq": torch.from_numpy(seq), "mask": mask, "adj_matrix": bpp}, {
            "react": react,
            "react_err": react_err,
            "sn": sn,
            "mask": mask,
        }


class RNA_DatasetBaselineSplitssV0(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.seq = df_2A3["sequence"].values
        self.ss = df_2A3["ss_roi"].values
        self.L = df_2A3["L"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))
        bpp = torch.tensor(dot_to_adjacency(self.ss[idx], self.Lmax)).int()

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return {"seq": torch.from_numpy(seq), "mask": mask, "adj_matrix": bpp}, {
            "react": react,
            "react_err": react_err,
            "sn": sn,
            "mask": mask,
        }


class RNA_DatasetBaselineSplitssV1(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.ss_map = {".": 0, "(": 1, ")": 2}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.seq = df_2A3["sequence"].values
        self.ss = df_2A3["ss_full"].values
        self.L = df_2A3["L"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)

        ss_seq = [self.ss_map[s] for s in self.ss[idx]]
        ss_seq = np.array(ss_seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))
        ss_seq = np.pad(ss_seq, (0, self.Lmax - len(ss_seq)))

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return {
            "seq": torch.from_numpy(seq),
            "mask": mask,
            "ss_seq": torch.from_numpy(ss_seq),
        }, {"react": react, "react_err": react_err, "sn": sn, "mask": mask}


class RNA_DatasetBaselineSplitbppV2(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}

        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.seq = df_2A3["sequence"].values
        self.bpp = df_2A3["bpp"].values
        self.L = df_2A3["L"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)

        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))
        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax)

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return {"seq": torch.from_numpy(seq), "mask": mask, "bpp": bpp}, {
            "react": react,
            "react_err": react_err,
            "sn": sn,
            "mask": mask,
        }


def dot_to_adjacencyv0(dot_notation, n):
    adjacency_matrix = np.zeros((n, n), dtype=int)
    stack = []
    for i, char in enumerate(dot_notation):
        if char == "(":
            stack.append(i)
        elif char == ")":
            j = stack.pop()
            adjacency_matrix[i][j] = adjacency_matrix[j][i] = 1

    return adjacency_matrix


class RNA_DatasetBaselineSplitssbppV0Conv(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.bpp = df_2A3["bpp"].values
        self.seq = df_2A3["sequence"].values
        self.ss = df_2A3["ss_full"].values
        self.L = df_2A3["L"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq_holder = np.zeros(self.Lmax, dtype=int)
        seq_holder[: len(seq)] = seq

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return deepcopy(
            {
                "seq": torch.from_numpy(seq_holder),
                "mask": mask,
            }
        ), {"react": react, "react_err": react_err, "sn": sn, "mask": mask}


class RNA_DatasetBaselineSplitssbppV0(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.bpp = df_2A3["bpp"].values
        self.seq = df_2A3["sequence"].values
        self.ss = df_2A3["ss_full"].values
        self.L = df_2A3["L"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))
        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()
        bpp = (generate_base_pair_matrixv1(self.bpp[idx], self.Lmax) > 0.5).int()

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return {
            "seq": torch.from_numpy(seq),
            "mask": mask,
            "ss_adj": ss_adj,
            "adj_matrix": bpp,
        }, {"react": react, "react_err": react_err, "sn": sn, "mask": mask}


class RNA_DatasetBaselineSplitssbppV1(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.bpp = df_2A3["bpp"].values
        self.seq = df_2A3["sequence"].values
        self.ss = df_2A3["ss_full"].values
        self.L = df_2A3["L"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))
        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()
        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax)

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return {
            "seq": torch.from_numpy(seq),
            "mask": mask,
            "ss_adj": ss_adj,
            "bb_matrix_full_prob": bpp,
        }, {"react": react, "react_err": react_err, "sn": sn, "mask": mask}


def load_rnafm(filename, seq_len, L_max):
    """
    Load data from a .npy file and convert it to an N x N matrix.

    Parameters:
    - filename: Path to the .npy file.
    - N: Dimension of the square matrix.

    Returns:
    - bpp_matrix: N x N matrix reconstructed from the input file.
    """
    # Load the structured array from the .npy file
    data = np.load(filename)

    # Create an empty N x N matrix
    bpp_matrix = np.zeros((seq_len, seq_len))

    # Fill the matrix with the probabilities from the loaded data
    bpp_matrix[data["pos_1"], data["pos_2"]] = data["probabilities"]

    bpp_matrix = bpp_matrix + bpp_matrix.T - np.diag(np.diag(bpp_matrix))
    full = np.zeros((L_max, L_max))
    full[:seq_len, :seq_len] = bpp_matrix
    return torch.tensor(full)


def extra_bpp_from_numpy(filename, N, seq_len=None):
    """
    Load data from a .npy file and convert it to an N x N matrix.

    Parameters:
    - filename: Path to the .npy file.
    - N: Dimension of the square matrix.

    Returns:
    - bpp_matrix: N x N matrix reconstructed from the input file.
    """
    # Load the structured array from the .npy file
    if filename.parent.stem in ["rnafm", "rnaformerv1"]:
        full = load_rnafm(filename, seq_len, N)
    else:
        data = np.load(filename)
        # Create an empty N x N matrix
        bpp_matrix = np.zeros((N, N))
        # Fill the matrix with the probabilities from the loaded data
        bpp_matrix[data["pos_1"], data["pos_2"]] = data["probabilities"]
        full = torch.tensor(bpp_matrix)

    return full


class RNA_DatasetBaselineSplitssbppV1R(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        extra_bpp_path=Path("../eda/bpp"),
        extra_bpp=["rnafm"],
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.bpp = df_2A3["bpp"].values
        self.seq = df_2A3["sequence"].values
        self.ss = df_2A3["ss_full"].values
        self.L = df_2A3["L"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only

        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))
        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()
        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax)
        bpp_extra = [
            extra_bpp_from_numpy(
                self.extra_bpp_path / f"{i}/{self.bpp[idx].stem}.npy",
                self.Lmax,
                seq_len=len(self.seq[idx]),
            )
            for i in self.extra_bpp
        ]
        bpp = torch.stack([*bpp_extra, bpp], dim=0).mean(0).float()
        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return {
            "seq": torch.from_numpy(seq),
            "mask": mask,
            "ss_adj": ss_adj,
            "bb_matrix_full_prob": bpp,
        }, {"react": react, "react_err": react_err, "sn": sn, "mask": mask}


class RNA_DatasetBaselineSplitssbppV2(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        extra_bpp_path=Path("../eda/bpp"),
        extra_bpp=["vienna_2", "contrafold_2"],
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.bpp = df_2A3["bpp"].values
        self.seq = df_2A3["sequence"].values
        self.ss = df_2A3["ss_full"].values
        self.L = df_2A3["L"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))
        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()
        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax)
        bpp_extra = [
            extra_bpp_from_numpy(
                self.extra_bpp_path / f"{i}/{self.bpp[idx].stem}.npy", self.Lmax
            )
            for i in self.extra_bpp
        ]
        bpp = torch.stack([bpp, *bpp_extra], dim=0).mean(0).float()

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return {
            "seq": torch.from_numpy(seq),
            "mask": mask,
            "ss_adj": ss_adj,
            "bb_matrix_full_prob": bpp,
        }, {"react": react, "react_err": react_err, "sn": sn, "mask": mask}


class RNA_DatasetBaselineSplitssbppV3(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        extra_bpp_path=Path("../eda/bpp"),
        extra_bpp=["vienna_2", "contrafold_2", "rnaformer"],
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.bpp = df_2A3["bpp"].values
        self.seq = df_2A3["sequence"].values
        self.ss = df_2A3["ss_full"].values
        self.L = df_2A3["L"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))
        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()
        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax).float()
        bpp_extra = [
            extra_bpp_from_numpy(
                self.extra_bpp_path / f"{i}/{self.bpp[idx].stem}.npy",
                self.Lmax,
                seq_len=len(self.seq[idx]),
            )
            for i in self.extra_bpp
        ]
        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return {
            "seq": torch.from_numpy(seq),
            "mask": mask,
            "ss_adj": ss_adj,
            "bb_matrix_full_prob": bpp,
            "bb_matrix_full_prob_extra": bpp_extra,
        }, {"react": react, "react_err": react_err, "sn": sn, "mask": mask}


class RNA_DatasetBaselineSplitssbppV4(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        extra_bpp_path=Path("../eda/bpp"),
        extra_bpp=["rnafm"],
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.bpp = df_2A3["bpp"].values
        self.seq = df_2A3["sequence"].values
        self.ss = df_2A3["ss_full"].values
        self.L = df_2A3["L"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))
        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()
        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax).float()
        bpp_extra = [
            extra_bpp_from_numpy(
                self.extra_bpp_path / f"{i}/{self.bpp[idx].stem}.npy",
                self.Lmax,
                seq_len=len(self.seq[idx]),
            )
            for i in self.extra_bpp
        ]
        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return {
            "seq": torch.from_numpy(seq),
            "mask": mask,
            "ss_adj": ss_adj,
            "bb_matrix_full_prob": bpp,
            "bb_matrix_full_prob_extra": bpp_extra,
        }, {"react": react, "react_err": react_err, "sn": sn, "mask": mask}


class RNA_DatasetBaselineSplitssbppV5(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        extra_bpp_path=Path("../eda/bpp"),
        extra_bpp=["rnafm", "vienna_2", "contrafold_2", "rnaformer"],
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.bpp = df_2A3["bpp"].values
        self.seq = df_2A3["sequence"].values
        self.ss = df_2A3["ss_full"].values
        self.L = df_2A3["L"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))
        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()
        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax).float()
        bpp_extra = [
            extra_bpp_from_numpy(
                self.extra_bpp_path / f"{i}/{self.bpp[idx].stem}.npy",
                self.Lmax,
                seq_len=len(self.seq[idx]),
            )
            for i in self.extra_bpp
        ]
        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return deepcopy(
            {
                "seq": torch.from_numpy(seq),
                "mask": mask,
                "ss_adj": ss_adj,
                "bb_matrix_full_prob": bpp,
                "bb_matrix_full_prob_extra": bpp_extra,
            }
        ), {"react": react, "react_err": react_err, "sn": sn, "mask": mask}


class RNA_DatasetBaselineSplitssbppV5BTTA(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        extra_bpp_path=Path("../eda/bpp"),
        extra_bpp=["rnafm", "vienna_2", "contrafold_2", "rnaformer"],
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.bpp = df_2A3["bpp"].values
        self.seq = df_2A3["sequence"].values
        self.ss = df_2A3["ss_full"].values
        self.L = df_2A3["L"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = np.pad(seq, (0, self.Lmax - len(seq)))
        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()
        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax).float()
        bpp_extra = [
            extra_bpp_from_numpy(
                self.extra_bpp_path / f"{i}/{self.bpp[idx].stem}.npy",
                self.Lmax,
                seq_len=len(self.seq[idx]),
            )
            for i in self.extra_bpp
        ]
        bpp_extra = torch.stack([*bpp_extra], dim=0).float()

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return deepcopy(
            {
                "seq": torch.from_numpy(seq),
                "mask": mask,
                "ss_adj": ss_adj,
                "bb_matrix_full_prob": bpp,
                "bb_matrix_full_prob_extra": bpp_extra,
            }
        ), {"react": react, "react_err": react_err, "sn": sn, "mask": mask}


class RNA_DatasetBaselineSplitssbppV6(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        extra_bpp_path=Path("../eda/bpp"),
        extra_bpp=["vienna_2", "contrafold_2", "rnaformer"],
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.bpp = df_2A3["bpp"].values
        self.seq = df_2A3["sequence"].values
        self.ss = df_2A3["ss_full"].values
        self.L = df_2A3["L"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq_holder = np.zeros(self.Lmax, dtype=int)
        seq_holder[: len(seq)] = seq

        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()
        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax).float()
        bpp_extra = [
            extra_bpp_from_numpy(
                self.extra_bpp_path / f"{i}/{self.bpp[idx].stem}.npy",
                self.Lmax,
                seq_len=len(self.seq[idx]),
            )
            for i in self.extra_bpp
        ]
        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return deepcopy(
            {
                "seq": torch.from_numpy(seq_holder),
                "mask": mask,
                "ss_adj": ss_adj,
                "bb_matrix_full_prob": bpp,
                "bb_matrix_full_prob_extra": bpp_extra,
            }
        ), deepcopy({"react": react, "react_err": react_err, "sn": sn, "mask": mask})


class RNA_DatasetBaselineFM(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        extra_bpp_path=Path("../eda/bpp"),
        extra_bpp=["vienna_2", "contrafold_2"],
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"S": 0, "E": 2, "A": 4, "U": 7, "C": 5, "G": 6}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.bpp = df_2A3["bpp"].values
        self.seq = df_2A3["sequence"].values
        self.ss = df_2A3["ss_full"].values
        self.L = df_2A3["L"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}

        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[: len(seq)] = True
        seq = [self.seq_map[s] for s in "S" + seq + "E"]
        seq = np.array(seq)
        seq_holder = np.ones(self.Lmax + 2, dtype=int)
        seq_holder[: len(seq)] = seq

        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()
        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax).float()

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        return {
            "seq": torch.from_numpy(seq_holder).long(),
            "mask": mask,
            "ss_adj": ss_adj,
            "bb_matrix_full_prob": bpp,
        }, {"react": react, "react_err": react_err, "sn": sn, "mask": mask}


class RNA_DatasetBaselineSplitssbppV7Flip(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        extra_bpp_path=Path("../eda/bpp"),
        extra_bpp=["vienna_2", "contrafold_2", "rnaformerv1"],
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.bpp = df_2A3["bpp"].values
        self.seq = df_2A3["sequence"].values
        self.ss = df_2A3["ss_full"].values
        self.L = df_2A3["L"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path
        self.mode = mode

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        L = len(seq)
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[: len(seq)] = True
            return {"mask": mask}, {"mask": mask}

        seq0 = np.array([*seq])
        seq = np.zeros(L, dtype=np.int64)
        for k in self.seq_map:
            seq[seq0 == k] = self.seq_map[k]
        seq = torch.from_numpy(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[:L] = True

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        if react.shape[0] != self.Lmax:
            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)
            react_err = F.pad(
                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan
            )

        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], L)).int()
        bpp = generate_base_pair_matrixv1(self.bpp[idx], L).float()

        bpp_extra = [
            extra_bpp_from_numpy(
                self.extra_bpp_path / f"{i}/{self.bpp[idx].stem}.npy", L, seq_len=L
            )
            for i in self.extra_bpp
        ]
        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()

        if self.mode == "train" and random.random() > 0.5:
            seq = seq.flip(-1)
            bpp = bpp.flip(-1, -2)
            bpp_extra = bpp_extra.flip(-1, -2)
            ss_adj = ss_adj.flip(-1, -2)

            react = F.pad(react[:L].flip(0), (0, 0, 0, self.Lmax - L), value=torch.nan)
            react_err = F.pad(
                react_err[:L].flip(0), (0, 0, 0, self.Lmax - L), value=torch.nan
            )

        seq = F.pad(seq, (0, self.Lmax - L))
        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))
        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))
        ss_adj = F.pad(ss_adj, (0, self.Lmax - L, 0, self.Lmax - L))

        return deepcopy(
            {
                "seq": seq,
                "mask": mask,
                "ss_adj": ss_adj,
                "bb_matrix_full_prob": bpp,
                "bb_matrix_full_prob_extra": bpp_extra,
            }
        ), deepcopy({"react": react, "react_err": react_err, "sn": sn, "mask": mask})


class RNA_DatasetBaselineSplitssbppV6SAVED(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        extra_bpp_path=Path("../eda/bpp/comb"),
        extra_bpp=[
            "vienna_2",
            "contrafold_2",
            "rnaformer",
        ],
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.L = df_2A3["L"].values
        self.seq = df_2A3["sequence"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path
        self.sequence_id = df_2A3["sequence_id"].values

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        L = len(seq)
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[:L] = True
            return {"mask": mask}, {"mask": mask}
        # seq = [self.seq_map[s] for s in seq]
        seq0 = np.array([*seq])
        seq = np.zeros(L, dtype=np.int64)
        for k in self.seq_map:
            seq[seq0 == k] = self.seq_map[k]
        seq = torch.from_numpy(seq)

        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[:L] = True

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        if react.shape[0] != self.Lmax:
            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)
            react_err = F.pad(
                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan
            )

        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        data = np.load(self.extra_bpp_path / f"{self.sequence_id[idx]}.npz")

        ss = torch.from_numpy(data["ss_vienna"].astype(np.float32))
        bpp = torch.from_numpy(data["bpp_org"].astype(np.float32))
        bpp_extra = torch.stack(
            [torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp],
            dim=0,
        ).mean(0)

        seq = F.pad(seq, (0, self.Lmax - L))
        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))
        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))
        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))

        return deepcopy(
            {
                "seq": seq,
                "mask": mask,
                "ss_adj": ss,
                "bb_matrix_full_prob": bpp,
                "bb_matrix_full_prob_extra": bpp_extra,
            }
        ), deepcopy({"react": react, "react_err": react_err, "sn": sn, "mask": mask})


class RNA_DatasetBaselineSplitssbppV6SAVEDwithFM(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        extra_bpp_path=Path("../eda/bpp/comb"),
        extra_bpp=[
            "vienna_2",
            "contrafold_2",
            "rnaformer",
        ],
        Lmax=206,
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = Lmax
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.L = df_2A3["L"].values
        self.seq = df_2A3["sequence"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path
        self.sequence_id = df_2A3["sequence_id"].values

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        L = len(seq)
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[:L] = True
            return {"mask": mask}, {"mask": mask}
        # seq = [self.seq_map[s] for s in seq]
        seq0 = np.array([*seq])
        seq = np.zeros(L, dtype=np.int64)
        for k in self.seq_map:
            seq[seq0 == k] = self.seq_map[k]
        seq = torch.from_numpy(seq)

        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[:L] = True

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        if react.shape[0] != self.Lmax:
            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)
            react_err = F.pad(
                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan
            )

        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        data = np.load(self.extra_bpp_path / f"{self.sequence_id[idx]}.npz")

        ss = torch.from_numpy(data["ss_vienna"].astype(np.float32))
        bpp = torch.from_numpy(data["bpp_org"].astype(np.float32))
        bpp_extra = [
            torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp
        ] + [
            extra_bpp_from_numpy(
                Path("../eda/bpp/rnafm") / f"{self.sequence_id[idx]}.npy", L, seq_len=L
            )
        ]
        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0)

        seq = F.pad(seq, (0, self.Lmax - L))
        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))
        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))
        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))

        return deepcopy(
            {
                "seq": seq,
                "mask": mask,
                "ss_adj": ss,
                "bb_matrix_full_prob": bpp,
                "bb_matrix_full_prob_extra": bpp_extra,
            }
        ), deepcopy(
            {
                "react": react,
                "react_err": react_err,
                "mask": mask,
                "react_ex": torch.full((self.Lmax, 12), torch.nan),
                "react_ex_err": torch.full((self.Lmax, 12), torch.nan),
            }
        )


class RNA_DatasetBaselineSplitssbppV6SAVEDwithFMFlip(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        extra_bpp_path=Path("../eda/bpp/comb"),
        extra_bpp=[
            "vienna_2",
            "contrafold_2",
            "rnaformer",
        ],
        Lmax=206,
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = Lmax
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.L = df_2A3["L"].values
        self.seq = df_2A3["sequence"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path
        self.sequence_id = df_2A3["sequence_id"].values
        self.mode = mode

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        L = len(seq)
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[:L] = True
            return {"mask": mask}, {"mask": mask}
        # seq = [self.seq_map[s] for s in seq]
        seq0 = np.array([*seq])
        seq = np.zeros(L, dtype=np.int64)
        for k in self.seq_map:
            seq[seq0 == k] = self.seq_map[k]
        seq = torch.from_numpy(seq)

        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[:L] = True

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        if react.shape[0] != self.Lmax:
            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)
            react_err = F.pad(
                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan
            )

        data = np.load(self.extra_bpp_path / f"{self.sequence_id[idx]}.npz")

        ss = torch.from_numpy(data["ss_vienna"].astype(np.float32))
        bpp = torch.from_numpy(data["bpp_org"].astype(np.float32))
        bpp_extra = [
            torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp
        ] + [
            extra_bpp_from_numpy(
                Path("../eda/bpp/rnafm") / f"{self.sequence_id[idx]}.npy", L, seq_len=L
            )
        ]
        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0)

        if self.mode == "train" and random.random() > 0.5:
            seq = seq.flip(-1)
            bpp = bpp.flip(-1, -2)
            bpp_extra = bpp_extra.flip(-1, -2)
            ss = ss.flip(-1, -2)

            react = F.pad(react[:L].flip(0), (0, 0, 0, self.Lmax - L), value=torch.nan)
            react_err = F.pad(
                react_err[:L].flip(0), (0, 0, 0, self.Lmax - L), value=torch.nan
            )

        seq = F.pad(seq, (0, self.Lmax - L))
        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))
        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))
        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))

        return deepcopy(
            {
                "seq": seq,
                "mask": mask,
                "ss_adj": ss,
                "bb_matrix_full_prob": bpp,
                "bb_matrix_full_prob_extra": bpp_extra,
            }
        ), deepcopy(
            {
                "react": react,
                "react_err": react_err,
                "mask": mask,
                "react_ex": torch.full((self.Lmax, 12), torch.nan),
                "react_ex_err": torch.full((self.Lmax, 12), torch.nan),
            }
        )


class RNA_DatasetBaselineSplitssbppV6SAVEDwithoutFM(Dataset):
    "similar to RNA_DatasetBaselineSplitssbppV6SAVED, just added external data support"

    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        extra_bpp_path=Path("../eda/bpp/comb"),
        extra_bpp=[
            "vienna_2",
            "contrafold_2",
            "rnaformer",
        ],
        Lmax=206,
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = Lmax
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.L = df_2A3["L"].values
        self.seq = df_2A3["sequence"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path
        self.sequence_id = df_2A3["sequence_id"].values

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        L = len(seq)
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[:L] = True
            return {"mask": mask}, {"mask": mask}
        # seq = [self.seq_map[s] for s in seq]
        seq0 = np.array([*seq])
        seq = np.zeros(L, dtype=np.int64)
        for k in self.seq_map:
            seq[seq0 == k] = self.seq_map[k]
        seq = torch.from_numpy(seq)

        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[:L] = True

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        if react.shape[0] != self.Lmax:
            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)
            react_err = F.pad(
                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan
            )

        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        data = np.load(self.extra_bpp_path / f"{self.sequence_id[idx]}.npz")

        ss = torch.from_numpy(data["ss_vienna"].astype(np.float32))
        bpp = torch.from_numpy(data["bpp_org"].astype(np.float32))
        bpp_extra = [
            torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp
        ] + [
            extra_bpp_from_numpy(
                Path("../eda/bpp/rnafm") / f"{self.sequence_id[idx]}.npy", L, seq_len=L
            )
        ]
        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0)

        seq = F.pad(seq, (0, self.Lmax - L))
        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))
        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))
        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))

        return deepcopy(
            {
                "seq": seq,
                "mask": mask,
                "ss_adj": ss,
                "bb_matrix_full_prob": bpp,
                "bb_matrix_full_prob_extra": bpp_extra,
            }
        ), deepcopy(
            {
                "react": react,
                "react_err": react_err,
                "mask": mask,
                "react_ex": torch.full((self.Lmax, 12), torch.nan),
                "react_ex_err": torch.full((self.Lmax, 12), torch.nan),
            }
        )


class RNA_DatasetBaselineSplitssbppV7SAVED(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        extra_bpp_path=Path("../eda/bpp/comb"),
        extra_bpp=["vienna_2", "contrafold_2", "rnaformer", "bpp_org", "ss_vienna"],
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.L = df_2A3["L"].values
        self.seq = df_2A3["sequence"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path
        self.sequence_id = df_2A3["sequence_id"].values

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        L = len(seq)
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[:L] = True
            return {"mask": mask}, {"mask": mask}
        # seq = [self.seq_map[s] for s in seq]
        seq0 = np.array([*seq])
        seq = np.zeros(L, dtype=np.int64)
        for k in self.seq_map:
            seq[seq0 == k] = self.seq_map[k]
        seq = torch.from_numpy(seq)

        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[:L] = True

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        if react.shape[0] != self.Lmax:
            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)
            react_err = F.pad(
                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan
            )

        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        data = np.load(self.extra_bpp_path / f"{self.sequence_id[idx]}.npz")
        bpp_extra = torch.stack(
            [torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp],
            dim=0,
        ).mean(0)
        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))
        seq = F.pad(seq, (0, self.Lmax - L))

        return deepcopy(
            {
                "seq": seq,
                "mask": mask,
                "bb_matrix_full_prob_extra": bpp_extra,
            }
        ), deepcopy({"react": react, "react_err": react_err, "sn": sn, "mask": mask})


class RNA_DatasetBaselineSplitssbppV6SAVEDFM(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        extra_bpp_path=Path("../eda/bpp/comb"),
        extra_bpp=[
            "vienna_2",
            "contrafold_2",
            "rnaformer",
        ],
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.L = df_2A3["L"].values
        self.seq = df_2A3["sequence"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path
        self.sequence_id = df_2A3["sequence_id"].values

    def get_rnafmseq(self, seqi):
        seq_map = {"S": 0, "E": 2, "A": 4, "U": 7, "C": 5, "G": 6}
        seq = [seq_map[s] for s in "S" + seqi + "E"]
        seq = np.array(seq)
        seq_holder = np.ones(self.Lmax + 2, dtype=int)
        seq_holder[: len(seq)] = seq
        seq = torch.from_numpy(seq_holder).long()
        return seq

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        seq_rnaformer = self.get_rnafmseq(seq)
        L = len(seq)
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[:L] = True
            return {"mask": mask}, {"mask": mask}
        # seq = [self.seq_map[s] for s in seq]
        seq0 = np.array([*seq])
        seq = np.zeros(L, dtype=np.int64)
        for k in self.seq_map:
            seq[seq0 == k] = self.seq_map[k]
        seq = torch.from_numpy(seq)

        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[:L] = True

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        if react.shape[0] != self.Lmax:
            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)
            react_err = F.pad(
                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan
            )

        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        data = np.load(self.extra_bpp_path / f"{self.sequence_id[idx]}.npz")

        ss = torch.from_numpy(data["ss_vienna"].astype(np.float32))
        bpp = torch.from_numpy(data["bpp_org"].astype(np.float32))
        bpp_extra = torch.stack(
            [torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp],
            dim=0,
        ).mean(0)

        seq = F.pad(seq, (0, self.Lmax - L))
        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))
        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))
        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))

        return deepcopy(
            {
                "seq": seq,
                "seq_rnafm": seq_rnaformer,
                "mask": mask,
                "ss_adj": ss,
                "bb_matrix_full_prob": bpp,
                "bb_matrix_full_prob_extra": bpp_extra,
            }
        ), deepcopy({"react": react, "react_err": react_err, "sn": sn, "mask": mask})


class RNA_DatasetBaselineSplitssbppV8SAVED(Dataset):
    def __init__(
        self,
        df,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        extra_bpp_path=Path("../eda/bpp/comb"),
        extra_bpp=["bpp_org", "vienna_2", "contrafold_2", "rnaformer", "ss_vienna"],
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = 206
        df["L"] = df.sequence.apply(len)
        df_2A3 = df.loc[df.experiment_type == "2A3_MaP"].reset_index(drop=True)
        df_DMS = df.loc[df.experiment_type == "DMS_MaP"].reset_index(drop=True)

        if mode != "train" or sn_train:
            m = (df_2A3["SN_filter"].values > 0) & (df_DMS["SN_filter"].values > 0)
            df_2A3 = df_2A3.loc[m].reset_index(drop=True)
            df_DMS = df_DMS.loc[m].reset_index(drop=True)

        self.L = df_2A3["L"].values
        self.seq = df_2A3["sequence"].values
        self.react_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_0" in c]
        ].values
        self.react_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_0" in c]
        ].values
        self.react_err_2A3 = df_2A3[
            [c for c in df_2A3.columns if "reactivity_error_0" in c]
        ].values
        self.react_err_DMS = df_DMS[
            [c for c in df_DMS.columns if "reactivity_error_0" in c]
        ].values
        self.sn_2A3 = df_2A3["signal_to_noise"].values
        self.sn_DMS = df_DMS["signal_to_noise"].values
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path
        self.sequence_id = df_2A3["sequence_id"].values

    def __len__(self):
        return len(self.seq)

    def __getitem__(self, idx):
        seq = self.seq[idx]
        L = len(seq)
        if self.mask_only:
            mask = torch.zeros(self.Lmax, dtype=torch.bool)
            mask[:L] = True
            return {"mask": mask}, {"mask": mask}
        # seq = [self.seq_map[s] for s in seq]
        seq0 = np.array([*seq])
        seq = np.zeros(L, dtype=np.int64)
        for k in self.seq_map:
            seq[seq0 == k] = self.seq_map[k]
        seq = torch.from_numpy(seq)

        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[:L] = True

        react = torch.from_numpy(
            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)
        )
        react_err = torch.from_numpy(
            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)
        )
        if react.shape[0] != self.Lmax:
            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)
            react_err = F.pad(
                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan
            )

        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])

        data = np.load(self.extra_bpp_path / f"{self.sequence_id[idx]}.npz")
        bpp_extra = torch.stack(
            [torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp],
            dim=0,
        )
        # bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))
        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L, 0, 0))
        seq = F.pad(seq, (0, self.Lmax - L))

        return deepcopy(
            {
                "seq": seq,
                "mask": mask,
                "bb_matrix_full_prob_extra": bpp_extra,
            }
        ), deepcopy({"react": react, "react_err": react_err, "sn": sn, "mask": mask})


class RNA_DatasetEXV0(Dataset):
    def __init__(
        self,
        df,
        mask_only=False,
        sn_train=True,
        flip_always=False,
        extra_bpp_path=Path("../eda/bpp/rmdb_data/comb"),
        extra_bpp=["vienna_2", "contrafold_2", "rnaformerv1", "rnafm"],
        repeat=1,
        Lmax=None,
        **kwargs,
    ):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        df["L"] = df.sequence.apply(len)
        if sn_train:
            df = df.loc[df.SN_filter > 0]
        self.Lmax = df.L.max() if Lmax is None else Lmax
        df_tmp = (
            df[["sequence_id", "sequence", "L"]]
            .groupby("sequence_id")
            .first()
            .reset_index()
        )
        self.sequence_id = df_tmp["sequence_id"].values.copy()
        self.seq = df_tmp["sequence"].values.copy()
        self.L = df_tmp["L"].values.copy()

        self.mapping, self.react, self.error = [], [], []
        self.experiments = sorted(df.experiment_type.unique())
        for experiment in self.experiments:
            df_tmp = df.loc[
                df.experiment_type == experiment,
                ["sequence_id"]
                + [f"reactivity_{i:04d}" for i in range(1, 434)]
                + [f"reactivity_error_{i:04d}" for i in range(1, 434)],
            ]
            df_tmp = df_tmp.groupby("sequence_id").mean()
            self.mapping.append({idx: i for i, idx in enumerate(df_tmp.index)})
            self.react.append(
                df_tmp[[f"reactivity_{i:04d}" for i in range(1, 434)]].values.copy()
            )
            self.error.append(
                df_tmp[
                    [f"reactivity_error_{i:04d}" for i in range(1, 434)]
                ].values.copy()
            )

        self.mask_only = mask_only
        self.flip_always = flip_always
        self.repeat = repeat
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path

    def __len__(self):
        return len(self.seq) * self.repeat

    def __getitem__(self, idx):
        if idx % 100000 == 0:
            gc.collect()
        idx = idx % len(self.seq)
        seq = self.seq[idx]
        L = len(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[:L] = True
        if self.mask_only:
            return {"mask": mask}, {"mask": mask}

        seq0 = np.array([*seq])
        seq = np.zeros(L, dtype=np.int64)
        for k in self.seq_map:
            seq[seq0 == k] = self.seq_map[k]
        seq = torch.from_numpy(seq)

        react, error = [], []
        seq_idx = self.sequence_id[idx]
        for e in range(len(self.experiments)):
            if seq_idx in self.mapping[e]:
                i = self.mapping[e][seq_idx]
                react.append(self.react[e][i])
                error.append(self.error[e][i])
            else:
                react.append(np.full(self.Lmax, np.nan, dtype=np.float32))
                error.append(np.full(self.Lmax, np.nan, dtype=np.float32))
        react = torch.from_numpy(np.stack(react, -1))
        error = torch.from_numpy(np.stack(error, -1))

        data = np.load(self.extra_bpp_path / f"{self.sequence_id[idx]}.npz")

        ss = torch.from_numpy(data["ss_vienna"].astype(np.float32))
        bpp = torch.from_numpy(data["eternafold"].astype(np.float32))
        bpp_extra = [
            torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp
        ]
        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0)

        if react.shape[0] != self.Lmax:
            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)
        if error.shape[0] != self.Lmax:
            error = F.pad(error, (0, 0, 0, self.Lmax - error.shape[0]), value=torch.nan)

        seq = F.pad(seq, (0, self.Lmax - L))
        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))
        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))
        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))

        return deepcopy(
            {
                "seq": seq,
                "mask": mask,
                "ss_adj": ss,
                "bb_matrix_full_prob": bpp,
                "bb_matrix_full_prob_extra": bpp_extra,
            }
        ), deepcopy(
            {
                "react": torch.full((self.Lmax, 2), torch.nan),
                "react_err": torch.full((self.Lmax, 2), torch.nan),
                "react_ex": react,
                "react_ex_err": error,
                "mask": mask,
            }
        )


class RNA_DatasetEXV0Flip(Dataset):
    def __init__(
        self,
        df,
        mask_only=False,
        sn_train=True,
        flip_always=False,
        extra_bpp_path=Path("../eda/bpp/rmdb_data/comb"),
        extra_bpp=["vienna_2", "contrafold_2", "rnaformerv1"],
        repeat=1,
        mode="train",
        Lmax=None,
        
        **kwargs,
    ):
        # same as RNA_DatasetEXV0 but without rnafm
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        df["L"] = df.sequence.apply(len)
        if sn_train:
            df = df.loc[df.SN_filter > 0]
        self.Lmax = df.L.max() if Lmax is None else Lmax
        df_tmp = (
            df[["sequence_id", "sequence", "L"]]
            .groupby("sequence_id")
            .first()
            .reset_index()
        )
        self.sequence_id = df_tmp["sequence_id"].values.copy()
        self.seq = df_tmp["sequence"].values.copy()
        self.L = df_tmp["L"].values.copy()

        self.mapping, self.react, self.error = [], [], []
        self.experiments = sorted(df.experiment_type.unique())
        for experiment in self.experiments:
            df_tmp = df.loc[
                df.experiment_type == experiment,
                ["sequence_id"]
                + [f"reactivity_{i:04d}" for i in range(1, 434)]
                + [f"reactivity_error_{i:04d}" for i in range(1, 434)],
            ]
            df_tmp = df_tmp.groupby("sequence_id").mean()
            self.mapping.append({idx: i for i, idx in enumerate(df_tmp.index)})
            self.react.append(
                df_tmp[[f"reactivity_{i:04d}" for i in range(1, 434)]].values.copy()
            )
            self.error.append(
                df_tmp[
                    [f"reactivity_error_{i:04d}" for i in range(1, 434)]
                ].values.copy()
            )

        self.mask_only = mask_only
        self.flip_always = flip_always
        self.repeat = repeat
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path
        self.mode = mode

    def __len__(self):
        return len(self.seq) * self.repeat

    def __getitem__(self, idx):
        if idx % 100000 == 0:
            gc.collect()
        idx = idx % len(self.seq)
        seq = self.seq[idx]
        L = len(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[:L] = True
        if self.mask_only:
            return {"mask": mask}, {"mask": mask}

        seq0 = np.array([*seq])
        seq = np.zeros(L, dtype=np.int64)
        for k in self.seq_map:
            seq[seq0 == k] = self.seq_map[k]
        seq = torch.from_numpy(seq)

        react, error = [], []
        seq_idx = self.sequence_id[idx]
        for e in range(len(self.experiments)):
            if seq_idx in self.mapping[e]:
                i = self.mapping[e][seq_idx]
                react.append(self.react[e][i])
                error.append(self.error[e][i])
            else:
                react.append(np.full(self.Lmax, np.nan, dtype=np.float32))
                error.append(np.full(self.Lmax, np.nan, dtype=np.float32))
        react = torch.from_numpy(np.stack(react, -1))
        error = torch.from_numpy(np.stack(error, -1))

        data = np.load(self.extra_bpp_path / f"{self.sequence_id[idx]}.npz")

        ss = torch.from_numpy(data["ss_vienna"].astype(np.float32))
        bpp = torch.from_numpy(data["eternafold"].astype(np.float32))
        bpp_extra = [
            torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp
        ]
        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0)

        if self.mode == "train" and random.random() > 0.5:
            seq = seq.flip(-1)
            bpp = bpp.flip(-1, -2)
            bpp_extra = bpp_extra.flip(-1, -2)
            ss = ss.flip(-1, -2)

            react = react[:L].flip(0)
            error = error[:L].flip(0)

        if react.shape[0] != self.Lmax:
            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)
        if error.shape[0] != self.Lmax:
            error = F.pad(error, (0, 0, 0, self.Lmax - error.shape[0]), value=torch.nan)

        seq = F.pad(seq, (0, self.Lmax - L))
        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))
        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))
        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))

        return deepcopy(
            {
                "seq": seq,
                "mask": mask,
                "ss_adj": ss,
                "bb_matrix_full_prob": bpp,
                "bb_matrix_full_prob_extra": bpp_extra,
            }
        ), deepcopy(
            {
                "react": torch.full((self.Lmax, 2), torch.nan),
                "react_err": torch.full((self.Lmax, 2), torch.nan),
                "react_ex": react,
                "react_ex_err": error,
                "mask": mask,
            }
        )


class RNA_DatasetBaselineSplitssbppV6SAVEDwithFMPSD(Dataset):
    def __init__(
        self,
        data,
        orig_test_csv,
        train_data,
        folds_split,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        extra_bpp_path=Path("../eda/bpp/comb"),
        extra_bpp=[
            "vienna_2",
            "contrafold_2",
            "rnaformer",
        ],
        Lmax=457,
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = Lmax

        df_test = pd.read_csv(orig_test_csv)[["sequence_id", "sequence"]]
        df_train = pd.read_parquet(train_data)[["sequence_id", "sequence"]]
        df = pd.concat([df_train, df_test])
        df = df.drop_duplicates(subset=["sequence_id"])

        split = pd.read_csv(folds_split)
        split = set(split.loc[~split.is_train, "sequence_id"])

        df = df.loc[~df.sequence_id.isin(split)]
        self.df = df.reset_index(drop=True)
        self.data = data

        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        if idx % 100000 == 0:
            gc.collect()
        idx, seq = self.df.loc[idx, ["sequence_id", "sequence"]]
        L = len(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[:L] = True
        if self.mask_only:
            return deepcopy({"mask": mask}), deepcopy({"mask": mask})
        seq0 = np.array([*seq])
        seq = np.zeros(L, dtype=np.int64)
        for k in self.seq_map:
            seq[seq0 == k] = self.seq_map[k]
        seq = torch.from_numpy(seq)

        react, react_err = self.data[idx]
        data = np.load(self.extra_bpp_path / f"{idx}.npz")
        ss = torch.from_numpy(data["ss_vienna"].astype(np.float32))
        bpp = torch.from_numpy(data["bpp_org"].astype(np.float32))
        bpp_extra = [
            torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp
        ] + [
            extra_bpp_from_numpy(
                Path("../eda/bpp/rnafm") / f"{idx}.npy", L, seq_len=L
            )
        ]
        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0)

        seq = F.pad(seq, (0, self.Lmax - L))
        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))
        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))
        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))

        if react.shape[0] != self.Lmax:
            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)
        if react_err.shape[0] != self.Lmax:
            react_err = F.pad(
                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan
            )

        return deepcopy(
            {
                "seq": seq,
                "mask": mask,
                "ss_adj": ss,
                "bb_matrix_full_prob": bpp,
                "bb_matrix_full_prob_extra": bpp_extra,
            }
        ), deepcopy(
            {
                "react": react,
                "react_err": react_err,
                "mask": mask,
            }
        )
        
        
class RNA_DatasetBaselineSplitssbppV6SAVEDwithFMPSDExternal(Dataset):
    def __init__(
        self,
        data,
        orig_test_csv,
        train_data,
        folds_split,
        mode="train",
        seed=2023,
        fold=0,
        nfolds=4,
        mask_only=False,
        sn_train=True,
        extra_bpp_path=Path("../eda/bpp/comb"),
        extra_bpp=[
            "vienna_2",
            "contrafold_2",
            "rnaformer",
        ],
        Lmax=457,
        **kwargs,
    ):
        """
        short sequence without adapters
        """
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        self.Lmax = Lmax

        df_test = pd.read_csv(orig_test_csv)[["sequence_id", "sequence"]]
        df_train = pd.read_parquet(train_data)[["sequence_id", "sequence"]]
        df = pd.concat([df_train, df_test])
        df = df.drop_duplicates(subset=["sequence_id"])

        split = pd.read_csv(folds_split)
        split = set(split.loc[~split.is_train, "sequence_id"])

        df = df.loc[~df.sequence_id.isin(split)]
        self.df = df.reset_index(drop=True)
        self.data = data

        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        if idx % 100000 == 0:
            gc.collect()
        idx, seq = self.df.loc[idx, ["sequence_id", "sequence"]]
        L = len(seq)
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        mask[:L] = True
        if self.mask_only:
            return deepcopy({"mask": mask}), deepcopy({"mask": mask})
        seq0 = np.array([*seq])
        seq = np.zeros(L, dtype=np.int64)
        for k in self.seq_map:
            seq[seq0 == k] = self.seq_map[k]
        seq = torch.from_numpy(seq)

        react, react_err = self.data[idx]
        data = np.load(self.extra_bpp_path / f"{idx}.npz")
        ss = torch.from_numpy(data["ss_vienna"].astype(np.float32))
        bpp = torch.from_numpy(data["bpp_org"].astype(np.float32))
        bpp_extra = [
            torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp
        ] + [
            extra_bpp_from_numpy(
                Path("../eda/bpp/rnafm") / f"{idx}.npy", L, seq_len=L
            )
        ]
        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0)

        seq = F.pad(seq, (0, self.Lmax - L))
        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))
        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))
        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))

        if react.shape[0] != self.Lmax:
            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)
        if react_err.shape[0] != self.Lmax:
            react_err = F.pad(
                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan
            )

        return deepcopy(
            {
                "seq": seq,
                "mask": mask,
                "ss_adj": ss,
                "bb_matrix_full_prob": bpp,
                "bb_matrix_full_prob_extra": bpp_extra,
            }
        ), deepcopy(
            {
                
                "react": torch.full((self.Lmax, 2), torch.nan),
                "react_err": torch.full((self.Lmax, 2), torch.nan),
                "react": react,
                "react_err": react_err,
                "mask": mask,
            }
        )

# %% ../nbs/00_dataset.ipynb 8
class RNA_Dataset_Test(Dataset):
    def __init__(self, df, mask_only=False, **kwargs):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        df["L"] = df.sequence.apply(len)
        self.Lmax = df["L"].max()
        self.df = df
        self.mask_only = mask_only

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        id_min, id_max, seq = self.df.loc[idx, ["id_min", "id_max", "sequence"]]
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        L = len(seq)
        mask[:L] = True
        if self.mask_only:
            return {"mask": mask}, {}
        ids = np.arange(id_min, id_max + 1)

        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        seq = np.pad(seq, (0, self.Lmax - L))
        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)

        return {"seq": torch.from_numpy(seq), "mask": mask}, {"ids": ids}


class RNA_Dataset_TestBpp(Dataset):
    def __init__(self, df, mask_only=False, **kwargs):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        df["L"] = df.sequence.apply(len)
        self.Lmax = df["L"].max()
        self.df = df
        self.mask_only = mask_only

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        id_min, id_max, seq = self.df.loc[idx, ["id_min", "id_max", "sequence"]]
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        L = len(seq)
        mask[:L] = True
        if self.mask_only:
            return {"mask": mask}, {}
        ids = np.arange(id_min, id_max + 1)
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        seq = np.pad(seq, (0, self.Lmax - L))
        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)
        bpp = self.df["bpp"][idx]
        bpp = (generate_base_pair_matrix(bpp, self.Lmax) > 0.5).int()

        return {"seq": torch.from_numpy(seq), "mask": mask, "adj_matrix": bpp}, {
            "ids": ids
        }


class RNA_Dataset_Testss(Dataset):
    def __init__(self, df, mask_only=False, **kwargs):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        df["L"] = df.sequence.apply(len)
        self.Lmax = df["L"].max()
        self.df = df
        self.mask_only = mask_only
        self.ss = df["ss_roi"].values

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        id_min, id_max, seq = self.df.loc[idx, ["id_min", "id_max", "sequence"]]
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        L = len(seq)
        mask[:L] = True
        if self.mask_only:
            return {"mask": mask}, {}
        ids = np.arange(id_min, id_max + 1)
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        seq = np.pad(seq, (0, self.Lmax - L))
        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)
        bpp = torch.tensor(dot_to_adjacency(self.ss[idx], self.Lmax)).int()

        return {"seq": torch.from_numpy(seq), "mask": mask, "adj_matrix": bpp}, {
            "ids": ids
        }


class RNA_Dataset_TestBppSS(Dataset):
    def __init__(self, df, mask_only=False, **kwargs):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        df["L"] = df.sequence.apply(len)
        self.Lmax = df["L"].max()
        self.df = df
        self.mask_only = mask_only

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        id_min, id_max, seq = self.df.loc[idx, ["id_min", "id_max", "sequence"]]
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        L = len(seq)
        mask[:L] = True
        if self.mask_only:
            return {"mask": mask}, {}
        ids = np.arange(id_min, id_max + 1)
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        seq = np.pad(seq, (0, self.Lmax - L))
        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)
        bpp = self.df["bpp"][idx]
        bpp = (generate_base_pair_matrix(bpp, self.Lmax) > 0.5).int()
        ss_adj = torch.tensor(dot_to_adjacency(self.df["ss_roi"][idx], self.Lmax)).int()

        return {
            "seq": torch.from_numpy(seq),
            "mask": mask,
            "adj_matrix": bpp,
            "ss_adj": ss_adj,
        }, {"ids": ids}


class RNA_Dataset_TestBppSSFullV0(Dataset):
    def __init__(self, df, mask_only=False, **kwargs):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        df["L"] = df.sequence.apply(len)
        self.Lmax = df["L"].max()
        self.df = df
        self.mask_only = mask_only

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        id_min, id_max, seq = self.df.loc[idx, ["id_min", "id_max", "sequence"]]
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        L = len(seq)
        mask[:L] = True
        if self.mask_only:
            return {"mask": mask}, {}
        ids = np.arange(id_min, id_max + 1)
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        seq = np.pad(seq, (0, self.Lmax - L))
        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)
        bpp = self.df["bpp"][idx]
        bb_matrix_full_prob = generate_base_pair_matrixv1(bpp, self.Lmax)
        bpp = (bb_matrix_full_prob.clone() > 0.5).int()
        ss_adj = torch.tensor(
            dot_to_adjacencyv0(self.df["ss_full"][idx], self.Lmax)
        ).int()

        return {
            "seq": torch.from_numpy(seq),
            "mask": mask,
            "adj_matrix": bpp,
            "ss_adj": ss_adj,
            "bb_matrix_full_prob": bb_matrix_full_prob,
        }, {"ids": ids}


class RNA_Dataset_TestBppSSFullV1(Dataset):
    def __init__(
        self,
        df,
        mask_only=False,
        extra_bpp_path=Path("../eda/bpp"),
        extra_bpp=["vienna_2", "contrafold_2"],
        **kwargs,
    ):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        df["L"] = df.sequence.apply(len)
        self.Lmax = df["L"].max()
        self.df = df
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        id_min, id_max, seq = self.df.loc[idx, ["id_min", "id_max", "sequence"]]
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        L = len(seq)
        mask[:L] = True
        if self.mask_only:
            return {"mask": mask}, {}
        ids = np.arange(id_min, id_max + 1)
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        seq = np.pad(seq, (0, self.Lmax - L))
        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)
        bpp = self.df["bpp"][idx]
        bpp_ = generate_base_pair_matrixv1(bpp, self.Lmax)
        bpp_extra = [
            extra_bpp_from_numpy(self.extra_bpp_path / f"{i}/{bpp.stem}.npy", self.Lmax)
            for i in self.extra_bpp
        ]
        bb_matrix_full_prob = torch.stack([bpp_, *bpp_extra], dim=0).mean(0).float()

        bpp = (bb_matrix_full_prob.clone() > 0.5).int()
        ss_adj = torch.tensor(
            dot_to_adjacencyv0(self.df["ss_full"][idx], self.Lmax)
        ).int()

        return {
            "seq": torch.from_numpy(seq),
            "mask": mask,
            "adj_matrix": bpp,
            "ss_adj": ss_adj,
            "bb_matrix_full_prob": bb_matrix_full_prob,
        }, {"ids": ids}
        
        
class RNA_Dataset_TestBppSSFullV2(Dataset):
    def __init__(
        self,
        df,
        mask_only=False,
        extra_bpp_path=Path("../eda/bpp"),
        extra_bpp=["vienna_2", "contrafold_2", "rnaformer"],
        **kwargs,
    ):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        df["L"] = df.sequence.apply(len)
        self.Lmax = df["L"].max()
        self.df = df
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        id_min, id_max, seq = self.df.loc[idx, ["id_min", "id_max", "sequence"]]
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        L = len(seq)
        mask[:L] = True
        if self.mask_only:
            return {"mask": mask}, {}
        ids = np.arange(id_min, id_max + 1)
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        seq = np.pad(seq, (0, self.Lmax - L))
        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)
        bpp = self.df["bpp"][idx]
        bpp_ = generate_base_pair_matrixv1(bpp, self.Lmax)
        bpp_extra = [
            extra_bpp_from_numpy(self.extra_bpp_path / f"{i}/{bpp.stem}.npy", self.Lmax, seq_len=L )
            for i in self.extra_bpp
        ]
        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()
        bb_matrix_full_prob = bpp_.float()

        bpp = (bb_matrix_full_prob.clone() > 0.5).int()
        ss_adj = torch.tensor(
            dot_to_adjacencyv0(self.df["ss_full"][idx], self.Lmax)
        ).int()

        return {
            "seq": torch.from_numpy(seq),
            "mask": mask,
            "adj_matrix": bpp,
            "ss_adj": ss_adj,
            "bb_matrix_full_prob": bb_matrix_full_prob,
            "bb_matrix_full_prob_extra": bpp_extra,
        }, {"ids": ids}
        
class RNA_Dataset_TestBppSSFullV3(Dataset):
    def __init__(
        self,
        df,
        mask_only=False,
        extra_bpp_path=Path("../eda/bpp"),
        extra_bpp=["rnafm"],
        **kwargs,
    ):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        df["L"] = df.sequence.apply(len)
        self.Lmax = df["L"].max()
        self.df = df
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        id_min, id_max, seq = self.df.loc[idx, ["id_min", "id_max", "sequence"]]
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        L = len(seq)
        mask[:L] = True
        if self.mask_only:
            return {"mask": mask}, {}
        ids = np.arange(id_min, id_max + 1)
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        seq = np.pad(seq, (0, self.Lmax - L))
        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)
        bpp = self.df["bpp"][idx]
        bpp_ = generate_base_pair_matrixv1(bpp, self.Lmax)
        bpp_extra = [
            extra_bpp_from_numpy(self.extra_bpp_path / f"{i}/{bpp.stem}.npy", self.Lmax, seq_len=L )
            for i in self.extra_bpp
        ]
        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()
        bb_matrix_full_prob = bpp_.float()

        bpp = (bb_matrix_full_prob.clone() > 0.5).int()
        ss_adj = torch.tensor(
            dot_to_adjacencyv0(self.df["ss_full"][idx], self.Lmax)
        ).int()

        return {
            "seq": torch.from_numpy(seq),
            "mask": mask,
            "adj_matrix": bpp,
            "ss_adj": ss_adj,
            "bb_matrix_full_prob": bb_matrix_full_prob,
            "bb_matrix_full_prob_extra": bpp_extra,
        }, {"ids": ids}
        
        
        

class RNA_Dataset_TestBppSSFullV4(Dataset):
    def __init__(
        self,
        df,
        mask_only=False,
        extra_bpp_path=Path("../eda/bpp"),
        extra_bpp=["rnafm", "vienna_2", "contrafold_2", "rnaformer"],
        **kwargs,
    ):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        df["L"] = df.sequence.apply(len)
        self.Lmax = df["L"].max()
        self.df = df
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        id_min, id_max, seq = self.df.loc[idx, ["id_min", "id_max", "sequence"]]
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        L = len(seq)
        mask[:L] = True
        if self.mask_only:
            return {"mask": mask}, {}
        ids = np.arange(id_min, id_max + 1)
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        seq = np.pad(seq, (0, self.Lmax - L))
        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)
        bpp = self.df["bpp"][idx]
        bpp_ = generate_base_pair_matrixv1(bpp, self.Lmax)
        bpp_extra = [
            extra_bpp_from_numpy(self.extra_bpp_path / f"{i}/{bpp.stem}.npy", self.Lmax, seq_len=L )
            for i in self.extra_bpp
        ]
        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()
        bb_matrix_full_prob = bpp_.float()

        bpp = (bb_matrix_full_prob.clone() > 0.5).int()
        ss_adj = torch.tensor(
            dot_to_adjacencyv0(self.df["ss_full"][idx], self.Lmax)
        ).int()

        return {
            "seq": torch.from_numpy(seq),
            "mask": mask,
            "adj_matrix": bpp,
            "ss_adj": ss_adj,
            "bb_matrix_full_prob": bb_matrix_full_prob,
            "bb_matrix_full_prob_extra": bpp_extra,
        }, {"ids": ids}
        
        
class RNA_Dataset_TestBppSSFullV5(Dataset):
    def __init__(
        self,
        df,
        mask_only=False,
        extra_bpp_path=Path("../eda/bpp"),
        extra_bpp=["vienna_2", "contrafold_2", "rnaformer"],
        **kwargs,
    ):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        df["L"] = df.sequence.apply(len)
        self.Lmax = df["L"].max()
        self.df = df
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        id_min, id_max, seq = self.df.loc[idx, ["id_min", "id_max", "sequence"]]
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        L = len(seq)
        mask[:L] = True
        if self.mask_only:
            return {"mask": mask}, {}
        ids = np.arange(id_min, id_max + 1)
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        seq = np.pad(seq, (0, self.Lmax - L))
        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)
        bpp = self.df["bpp"][idx]
        bpp_ = generate_base_pair_matrixv1(bpp, self.Lmax)
        bpp_extra = [
            extra_bpp_from_numpy(self.extra_bpp_path / f"{i}/{bpp.stem}.npy", self.Lmax, seq_len=L )
            for i in self.extra_bpp
        ]
        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()
        bb_matrix_full_prob = bpp_.float()

        bpp = (bb_matrix_full_prob.clone() > 0.5).int()
        ss_adj = torch.tensor(
            dot_to_adjacencyv0(self.df["ss_full"][idx], self.Lmax)
        ).int()

        return {
            "seq": torch.from_numpy(seq),
            "mask": mask,
            "adj_matrix": bpp,
            "ss_adj": ss_adj,
            "bb_matrix_full_prob": bb_matrix_full_prob,
            "bb_matrix_full_prob_extra": bpp_extra,
        }, {"ids": ids}
        
        
        

class RNA_Dataset_TestSavedV0(Dataset):
    def __init__(
        self,
        df,
        mask_only=False,
        extra_bpp_path=Path("../eda/bpp/comb"),
        extra_bpp=["vienna_2", "contrafold_2", "rnaformer",],
        **kwargs,
    ):
        self.seq_map = {"A": 0, "C": 1, "G": 2, "U": 3}
        df["L"] = df.sequence.apply(len)
        self.Lmax = df["L"].max()
        self.df = df
        self.mask_only = mask_only
        self.extra_bpp = extra_bpp
        self.extra_bpp_path = extra_bpp_path

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        id_min, id_max, seq = self.df.loc[idx, ["id_min", "id_max", "sequence"]]
        mask = torch.zeros(self.Lmax, dtype=torch.bool)
        L = len(seq)
        mask[:L] = True
        if self.mask_only:
            return {"mask": mask}, {}
        ids = np.arange(id_min, id_max + 1)
        seq = [self.seq_map[s] for s in seq]
        seq = np.array(seq)
        seq = np.pad(seq, (0, self.Lmax - L))
        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)
        data = np.load(self.extra_bpp_path/f'{self.df["bpp"][idx].stem}.npz')
        
        ss =  torch.from_numpy(data['ss_vienna'].astype(np.float32))
        bpp = torch.from_numpy(data['bpp_org'].astype(np.float32))
        bpp_extra = torch.stack([torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp], dim=0).mean(0)
        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))
        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))
        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))



        return deepcopy({
            "seq": torch.from_numpy(seq),
            "mask": mask,
            "adj_matrix": bpp,
            "ss_adj": ss,
            "bb_matrix_full_prob": bpp,
            "bb_matrix_full_prob_extra": bpp_extra,
        }), deepcopy({"ids": ids})
        

