{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data, DataLoader, Batch\n",
    "import torch\n",
    "import seaborn as sbn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def good_luck():\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export \n",
    "class LenMatchBatchSampler(torch.utils.data.BatchSampler):\n",
    "    def __iter__(self):\n",
    "        buckets = [[]] * 100\n",
    "        yielded = 0\n",
    "\n",
    "        for idx in self.sampler:\n",
    "            s = self.sampler.data_source[idx]\n",
    "            if isinstance(s,tuple): L = s[0][\"mask\"].sum()\n",
    "            else: L = s[\"mask\"].sum()\n",
    "            L = max(1,L // 16) \n",
    "            if len(buckets[L]) == 0:  buckets[L] = []\n",
    "            buckets[L].append(idx)\n",
    "            \n",
    "            if len(buckets[L]) == self.batch_size:\n",
    "                batch = list(buckets[L])\n",
    "                yield batch\n",
    "                yielded += 1\n",
    "                buckets[L] = []\n",
    "                \n",
    "        batch = []\n",
    "        leftover = [idx for bucket in buckets for idx in bucket]\n",
    "\n",
    "        for idx in leftover:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yielded += 1\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yielded += 1\n",
    "            yield batch\n",
    "            \n",
    "def dict_to(x, device='cuda'):\n",
    "    return {k:x[k].to(device) for k in x}\n",
    "\n",
    "def to_device(x, device='cuda'):\n",
    "    return tuple(dict_to(e,device) for e in x)\n",
    "\n",
    "class DeviceDataLoader:\n",
    "    def __init__(self, dataloader, device='cuda'):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dataloader:\n",
    "            yield tuple(dict_to(x, self.device) for x in batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# |export\n",
    "def encode_rna_sequence(seq):\n",
    "    L = len(seq)\n",
    "\n",
    "    # Initialize the tensor with zeros\n",
    "    tensor = np.zeros((L, L, 8))\n",
    "\n",
    "    # Define valid base pairs\n",
    "    valid_pairs = [\n",
    "        (\"A\", \"U\"),\n",
    "        (\"U\", \"A\"),\n",
    "        (\"U\", \"G\"),\n",
    "        (\"G\", \"U\"),\n",
    "        (\"G\", \"C\"),\n",
    "        (\"C\", \"G\"),\n",
    "    ]\n",
    "\n",
    "    for i in range(L):\n",
    "        for j in range(L):\n",
    "            # Check for valid base pairs\n",
    "            if (seq[i], seq[j]) in valid_pairs:\n",
    "                channel = valid_pairs.index((seq[i], seq[j]))\n",
    "                tensor[i, j, channel] = 1\n",
    "            # Check for diagonal\n",
    "            elif i == j:\n",
    "                tensor[i, j, 6] = 1\n",
    "            # If not a valid pair and not on the diagonal, set the last channel\n",
    "            else:\n",
    "                tensor[i, j, 7] = 1\n",
    "\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def generate_edge_data(file_path):\n",
    "    # Read the file into a DataFrame\n",
    "    data = pd.read_csv(file_path, sep=\" \", header=None, names=[\"pos1\", \"pos2\", \"prob\"])\n",
    "\n",
    "    # Convert the pos1 and pos2 columns to 0-based indices and then to a tensor for edge index\n",
    "    edge_index = torch.tensor(\n",
    "        [data[\"pos1\"].values - 1, data[\"pos2\"].values - 1], dtype=torch.long\n",
    "    )\n",
    "\n",
    "    # Convert the prob column to a tensor for edge features\n",
    "    edge_features = torch.tensor(data[\"prob\"].values, dtype=torch.float).unsqueeze(\n",
    "        1\n",
    "    )  # Adding an extra dimension\n",
    "\n",
    "    return edge_index, edge_features\n",
    "\n",
    "\n",
    "class RNA_DatasetBaseline(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"]\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"]\n",
    "\n",
    "        split = list(\n",
    "            KFold(n_splits=nfolds, random_state=seed, shuffle=True).split(df_2A3)\n",
    "        )[fold][0 if mode == \"train\" else 1]\n",
    "        df_2A3 = df_2A3.iloc[split].reset_index(drop=True)\n",
    "        df_DMS = df_DMS.iloc[split].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplit(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetBaseline(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"]\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"]\n",
    "\n",
    "        split = list(\n",
    "            KFold(n_splits=nfolds, random_state=seed, shuffle=True).split(df_2A3)\n",
    "        )[fold][0 if mode == \"train\" else 1]\n",
    "        df_2A3 = df_2A3.iloc[split].reset_index(drop=True)\n",
    "        df_DMS = df_DMS.iloc[split].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetV0(Dataset):\n",
    "    def __init__(self, df, mask_only=False, prob_for_adj=0.5, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        self.prob_for_adj = prob_for_adj\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        adj_matrix = generate_adj_matrix(self.bpp[idx], self.Lmax, self.prob_for_adj)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": adj_matrix}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetV1(Dataset):\n",
    "    # same as v0 but not adj matrix\n",
    "    def __init__(self, df, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetV0G(Dataset):\n",
    "    def __init__(self, df, path_to_bpp_folder, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        edge_index, edge_features = generate_edge_data(self.bpp[idx])\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        return Data(\n",
    "            x=torch.from_numpy(seq),\n",
    "            edge_index=edge_index,\n",
    "            edge_features=edge_features,\n",
    "            y=react,\n",
    "            y_err=react_err,\n",
    "        )\n",
    "\n",
    "\n",
    "class LenMatchBatchSampler(torch.utils.data.BatchSampler):\n",
    "    def __iter__(self):\n",
    "        buckets = [[]] * 100\n",
    "        yielded = 0\n",
    "\n",
    "        for idx in self.sampler:\n",
    "            s = self.sampler.data_source[idx]\n",
    "            if isinstance(s, tuple):\n",
    "                L = s[0][\"mask\"].sum()\n",
    "            else:\n",
    "                L = s[\"mask\"].sum()\n",
    "            L = max(1, L // 16)\n",
    "            if len(buckets[L]) == 0:\n",
    "                buckets[L] = []\n",
    "            buckets[L].append(idx)\n",
    "\n",
    "            if len(buckets[L]) == self.batch_size:\n",
    "                batch = list(buckets[L])\n",
    "                yield batch\n",
    "                yielded += 1\n",
    "                buckets[L] = []\n",
    "\n",
    "        batch = []\n",
    "        leftover = [idx for bucket in buckets for idx in bucket]\n",
    "\n",
    "        for idx in leftover:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yielded += 1\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yielded += 1\n",
    "            yield batch\n",
    "\n",
    "\n",
    "def generate_base_pair_matrix(file_path, L):\n",
    "    \"\"\"\n",
    "    Reads a TXT file of base pair probabilities and generates an n x n matrix.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the TXT file.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: An n x n matrix of base pair probabilities.\n",
    "    \"\"\"\n",
    "    # Read the data using pandas\n",
    "    data = pd.read_csv(file_path, sep=\" \", header=None, names=[\"pos1\", \"pos2\", \"prob\"])\n",
    "\n",
    "    # Find the largest position in the 'pos1' column\n",
    "    largest_position = data[\"pos1\"].max()\n",
    "\n",
    "    ids = torch.from_numpy(data[[\"pos1\", \"pos2\"]].values)\n",
    "    matrix = torch.zeros((L, L))\n",
    "    matrix[ids[:, 0] - 1, ids[:, 1] - 1] = torch.from_numpy(data[\"prob\"].values).float()\n",
    "    matrix[ids[:, 1] - 1, ids[:, 0] - 1] = torch.from_numpy(data[\"prob\"].values).float()\n",
    "\n",
    "    matrix[:26, :] = 0\n",
    "    matrix[:, :26] = 0\n",
    "\n",
    "    # Adjust the end based on the largest_position and set the last 21 positions to 0\n",
    "    adjusted_end = largest_position - 21\n",
    "    matrix[adjusted_end:, :] = 0\n",
    "    matrix[:, adjusted_end:] = 0\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitbppV0(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        bpp = (generate_base_pair_matrix(self.bpp[idx], self.Lmax) > 0.5).int()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": bpp}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "def generate_base_pair_matrixv1(file_path, L):\n",
    "    \"\"\"\n",
    "    Reads a TXT file of base pair probabilities and generates an n x n matrix.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the TXT file.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: An n x n matrix of base pair probabilities.\n",
    "    \"\"\"\n",
    "    # Read the data using pandas\n",
    "    data = pd.read_csv(file_path, sep=\" \", header=None, names=[\"pos1\", \"pos2\", \"prob\"])\n",
    "\n",
    "    # Find the largest position in the 'pos1' column\n",
    "    largest_position = data[\"pos1\"].max()\n",
    "\n",
    "    ids = torch.from_numpy(data[[\"pos1\", \"pos2\"]].values)\n",
    "    matrix = torch.zeros((L, L))\n",
    "    matrix[ids[:, 0] - 1, ids[:, 1] - 1] = torch.from_numpy(data[\"prob\"].values).float()\n",
    "    matrix[ids[:, 1] - 1, ids[:, 0] - 1] = torch.from_numpy(data[\"prob\"].values).float()\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitbppV1(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        bpp = (generate_base_pair_matrixv1(self.bpp[idx], self.Lmax) > 0.5).int()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": bpp}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "def dot_to_adjacency(dot_notation, n):\n",
    "    adjacency_matrix = np.zeros((n, n), dtype=int)\n",
    "    dot_notation = (26 * \".\") + dot_notation + (21 * \".\")\n",
    "    stack = []\n",
    "    for i, char in enumerate(dot_notation):\n",
    "        if char == \"(\":\n",
    "            stack.append(i)\n",
    "        elif char == \")\":\n",
    "            j = stack.pop()\n",
    "            adjacency_matrix[i][j] = adjacency_matrix[j][i] = 1\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssV0(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_roi\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        bpp = torch.tensor(dot_to_adjacency(self.ss[idx], self.Lmax)).int()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": bpp}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssV0(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_roi\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        bpp = torch.tensor(dot_to_adjacency(self.ss[idx], self.Lmax)).int()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": bpp}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssV1(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.ss_map = {\".\": 0, \"(\": 1, \")\": 2}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "\n",
    "        ss_seq = [self.ss_map[s] for s in self.ss[idx]]\n",
    "        ss_seq = np.array(ss_seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_seq = np.pad(ss_seq, (0, self.Lmax - len(ss_seq)))\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_seq\": torch.from_numpy(ss_seq),\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitbppV2(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax)\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"bpp\": bpp}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "def dot_to_adjacencyv0(dot_notation, n):\n",
    "    adjacency_matrix = np.zeros((n, n), dtype=int)\n",
    "    stack = []\n",
    "    for i, char in enumerate(dot_notation):\n",
    "        if char == \"(\":\n",
    "            stack.append(i)\n",
    "        elif char == \")\":\n",
    "            j = stack.pop()\n",
    "            adjacency_matrix[i][j] = adjacency_matrix[j][i] = 1\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV0(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = (generate_base_pair_matrixv1(self.bpp[idx], self.Lmax) > 0.5).int()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"adj_matrix\": bpp,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV1(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax)\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bpp,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "def extra_bpp_from_numpy(filename, N):\n",
    "    \"\"\"\n",
    "    Load data from a .npy file and convert it to an N x N matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: Path to the .npy file.\n",
    "    - N: Dimension of the square matrix.\n",
    "\n",
    "    Returns:\n",
    "    - bpp_matrix: N x N matrix reconstructed from the input file.\n",
    "    \"\"\"\n",
    "    # Load the structured array from the .npy file\n",
    "    data = np.load(filename)\n",
    "\n",
    "    # Create an empty N x N matrix\n",
    "    bpp_matrix = np.zeros((N, N))\n",
    "\n",
    "    # Fill the matrix with the probabilities from the loaded data\n",
    "    bpp_matrix[data[\"pos_1\"], data[\"pos_2\"]] = data[\"probabilities\"]\n",
    "\n",
    "    return torch.tensor(bpp_matrix)\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV2(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax)\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(\n",
    "                self.extra_bpp_path / f\"{i}/{self.bpp[idx].stem}.npy\", self.Lmax\n",
    "            )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp = torch.stack([bpp, *bpp_extra], dim=0).mean(0).float()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bpp,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "        \n",
    "        \n",
    "class RNA_DatasetBaselineSplitssbppV3(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\", \"rnaformer\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax).float()\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(\n",
    "                self.extra_bpp_path / f\"{i}/{self.bpp[idx].stem}.npy\", self.Lmax\n",
    "            )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bpp,\n",
    "            \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineFM(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"S\": 0, \"E\": 2, \"A\": 4, \"U\": 7, \"C\": 5, \"G\": 6}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = [self.seq_map[s] for s in \"S\" + seq + \"E\"]\n",
    "        seq = np.array(seq)\n",
    "        seq_holder = np.ones(self.Lmax + 2, dtype=int)\n",
    "        seq_holder[: len(seq)] = seq\n",
    "\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax).float()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq_holder),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bpp,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CFG:\n",
    "#     path = Path(\"../data/\")\n",
    "#     pathbb = Path(\"../data/Ribonanza_bpp_files\")\n",
    "#     pathss = Path(\"../eda/train_ss_vienna_rna.parquet\")\n",
    "#     split_id = Path('../eda/fold_split.csv')\n",
    "#     bs = 16\n",
    "#     num_workers = 8\n",
    "#     device = 'cpu'\n",
    "#     adjnact_prob = 0.5\n",
    "    \n",
    "\n",
    "\n",
    "# fns = list(CFG.pathbb.rglob(\"*.txt\"))\n",
    "# bpp_df = pd.DataFrame({\"bpp\": fns})\n",
    "# bpp_df['sequence_id'] = bpp_df['bpp'].apply(lambda x: x.stem)\n",
    "# ss = pd.read_parquet(CFG.pathss)[[\"sequence_id\", \"ss_full\"]]\n",
    "# df = pd.read_parquet(CFG.path/'train_data.parquet')\n",
    "# split = pd.read_csv(CFG.split_id)\n",
    "# df = pd.merge(df, split, on='sequence_id')\n",
    "# df = pd.merge(df, bpp_df, on='sequence_id')\n",
    "# df = pd.merge(df, ss, on='sequence_id')\n",
    "# df_train = df.query('is_train==True').reset_index(drop=True)\n",
    "# df_valid = df.query('is_train==False').reset_index(drop=True)\n",
    "# ds_val = RNA_DatasetBaselineSplitssbppV3(df_valid, mode='eval')\n",
    "# ds_val_len = RNA_DatasetBaselineSplitssbppV3(df_valid, mode='eval', mask_only=True)\n",
    "# sampler_val = torch.utils.data.SequentialSampler(ds_val_len)\n",
    "# len_sampler_val = LenMatchBatchSampler(sampler_val, batch_size=CFG.bs, \n",
    "#                drop_last=False)\n",
    "# dl_val= DeviceDataLoader(torch.utils.data.DataLoader(ds_val, \n",
    "#                batch_sampler=len_sampler_val, num_workers=CFG.num_workers), CFG.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_val[0][0]['bb_matrix_full_prob'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RNA_Dataset_Test(Dataset):\n",
    "    def __init__(self, df, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask}, {\"ids\": ids}\n",
    "\n",
    "\n",
    "class RNA_Dataset_TestBpp(Dataset):\n",
    "    def __init__(self, df, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = self.df[\"bpp\"][idx]\n",
    "        bpp = (generate_base_pair_matrix(bpp, self.Lmax) > 0.5).int()\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": bpp}, {\n",
    "            \"ids\": ids\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_Dataset_Testss(Dataset):\n",
    "    def __init__(self, df, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "        self.ss = df[\"ss_roi\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = torch.tensor(dot_to_adjacency(self.ss[idx], self.Lmax)).int()\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": bpp}, {\n",
    "            \"ids\": ids\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_Dataset_TestBppSS(Dataset):\n",
    "    def __init__(self, df, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = self.df[\"bpp\"][idx]\n",
    "        bpp = (generate_base_pair_matrix(bpp, self.Lmax) > 0.5).int()\n",
    "        ss_adj = torch.tensor(dot_to_adjacency(self.df[\"ss_roi\"][idx], self.Lmax)).int()\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"adj_matrix\": bpp,\n",
    "            \"ss_adj\": ss_adj,\n",
    "        }, {\"ids\": ids}\n",
    "\n",
    "\n",
    "class RNA_Dataset_TestBppSSFullV0(Dataset):\n",
    "    def __init__(self, df, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = self.df[\"bpp\"][idx]\n",
    "        bb_matrix_full_prob = generate_base_pair_matrixv1(bpp, self.Lmax)\n",
    "        bpp = (bb_matrix_full_prob.clone() > 0.5).int()\n",
    "        ss_adj = torch.tensor(\n",
    "            dot_to_adjacencyv0(self.df[\"ss_full\"][idx], self.Lmax)\n",
    "        ).int()\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"adj_matrix\": bpp,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bb_matrix_full_prob,\n",
    "        }, {\"ids\": ids}\n",
    "\n",
    "\n",
    "class RNA_Dataset_TestBppSSFullV1(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mask_only=False,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = self.df[\"bpp\"][idx]\n",
    "        bpp_ = generate_base_pair_matrixv1(bpp, self.Lmax)\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(self.extra_bpp_path / f\"{i}/{bpp.stem}.npy\", self.Lmax)\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bb_matrix_full_prob = torch.stack([bpp_, *bpp_extra], dim=0).mean(0).float()\n",
    "\n",
    "        bpp = (bb_matrix_full_prob.clone() > 0.5).int()\n",
    "        ss_adj = torch.tensor(\n",
    "            dot_to_adjacencyv0(self.df[\"ss_full\"][idx], self.Lmax)\n",
    "        ).int()\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"adj_matrix\": bpp,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bb_matrix_full_prob,\n",
    "        }, {\"ids\": ids}\n",
    "        \n",
    "        \n",
    "class RNA_Dataset_TestBppSSFullV2(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mask_only=False,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\", \"rnaformer\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = self.df[\"bpp\"][idx]\n",
    "        bpp_ = generate_base_pair_matrixv1(bpp, self.Lmax)\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(self.extra_bpp_path / f\"{i}/{bpp.stem}.npy\", self.Lmax)\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()\n",
    "        bb_matrix_full_prob = bpp_.float()\n",
    "\n",
    "        bpp = (bb_matrix_full_prob.clone() > 0.5).int()\n",
    "        ss_adj = torch.tensor(\n",
    "            dot_to_adjacencyv0(self.df[\"ss_full\"][idx], self.Lmax)\n",
    "        ).int()\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"adj_matrix\": bpp,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bb_matrix_full_prob,\n",
    "            \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "        }, {\"ids\": ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
