{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data, DataLoader, Batch\n",
    "import torch\n",
    "import seaborn as sbn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "from copy import deepcopy   \n",
    "import pickle\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def good_luck():\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export \n",
    "class LenMatchBatchSampler(torch.utils.data.BatchSampler):\n",
    "    def __iter__(self):\n",
    "        buckets = [[]] * 100\n",
    "        yielded = 0\n",
    "\n",
    "        for idx in self.sampler:\n",
    "            s = self.sampler.data_source[idx]\n",
    "            if isinstance(s,tuple): L = s[0][\"mask\"].sum()\n",
    "            else: L = s[\"mask\"].sum()\n",
    "            L = max(1,L // 16) \n",
    "            if len(buckets[L]) == 0:  buckets[L] = []\n",
    "            buckets[L].append(idx)\n",
    "            \n",
    "            if len(buckets[L]) == self.batch_size:\n",
    "                batch = list(buckets[L])\n",
    "                yield batch\n",
    "                yielded += 1\n",
    "                buckets[L] = []\n",
    "                \n",
    "        batch = []\n",
    "        leftover = [idx for bucket in buckets for idx in bucket]\n",
    "\n",
    "        for idx in leftover:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yielded += 1\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yielded += 1\n",
    "            yield batch\n",
    "            \n",
    "def dict_to(x, device='cuda'):\n",
    "    return {k:x[k].to(device) for k in x}\n",
    "\n",
    "def to_device(x, device='cuda'):\n",
    "    return tuple(dict_to(e,device) for e in x)\n",
    "\n",
    "class DeviceDataLoader:\n",
    "    def __init__(self, dataloader, device='cuda'):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dataloader:\n",
    "            yield tuple(dict_to(x, self.device) for x in batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "# |export\n",
    "def encode_rna_sequence(seq):\n",
    "    L = len(seq)\n",
    "\n",
    "    # Initialize the tensor with zeros\n",
    "    tensor = np.zeros((L, L, 8))\n",
    "\n",
    "    # Define valid base pairs\n",
    "    valid_pairs = [\n",
    "        (\"A\", \"U\"),\n",
    "        (\"U\", \"A\"),\n",
    "        (\"U\", \"G\"),\n",
    "        (\"G\", \"U\"),\n",
    "        (\"G\", \"C\"),\n",
    "        (\"C\", \"G\"),\n",
    "    ]\n",
    "\n",
    "    for i in range(L):\n",
    "        for j in range(L):\n",
    "            # Check for valid base pairs\n",
    "            if (seq[i], seq[j]) in valid_pairs:\n",
    "                channel = valid_pairs.index((seq[i], seq[j]))\n",
    "                tensor[i, j, channel] = 1\n",
    "            # Check for diagonal\n",
    "            elif i == j:\n",
    "                tensor[i, j, 6] = 1\n",
    "            # If not a valid pair and not on the diagonal, set the last channel\n",
    "            else:\n",
    "                tensor[i, j, 7] = 1\n",
    "\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def generate_edge_data(file_path):\n",
    "    # Read the file into a DataFrame\n",
    "    data = pd.read_csv(file_path, sep=\" \", header=None, names=[\"pos1\", \"pos2\", \"prob\"])\n",
    "\n",
    "    # Convert the pos1 and pos2 columns to 0-based indices and then to a tensor for edge index\n",
    "    edge_index = torch.tensor(\n",
    "        [data[\"pos1\"].values - 1, data[\"pos2\"].values - 1], dtype=torch.long\n",
    "    )\n",
    "\n",
    "    # Convert the prob column to a tensor for edge features\n",
    "    edge_features = torch.tensor(data[\"prob\"].values, dtype=torch.float).unsqueeze(\n",
    "        1\n",
    "    )  # Adding an extra dimension\n",
    "\n",
    "    return edge_index, edge_features\n",
    "\n",
    "\n",
    "class RNA_DatasetBaseline(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"]\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"]\n",
    "\n",
    "        split = list(\n",
    "            KFold(n_splits=nfolds, random_state=seed, shuffle=True).split(df_2A3)\n",
    "        )[fold][0 if mode == \"train\" else 1]\n",
    "        df_2A3 = df_2A3.iloc[split].reset_index(drop=True)\n",
    "        df_DMS = df_DMS.iloc[split].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplit(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetBaseline(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"]\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"]\n",
    "\n",
    "        split = list(\n",
    "            KFold(n_splits=nfolds, random_state=seed, shuffle=True).split(df_2A3)\n",
    "        )[fold][0 if mode == \"train\" else 1]\n",
    "        df_2A3 = df_2A3.iloc[split].reset_index(drop=True)\n",
    "        df_DMS = df_DMS.iloc[split].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetV0(Dataset):\n",
    "    def __init__(self, df, mask_only=False, prob_for_adj=0.5, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        self.prob_for_adj = prob_for_adj\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        adj_matrix = generate_adj_matrix(self.bpp[idx], self.Lmax, self.prob_for_adj)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": adj_matrix}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetV1(Dataset):\n",
    "    # same as v0 but not adj matrix\n",
    "    def __init__(self, df, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetV0G(Dataset):\n",
    "    def __init__(self, df, path_to_bpp_folder, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        edge_index, edge_features = generate_edge_data(self.bpp[idx])\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        return Data(\n",
    "            x=torch.from_numpy(seq),\n",
    "            edge_index=edge_index,\n",
    "            edge_features=edge_features,\n",
    "            y=react,\n",
    "            y_err=react_err,\n",
    "        )\n",
    "\n",
    "\n",
    "class LenMatchBatchSampler(torch.utils.data.BatchSampler):\n",
    "    def __iter__(self):\n",
    "        buckets = [[]] * 100\n",
    "        yielded = 0\n",
    "\n",
    "        for idx in self.sampler:\n",
    "            s = self.sampleRNA_DatasetBaselineSplitssbppV6SAVEDwithFMPSDr.data_source[idx]\n",
    "            if isinstance(s, tuple):\n",
    "                L = s[0][\"mask\"].sum()\n",
    "            else:\n",
    "                L = s[\"mask\"].sum()\n",
    "            L = max(1, L // 16)\n",
    "            if len(buckets[L]) == 0:\n",
    "                buckets[L] = []\n",
    "            buckets[L].append(idx)\n",
    "\n",
    "            if len(buckets[L]) == self.batch_size:\n",
    "                batch = list(buckets[L])\n",
    "                yield batch\n",
    "                yielded += 1\n",
    "                buckets[L] = []\n",
    "\n",
    "        batch = []\n",
    "        leftover = [idx for bucket in buckets for idx in bucket]\n",
    "\n",
    "        for idx in leftover:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yielded += 1\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yielded += 1\n",
    "            yield batch\n",
    "\n",
    "\n",
    "def generate_base_pair_matrix(file_path, L):\n",
    "    \"\"\"\n",
    "    Reads a TXT file of base pair probabilities and generates an n x n matrix.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the TXT file.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: An n x n matrix of base pair probabilities.\n",
    "    \"\"\"\n",
    "    # Read the data using pandas\n",
    "    data = pd.read_csv(file_path, sep=\" \", header=None, names=[\"pos1\", \"pos2\", \"prob\"])\n",
    "\n",
    "    # Find the largest position in the 'pos1' column\n",
    "    largest_position = data[\"pos1\"].max()\n",
    "\n",
    "    ids = torch.from_numpy(data[[\"pos1\", \"pos2\"]].values)\n",
    "    matrix = torch.zeros((L, L))\n",
    "    matrix[ids[:, 0] - 1, ids[:, 1] - 1] = torch.from_numpy(data[\"prob\"].values).float()\n",
    "    matrix[ids[:, 1] - 1, ids[:, 0] - 1] = torch.from_numpy(data[\"prob\"].values).float()\n",
    "\n",
    "    matrix[:26, :] = 0\n",
    "    matrix[:, :26] = 0\n",
    "\n",
    "    # Adjust the end based on the largest_position and set the last 21 positions to 0\n",
    "    adjusted_end = largest_position - 21\n",
    "    matrix[adjusted_end:, :] = 0\n",
    "    matrix[:, adjusted_end:] = 0\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitbppV0(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        bpp = (generate_base_pair_matrix(self.bpp[idx], self.Lmax) > 0.5).int()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": bpp}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "def generate_base_pair_matrixv1(file_path, L):\n",
    "    \"\"\"\n",
    "    Reads a TXT file of base pair probabilities and generates an n x n matrix.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the TXT file.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: An n x n matrix of base pair probabilities.\n",
    "    \"\"\"\n",
    "    # Read the data using pandas\n",
    "    data = pd.read_csv(file_path, sep=\" \", header=None, names=[\"pos1\", \"pos2\", \"prob\"])\n",
    "\n",
    "    # Find the largest position in the 'pos1' column\n",
    "    largest_position = data[\"pos1\"].max()\n",
    "\n",
    "    ids = torch.from_numpy(data[[\"pos1\", \"pos2\"]].values.astype(int))\n",
    "    matrix = torch.zeros((L, L))\n",
    "    matrix[ids[:, 0] - 1, ids[:, 1] - 1] = torch.from_numpy(data[\"prob\"].values).float()\n",
    "    matrix[ids[:, 1] - 1, ids[:, 0] - 1] = torch.from_numpy(data[\"prob\"].values).float()\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitbppV1(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        bpp = (generate_base_pair_matrixv1(self.bpp[idx], self.Lmax) > 0.5).int()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": bpp}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "def dot_to_adjacency(dot_notation, n):\n",
    "    adjacency_matrix = np.zeros((n, n), dtype=int)\n",
    "    dot_notation = (26 * \".\") + dot_notation + (21 * \".\")\n",
    "    stack = []\n",
    "    for i, char in enumerate(dot_notation):\n",
    "        if char == \"(\":\n",
    "            stack.append(i)\n",
    "        elif char == \")\":\n",
    "            j = stack.pop()\n",
    "            adjacency_matrix[i][j] = adjacency_matrix[j][i] = 1\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssV0(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_roi\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        bpp = torch.tensor(dot_to_adjacency(self.ss[idx], self.Lmax)).int()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": bpp}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssV0(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_roi\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        bpp = torch.tensor(dot_to_adjacency(self.ss[idx], self.Lmax)).int()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": bpp}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssV1(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.ss_map = {\".\": 0, \"(\": 1, \")\": 2}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "\n",
    "        ss_seq = [self.ss_map[s] for s in self.ss[idx]]\n",
    "        ss_seq = np.array(ss_seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_seq = np.pad(ss_seq, (0, self.Lmax - len(ss_seq)))\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_seq\": torch.from_numpy(ss_seq),\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitbppV2(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax)\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"bpp\": bpp}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "def dot_to_adjacencyv0(dot_notation, n):\n",
    "    adjacency_matrix = np.zeros((n, n), dtype=int)\n",
    "    stack = []\n",
    "    for i, char in enumerate(dot_notation):\n",
    "        if char == \"(\":\n",
    "            stack.append(i)\n",
    "        elif char == \")\":\n",
    "            j = stack.pop()\n",
    "            adjacency_matrix[i][j] = adjacency_matrix[j][i] = 1\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV0Conv(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq_holder = np.zeros(self.Lmax, dtype=int)\n",
    "        seq_holder[: len(seq)] = seq\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return deepcopy(\n",
    "            {\n",
    "                \"seq\": torch.from_numpy(seq_holder),\n",
    "                \"mask\": mask,\n",
    "            }\n",
    "        ), {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV0(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = (generate_base_pair_matrixv1(self.bpp[idx], self.Lmax) > 0.5).int()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"adj_matrix\": bpp,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV1(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax)\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bpp,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "def load_rnafm(filename, seq_len, L_max):\n",
    "    \"\"\"\n",
    "    Load data from a .npy file and convert it to an N x N matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: Path to the .npy file.\n",
    "    - N: Dimension of the square matrix.\n",
    "\n",
    "    Returns:\n",
    "    - bpp_matrix: N x N matrix reconstructed from the input file.\n",
    "    \"\"\"\n",
    "    # Load the structured array from the .npy file\n",
    "    data = np.load(filename)\n",
    "\n",
    "    # Create an empty N x N matrix\n",
    "    bpp_matrix = np.zeros((seq_len, seq_len))\n",
    "\n",
    "    # Fill the matrix with the probabilities from the loaded data\n",
    "    bpp_matrix[data[\"pos_1\"], data[\"pos_2\"]] = data[\"probabilities\"]\n",
    "\n",
    "    bpp_matrix = bpp_matrix + bpp_matrix.T - np.diag(np.diag(bpp_matrix))\n",
    "    full = np.zeros((L_max, L_max))\n",
    "    full[:seq_len, :seq_len] = bpp_matrix\n",
    "    return torch.tensor(full)\n",
    "\n",
    "\n",
    "def extra_bpp_from_numpy(filename, N, seq_len=None):\n",
    "    \"\"\"\n",
    "    Load data from a .npy file and convert it to an N x N matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: Path to the .npy file.\n",
    "    - N: Dimension of the square matrix.\n",
    "\n",
    "    Returns:\n",
    "    - bpp_matrix: N x N matrix reconstructed from the input file.\n",
    "    \"\"\"\n",
    "    # Load the structured array from the .npy file\n",
    "    if filename.parent.stem in [\"rnafm\", \"rnaformerv1\"]:\n",
    "        full = load_rnafm(filename, seq_len, N)\n",
    "    else:\n",
    "        data = np.load(filename)\n",
    "        # Create an empty N x N matrix\n",
    "        bpp_matrix = np.zeros((N, N))\n",
    "        # Fill the matrix with the probabilities from the loaded data\n",
    "        bpp_matrix[data[\"pos_1\"], data[\"pos_2\"]] = data[\"probabilities\"]\n",
    "        full = torch.tensor(bpp_matrix)\n",
    "\n",
    "    return full\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV1R(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"rnafm\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax)\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(\n",
    "                self.extra_bpp_path / f\"{i}/{self.bpp[idx].stem}.npy\",\n",
    "                self.Lmax,\n",
    "                seq_len=len(self.seq[idx]),\n",
    "            )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp = torch.stack([*bpp_extra, bpp], dim=0).mean(0).float()\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bpp,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV2(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax)\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(\n",
    "                self.extra_bpp_path / f\"{i}/{self.bpp[idx].stem}.npy\", self.Lmax\n",
    "            )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp = torch.stack([bpp, *bpp_extra], dim=0).mean(0).float()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bpp,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV3(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\", \"rnaformer\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax).float()\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(\n",
    "                self.extra_bpp_path / f\"{i}/{self.bpp[idx].stem}.npy\",\n",
    "                self.Lmax,\n",
    "                seq_len=len(self.seq[idx]),\n",
    "            )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bpp,\n",
    "            \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV4(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"rnafm\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax).float()\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(\n",
    "                self.extra_bpp_path / f\"{i}/{self.bpp[idx].stem}.npy\",\n",
    "                self.Lmax,\n",
    "                seq_len=len(self.seq[idx]),\n",
    "            )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bpp,\n",
    "            \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV5(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"rnafm\", \"vienna_2\", \"contrafold_2\", \"rnaformer\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax).float()\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(\n",
    "                self.extra_bpp_path / f\"{i}/{self.bpp[idx].stem}.npy\",\n",
    "                self.Lmax,\n",
    "                seq_len=len(self.seq[idx]),\n",
    "            )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return deepcopy(\n",
    "            {\n",
    "                \"seq\": torch.from_numpy(seq),\n",
    "                \"mask\": mask,\n",
    "                \"ss_adj\": ss_adj,\n",
    "                \"bb_matrix_full_prob\": bpp,\n",
    "                \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "            }\n",
    "        ), {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV5BTTA(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"rnafm\", \"vienna_2\", \"contrafold_2\", \"rnaformer\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax).float()\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(\n",
    "                self.extra_bpp_path / f\"{i}/{self.bpp[idx].stem}.npy\",\n",
    "                self.Lmax,\n",
    "                seq_len=len(self.seq[idx]),\n",
    "            )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).float()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return deepcopy(\n",
    "            {\n",
    "                \"seq\": torch.from_numpy(seq),\n",
    "                \"mask\": mask,\n",
    "                \"ss_adj\": ss_adj,\n",
    "                \"bb_matrix_full_prob\": bpp,\n",
    "                \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "            }\n",
    "        ), {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV6(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\", \"rnaformer\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq_holder = np.zeros(self.Lmax, dtype=int)\n",
    "        seq_holder[: len(seq)] = seq\n",
    "\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax).float()\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(\n",
    "                self.extra_bpp_path / f\"{i}/{self.bpp[idx].stem}.npy\",\n",
    "                self.Lmax,\n",
    "                seq_len=len(self.seq[idx]),\n",
    "            )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return deepcopy(\n",
    "            {\n",
    "                \"seq\": torch.from_numpy(seq_holder),\n",
    "                \"mask\": mask,\n",
    "                \"ss_adj\": ss_adj,\n",
    "                \"bb_matrix_full_prob\": bpp,\n",
    "                \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "            }\n",
    "        ), deepcopy({\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask})\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineFM(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"S\": 0, \"E\": 2, \"A\": 4, \"U\": 7, \"C\": 5, \"G\": 6}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = [self.seq_map[s] for s in \"S\" + seq + \"E\"]\n",
    "        seq = np.array(seq)\n",
    "        seq_holder = np.ones(self.Lmax + 2, dtype=int)\n",
    "        seq_holder[: len(seq)] = seq\n",
    "\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax).float()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq_holder).long(),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bpp,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV7Flip(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\", \"rnaformerv1\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        L = len(seq)\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "\n",
    "        seq0 = np.array([*seq])\n",
    "        seq = np.zeros(L, dtype=np.int64)\n",
    "        for k in self.seq_map:\n",
    "            seq[seq0 == k] = self.seq_map[k]\n",
    "        seq = torch.from_numpy(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[:L] = True\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        if react.shape[0] != self.Lmax:\n",
    "            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)\n",
    "            react_err = F.pad(\n",
    "                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan\n",
    "            )\n",
    "\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], L)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], L).float()\n",
    "\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(\n",
    "                self.extra_bpp_path / f\"{i}/{self.bpp[idx].stem}.npy\", L, seq_len=L\n",
    "            )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()\n",
    "\n",
    "        if self.mode == \"train\" and random.random() > 0.5:\n",
    "            seq = seq.flip(-1)\n",
    "            bpp = bpp.flip(-1, -2)\n",
    "            bpp_extra = bpp_extra.flip(-1, -2)\n",
    "            ss_adj = ss_adj.flip(-1, -2)\n",
    "\n",
    "            react = F.pad(react[:L].flip(0), (0, 0, 0, self.Lmax - L), value=torch.nan)\n",
    "            react_err = F.pad(\n",
    "                react_err[:L].flip(0), (0, 0, 0, self.Lmax - L), value=torch.nan\n",
    "            )\n",
    "\n",
    "        seq = F.pad(seq, (0, self.Lmax - L))\n",
    "        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        ss_adj = F.pad(ss_adj, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "\n",
    "        return deepcopy(\n",
    "            {\n",
    "                \"seq\": seq,\n",
    "                \"mask\": mask,\n",
    "                \"ss_adj\": ss_adj,\n",
    "                \"bb_matrix_full_prob\": bpp,\n",
    "                \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "            }\n",
    "        ), deepcopy({\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask})\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV6SAVED(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp/comb\"),\n",
    "        extra_bpp=[\n",
    "            \"vienna_2\",\n",
    "            \"contrafold_2\",\n",
    "            \"rnaformer\",\n",
    "        ],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "        self.sequence_id = df_2A3[\"sequence_id\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        L = len(seq)\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[:L] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        # seq = [self.seq_map[s] for s in seq]\n",
    "        seq0 = np.array([*seq])\n",
    "        seq = np.zeros(L, dtype=np.int64)\n",
    "        for k in self.seq_map:\n",
    "            seq[seq0 == k] = self.seq_map[k]\n",
    "        seq = torch.from_numpy(seq)\n",
    "\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[:L] = True\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        if react.shape[0] != self.Lmax:\n",
    "            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)\n",
    "            react_err = F.pad(\n",
    "                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan\n",
    "            )\n",
    "\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        data = np.load(self.extra_bpp_path / f\"{self.sequence_id[idx]}.npz\")\n",
    "\n",
    "        ss = torch.from_numpy(data[\"ss_vienna\"].astype(np.float32))\n",
    "        bpp = torch.from_numpy(data[\"bpp_org\"].astype(np.float32))\n",
    "        bpp_extra = torch.stack(\n",
    "            [torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp],\n",
    "            dim=0,\n",
    "        ).mean(0)\n",
    "\n",
    "        seq = F.pad(seq, (0, self.Lmax - L))\n",
    "        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "\n",
    "        return deepcopy(\n",
    "            {\n",
    "                \"seq\": seq,\n",
    "                \"mask\": mask,\n",
    "                \"ss_adj\": ss,\n",
    "                \"bb_matrix_full_prob\": bpp,\n",
    "                \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "            }\n",
    "        ), deepcopy({\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask})\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV6SAVEDwithFM(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp/comb\"),\n",
    "        extra_bpp=[\n",
    "            \"vienna_2\",\n",
    "            \"contrafold_2\",\n",
    "            \"rnaformer\",\n",
    "        ],\n",
    "        Lmax=206,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = Lmax\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "        self.sequence_id = df_2A3[\"sequence_id\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        L = len(seq)\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[:L] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        # seq = [self.seq_map[s] for s in seq]\n",
    "        seq0 = np.array([*seq])\n",
    "        seq = np.zeros(L, dtype=np.int64)\n",
    "        for k in self.seq_map:\n",
    "            seq[seq0 == k] = self.seq_map[k]\n",
    "        seq = torch.from_numpy(seq)\n",
    "\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[:L] = True\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        if react.shape[0] != self.Lmax:\n",
    "            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)\n",
    "            react_err = F.pad(\n",
    "                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan\n",
    "            )\n",
    "\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        data = np.load(self.extra_bpp_path / f\"{self.sequence_id[idx]}.npz\")\n",
    "\n",
    "        ss = torch.from_numpy(data[\"ss_vienna\"].astype(np.float32))\n",
    "        bpp = torch.from_numpy(data[\"bpp_org\"].astype(np.float32))\n",
    "        bpp_extra = [\n",
    "            torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp\n",
    "        ] + [\n",
    "            extra_bpp_from_numpy(\n",
    "                Path(\"../eda/bpp/rnafm\") / f\"{self.sequence_id[idx]}.npy\", L, seq_len=L\n",
    "            )\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0)\n",
    "\n",
    "        seq = F.pad(seq, (0, self.Lmax - L))\n",
    "        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "\n",
    "        return deepcopy(\n",
    "            {\n",
    "                \"seq\": seq,\n",
    "                \"mask\": mask,\n",
    "                \"ss_adj\": ss,\n",
    "                \"bb_matrix_full_prob\": bpp,\n",
    "                \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "            }\n",
    "        ), deepcopy(\n",
    "            {\n",
    "                \"react\": react,\n",
    "                \"react_err\": react_err,\n",
    "                \"mask\": mask,\n",
    "                \"react_ex\": torch.full((self.Lmax, 12), torch.nan),\n",
    "                \"react_ex_err\": torch.full((self.Lmax, 12), torch.nan),\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV6SAVEDwithFMFlip(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp/comb\"),\n",
    "        extra_bpp=[\n",
    "            \"vienna_2\",\n",
    "            \"contrafold_2\",\n",
    "            \"rnaformer\",\n",
    "        ],\n",
    "        Lmax=206,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = Lmax\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "        self.sequence_id = df_2A3[\"sequence_id\"].values\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        L = len(seq)\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[:L] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        # seq = [self.seq_map[s] for s in seq]\n",
    "        seq0 = np.array([*seq])\n",
    "        seq = np.zeros(L, dtype=np.int64)\n",
    "        for k in self.seq_map:\n",
    "            seq[seq0 == k] = self.seq_map[k]\n",
    "        seq = torch.from_numpy(seq)\n",
    "\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[:L] = True\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        if react.shape[0] != self.Lmax:\n",
    "            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)\n",
    "            react_err = F.pad(\n",
    "                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan\n",
    "            )\n",
    "\n",
    "        data = np.load(self.extra_bpp_path / f\"{self.sequence_id[idx]}.npz\")\n",
    "\n",
    "        ss = torch.from_numpy(data[\"ss_vienna\"].astype(np.float32))\n",
    "        bpp = torch.from_numpy(data[\"bpp_org\"].astype(np.float32))\n",
    "        bpp_extra = [\n",
    "            torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp\n",
    "        ] + [\n",
    "            extra_bpp_from_numpy(\n",
    "                Path(\"../eda/bpp/rnafm\") / f\"{self.sequence_id[idx]}.npy\", L, seq_len=L\n",
    "            )\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0)\n",
    "\n",
    "        if self.mode == \"train\" and random.random() > 0.5:\n",
    "            seq = seq.flip(-1)\n",
    "            bpp = bpp.flip(-1, -2)\n",
    "            bpp_extra = bpp_extra.flip(-1, -2)\n",
    "            ss = ss.flip(-1, -2)\n",
    "\n",
    "            react = F.pad(react[:L].flip(0), (0, 0, 0, self.Lmax - L), value=torch.nan)\n",
    "            react_err = F.pad(\n",
    "                react_err[:L].flip(0), (0, 0, 0, self.Lmax - L), value=torch.nan\n",
    "            )\n",
    "\n",
    "        seq = F.pad(seq, (0, self.Lmax - L))\n",
    "        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "\n",
    "        return deepcopy(\n",
    "            {\n",
    "                \"seq\": seq,\n",
    "                \"mask\": mask,\n",
    "                \"ss_adj\": ss,\n",
    "                \"bb_matrix_full_prob\": bpp,\n",
    "                \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "            }\n",
    "        ), deepcopy(\n",
    "            {\n",
    "                \"react\": react,\n",
    "                \"react_err\": react_err,\n",
    "                \"mask\": mask,\n",
    "                \"react_ex\": torch.full((self.Lmax, 12), torch.nan),\n",
    "                \"react_ex_err\": torch.full((self.Lmax, 12), torch.nan),\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV6SAVEDwithoutFM(Dataset):\n",
    "    \"similar to RNA_DatasetBaselineSplitssbppV6SAVED, just added external data support\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp/comb\"),\n",
    "        extra_bpp=[\n",
    "            \"vienna_2\",\n",
    "            \"contrafold_2\",\n",
    "            \"rnaformer\",\n",
    "        ],\n",
    "        Lmax=206,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = Lmax\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "        self.sequence_id = df_2A3[\"sequence_id\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        L = len(seq)\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[:L] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        # seq = [self.seq_map[s] for s in seq]\n",
    "        seq0 = np.array([*seq])\n",
    "        seq = np.zeros(L, dtype=np.int64)\n",
    "        for k in self.seq_map:\n",
    "            seq[seq0 == k] = self.seq_map[k]\n",
    "        seq = torch.from_numpy(seq)\n",
    "\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[:L] = True\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        if react.shape[0] != self.Lmax:\n",
    "            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)\n",
    "            react_err = F.pad(\n",
    "                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan\n",
    "            )\n",
    "\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        data = np.load(self.extra_bpp_path / f\"{self.sequence_id[idx]}.npz\")\n",
    "\n",
    "        ss = torch.from_numpy(data[\"ss_vienna\"].astype(np.float32))\n",
    "        bpp = torch.from_numpy(data[\"bpp_org\"].astype(np.float32))\n",
    "        bpp_extra = [\n",
    "            torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp\n",
    "        ] + [\n",
    "            extra_bpp_from_numpy(\n",
    "                Path(\"../eda/bpp/rnafm\") / f\"{self.sequence_id[idx]}.npy\", L, seq_len=L\n",
    "            )\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0)\n",
    "\n",
    "        seq = F.pad(seq, (0, self.Lmax - L))\n",
    "        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "\n",
    "        return deepcopy(\n",
    "            {\n",
    "                \"seq\": seq,\n",
    "                \"mask\": mask,\n",
    "                \"ss_adj\": ss,\n",
    "                \"bb_matrix_full_prob\": bpp,\n",
    "                \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "            }\n",
    "        ), deepcopy(\n",
    "            {\n",
    "                \"react\": react,\n",
    "                \"react_err\": react_err,\n",
    "                \"mask\": mask,\n",
    "                \"react_ex\": torch.full((self.Lmax, 12), torch.nan),\n",
    "                \"react_ex_err\": torch.full((self.Lmax, 12), torch.nan),\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV7SAVED(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp/comb\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\", \"rnaformer\", \"bpp_org\", \"ss_vienna\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "        self.sequence_id = df_2A3[\"sequence_id\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        L = len(seq)\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[:L] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        # seq = [self.seq_map[s] for s in seq]\n",
    "        seq0 = np.array([*seq])\n",
    "        seq = np.zeros(L, dtype=np.int64)\n",
    "        for k in self.seq_map:\n",
    "            seq[seq0 == k] = self.seq_map[k]\n",
    "        seq = torch.from_numpy(seq)\n",
    "\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[:L] = True\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        if react.shape[0] != self.Lmax:\n",
    "            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)\n",
    "            react_err = F.pad(\n",
    "                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan\n",
    "            )\n",
    "\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        data = np.load(self.extra_bpp_path / f\"{self.sequence_id[idx]}.npz\")\n",
    "        bpp_extra = torch.stack(\n",
    "            [torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp],\n",
    "            dim=0,\n",
    "        ).mean(0)\n",
    "        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        seq = F.pad(seq, (0, self.Lmax - L))\n",
    "\n",
    "        return deepcopy(\n",
    "            {\n",
    "                \"seq\": seq,\n",
    "                \"mask\": mask,\n",
    "                \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "            }\n",
    "        ), deepcopy({\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask})\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV6SAVEDFM(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp/comb\"),\n",
    "        extra_bpp=[\n",
    "            \"vienna_2\",\n",
    "            \"contrafold_2\",\n",
    "            \"rnaformer\",\n",
    "        ],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "        self.sequence_id = df_2A3[\"sequence_id\"].values\n",
    "\n",
    "    def get_rnafmseq(self, seqi):\n",
    "        seq_map = {\"S\": 0, \"E\": 2, \"A\": 4, \"U\": 7, \"C\": 5, \"G\": 6}\n",
    "        seq = [seq_map[s] for s in \"S\" + seqi + \"E\"]\n",
    "        seq = np.array(seq)\n",
    "        seq_holder = np.ones(self.Lmax + 2, dtype=int)\n",
    "        seq_holder[: len(seq)] = seq\n",
    "        seq = torch.from_numpy(seq_holder).long()\n",
    "        return seq\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        seq_rnaformer = self.get_rnafmseq(seq)\n",
    "        L = len(seq)\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[:L] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        # seq = [self.seq_map[s] for s in seq]\n",
    "        seq0 = np.array([*seq])\n",
    "        seq = np.zeros(L, dtype=np.int64)\n",
    "        for k in self.seq_map:\n",
    "            seq[seq0 == k] = self.seq_map[k]\n",
    "        seq = torch.from_numpy(seq)\n",
    "\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[:L] = True\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        if react.shape[0] != self.Lmax:\n",
    "            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)\n",
    "            react_err = F.pad(\n",
    "                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan\n",
    "            )\n",
    "\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        data = np.load(self.extra_bpp_path / f\"{self.sequence_id[idx]}.npz\")\n",
    "\n",
    "        ss = torch.from_numpy(data[\"ss_vienna\"].astype(np.float32))\n",
    "        bpp = torch.from_numpy(data[\"bpp_org\"].astype(np.float32))\n",
    "        bpp_extra = torch.stack(\n",
    "            [torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp],\n",
    "            dim=0,\n",
    "        ).mean(0)\n",
    "\n",
    "        seq = F.pad(seq, (0, self.Lmax - L))\n",
    "        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "\n",
    "        return deepcopy(\n",
    "            {\n",
    "                \"seq\": seq,\n",
    "                \"seq_rnafm\": seq_rnaformer,\n",
    "                \"mask\": mask,\n",
    "                \"ss_adj\": ss,\n",
    "                \"bb_matrix_full_prob\": bpp,\n",
    "                \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "            }\n",
    "        ), deepcopy({\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask})\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV8SAVED(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp/comb\"),\n",
    "        extra_bpp=[\"bpp_org\", \"vienna_2\", \"contrafold_2\", \"rnaformer\", \"ss_vienna\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "        self.sequence_id = df_2A3[\"sequence_id\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        L = len(seq)\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[:L] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        # seq = [self.seq_map[s] for s in seq]\n",
    "        seq0 = np.array([*seq])\n",
    "        seq = np.zeros(L, dtype=np.int64)\n",
    "        for k in self.seq_map:\n",
    "            seq[seq0 == k] = self.seq_map[k]\n",
    "        seq = torch.from_numpy(seq)\n",
    "\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[:L] = True\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        if react.shape[0] != self.Lmax:\n",
    "            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)\n",
    "            react_err = F.pad(\n",
    "                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan\n",
    "            )\n",
    "\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        data = np.load(self.extra_bpp_path / f\"{self.sequence_id[idx]}.npz\")\n",
    "        bpp_extra = torch.stack(\n",
    "            [torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp],\n",
    "            dim=0,\n",
    "        )\n",
    "        # bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L, 0, 0))\n",
    "        seq = F.pad(seq, (0, self.Lmax - L))\n",
    "\n",
    "        return deepcopy(\n",
    "            {\n",
    "                \"seq\": seq,\n",
    "                \"mask\": mask,\n",
    "                \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "            }\n",
    "        ), deepcopy({\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask})\n",
    "\n",
    "\n",
    "class RNA_DatasetEXV0(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        flip_always=False,\n",
    "        extra_bpp_path=Path(\"../eda/bpp/rmdb_data/comb\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\", \"rnaformerv1\", \"rnafm\"],\n",
    "        repeat=1,\n",
    "        Lmax=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        if sn_train:\n",
    "            df = df.loc[df.SN_filter > 0]\n",
    "        self.Lmax_ = df.L.max() \n",
    "        self.Lmax = Lmax\n",
    "        df_tmp = (\n",
    "            df[[\"sequence_id\", \"sequence\", \"L\"]]\n",
    "            .groupby(\"sequence_id\")\n",
    "            .first()\n",
    "            .reset_index()\n",
    "        )\n",
    "        self.sequence_id = df_tmp[\"sequence_id\"].values.copy()\n",
    "        self.seq = df_tmp[\"sequence\"].values.copy()\n",
    "        self.L = df_tmp[\"L\"].values.copy()\n",
    "\n",
    "        self.mapping, self.react, self.error = [], [], []\n",
    "        self.experiments = sorted(df.experiment_type.unique())\n",
    "        for experiment in self.experiments:\n",
    "            df_tmp = df.loc[\n",
    "                df.experiment_type == experiment,\n",
    "                [\"sequence_id\"]\n",
    "                + [f\"reactivity_{i:04d}\" for i in range(1, 434)]\n",
    "                + [f\"reactivity_error_{i:04d}\" for i in range(1, 434)],\n",
    "            ]\n",
    "            df_tmp = df_tmp.groupby(\"sequence_id\").mean()\n",
    "            self.mapping.append({idx: i for i, idx in enumerate(df_tmp.index)})\n",
    "            self.react.append(\n",
    "                df_tmp[[f\"reactivity_{i:04d}\" for i in range(1, 434)]].values.copy()\n",
    "            )\n",
    "            self.error.append(\n",
    "                df_tmp[\n",
    "                    [f\"reactivity_error_{i:04d}\" for i in range(1, 434)]\n",
    "                ].values.copy()\n",
    "            )\n",
    "\n",
    "        self.mask_only = mask_only\n",
    "        self.flip_always = flip_always\n",
    "        self.repeat = repeat\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq) * self.repeat\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx % 100000 == 0:\n",
    "            gc.collect()\n",
    "        idx = idx % len(self.seq)\n",
    "        seq = self.seq[idx]\n",
    "        L = len(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "\n",
    "        seq0 = np.array([*seq])\n",
    "        seq = np.zeros(L, dtype=np.int64)\n",
    "        for k in self.seq_map:\n",
    "            seq[seq0 == k] = self.seq_map[k]\n",
    "        seq = torch.from_numpy(seq)\n",
    "\n",
    "        react, error = [], []\n",
    "        seq_idx = self.sequence_id[idx]\n",
    "        for e in range(len(self.experiments)):\n",
    "            if seq_idx in self.mapping[e]:\n",
    "                i = self.mapping[e][seq_idx]\n",
    "                react.append(self.react[e][i])\n",
    "                error.append(self.error[e][i])\n",
    "            else:\n",
    "                react.append(np.full(self.Lmax_, np.nan, dtype=np.float32))\n",
    "                error.append(np.full(self.Lmax_, np.nan, dtype=np.float32))\n",
    "        react = torch.from_numpy(np.stack(react, -1))\n",
    "        error = torch.from_numpy(np.stack(error, -1))\n",
    "\n",
    "        data = np.load(self.extra_bpp_path / f\"{self.sequence_id[idx]}.npz\")\n",
    "\n",
    "        ss = torch.from_numpy(data[\"ss_vienna\"].astype(np.float32))\n",
    "        bpp = torch.from_numpy(data[\"eternafold\"].astype(np.float32))\n",
    "        bpp_extra = [\n",
    "            torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0)\n",
    "\n",
    "        if react.shape[0] != self.Lmax:\n",
    "            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)\n",
    "        if error.shape[0] != self.Lmax:\n",
    "            error = F.pad(error, (0, 0, 0, self.Lmax - error.shape[0]), value=torch.nan)\n",
    "\n",
    "        seq = F.pad(seq, (0, self.Lmax - L))\n",
    "        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "\n",
    "        return deepcopy(\n",
    "            {\n",
    "                \"seq\": seq,\n",
    "                \"mask\": mask,\n",
    "                \"ss_adj\": ss,\n",
    "                \"bb_matrix_full_prob\": bpp,\n",
    "                \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "            }\n",
    "        ), deepcopy(\n",
    "            {\n",
    "                \"react\": torch.full((self.Lmax, 2), torch.nan),\n",
    "                \"react_err\": torch.full((self.Lmax, 2), torch.nan),\n",
    "                \"react_ex\": react,\n",
    "                \"react_ex_err\": error,\n",
    "                \"mask\": mask,\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "class RNA_DatasetEXV1(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        flip_always=False,\n",
    "        extra_bpp_path=Path(\"../eda/bpp/rmdb_data/comb\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\", \"rnaformerv1\"],\n",
    "        repeat=1,\n",
    "        Lmax=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        if sn_train:\n",
    "            df = df.loc[df.SN_filter > 0]\n",
    "        self.Lmax_ = df.L.max() \n",
    "        self.Lmax = Lmax\n",
    "        df_tmp = (\n",
    "            df[[\"sequence_id\", \"sequence\", \"L\"]]\n",
    "            .groupby(\"sequence_id\")\n",
    "            .first()\n",
    "            .reset_index()\n",
    "        )\n",
    "        self.sequence_id = df_tmp[\"sequence_id\"].values.copy()\n",
    "        self.seq = df_tmp[\"sequence\"].values.copy()\n",
    "        self.L = df_tmp[\"L\"].values.copy()\n",
    "\n",
    "        self.mapping, self.react, self.error = [], [], []\n",
    "        self.experiments = sorted(df.experiment_type.unique())\n",
    "        for experiment in self.experiments:\n",
    "            df_tmp = df.loc[\n",
    "                df.experiment_type == experiment,\n",
    "                [\"sequence_id\"]\n",
    "                + [f\"reactivity_{i:04d}\" for i in range(1, 434)]\n",
    "                + [f\"reactivity_error_{i:04d}\" for i in range(1, 434)],\n",
    "            ]\n",
    "            df_tmp = df_tmp.groupby(\"sequence_id\").mean()\n",
    "            self.mapping.append({idx: i for i, idx in enumerate(df_tmp.index)})\n",
    "            self.react.append(\n",
    "                df_tmp[[f\"reactivity_{i:04d}\" for i in range(1, 434)]].values.copy()\n",
    "            )\n",
    "            self.error.append(\n",
    "                df_tmp[\n",
    "                    [f\"reactivity_error_{i:04d}\" for i in range(1, 434)]\n",
    "                ].values.copy()\n",
    "            )\n",
    "\n",
    "        self.mask_only = mask_only\n",
    "        self.flip_always = flip_always\n",
    "        self.repeat = repeat\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq) * self.repeat\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx % 100000 == 0:\n",
    "            gc.collect()\n",
    "        idx = idx % len(self.seq)\n",
    "        seq = self.seq[idx]\n",
    "        L = len(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "\n",
    "        seq0 = np.array([*seq])\n",
    "        seq = np.zeros(L, dtype=np.int64)\n",
    "        for k in self.seq_map:\n",
    "            seq[seq0 == k] = self.seq_map[k]\n",
    "        seq = torch.from_numpy(seq)\n",
    "\n",
    "        react, error = [], []\n",
    "        seq_idx = self.sequence_id[idx]\n",
    "        for e in range(len(self.experiments)):\n",
    "            if seq_idx in self.mapping[e]:\n",
    "                i = self.mapping[e][seq_idx]\n",
    "                react.append(self.react[e][i])\n",
    "                error.append(self.error[e][i])\n",
    "            else:\n",
    "                react.append(np.full(self.Lmax_, np.nan, dtype=np.float32))\n",
    "                error.append(np.full(self.Lmax_, np.nan, dtype=np.float32))\n",
    "        react = torch.from_numpy(np.stack(react, -1))\n",
    "        error = torch.from_numpy(np.stack(error, -1))\n",
    "\n",
    "        data = np.load(self.extra_bpp_path / f\"{self.sequence_id[idx]}.npz\")\n",
    "\n",
    "        ss = torch.from_numpy(data[\"ss_vienna\"].astype(np.float32))\n",
    "        bpp = torch.from_numpy(data[\"eternafold\"].astype(np.float32))\n",
    "        bpp_extra = [\n",
    "            torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0)\n",
    "\n",
    "        if react.shape[0] != self.Lmax:\n",
    "            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)\n",
    "        if error.shape[0] != self.Lmax:\n",
    "            error = F.pad(error, (0, 0, 0, self.Lmax - error.shape[0]), value=torch.nan)\n",
    "\n",
    "        seq = F.pad(seq, (0, self.Lmax - L))\n",
    "        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "\n",
    "        return deepcopy(\n",
    "            {\n",
    "                \"seq\": seq,\n",
    "                \"mask\": mask,\n",
    "                \"ss_adj\": ss,\n",
    "                \"bb_matrix_full_prob\": bpp,\n",
    "                \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "            }\n",
    "        ), deepcopy(\n",
    "            {\n",
    "                \"react\": torch.full((self.Lmax, 2), torch.nan),\n",
    "                \"react_err\": torch.full((self.Lmax, 2), torch.nan),\n",
    "                \"react_ex\": react,\n",
    "                \"react_ex_err\": error,\n",
    "                \"mask\": mask,\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "class RNA_DatasetEXV0Flip(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        flip_always=False,\n",
    "        extra_bpp_path=Path(\"../eda/bpp/rmdb_data/comb\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\", \"rnaformerv1\"],\n",
    "        repeat=1,\n",
    "        mode=\"train\",\n",
    "        Lmax=None,\n",
    "        \n",
    "        **kwargs,\n",
    "    ):\n",
    "        # same as RNA_DatasetEXV0 but without rnafm\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        if sn_train:\n",
    "            df = df.loc[df.SN_filter > 0]\n",
    "        self.Lmax = df.L.max() if Lmax is None else Lmax\n",
    "        df_tmp = (\n",
    "            df[[\"sequence_id\", \"sequence\", \"L\"]]\n",
    "            .groupby(\"sequence_id\")\n",
    "            .first()\n",
    "            .reset_index()\n",
    "        )\n",
    "        self.sequence_id = df_tmp[\"sequence_id\"].values.copy()\n",
    "        self.seq = df_tmp[\"sequence\"].values.copy()\n",
    "        self.L = df_tmp[\"L\"].values.copy()\n",
    "\n",
    "        self.mapping, self.react, self.error = [], [], []\n",
    "        self.experiments = sorted(df.experiment_type.unique())\n",
    "        for experiment in self.experiments:\n",
    "            df_tmp = df.loc[\n",
    "                df.experiment_type == experiment,\n",
    "                [\"sequence_id\"]\n",
    "                + [f\"reactivity_{i:04d}\" for i in range(1, 434)]\n",
    "                + [f\"reactivity_error_{i:04d}\" for i in range(1, 434)],\n",
    "            ]\n",
    "            df_tmp = df_tmp.groupby(\"sequence_id\").mean()\n",
    "            self.mapping.append({idx: i for i, idx in enumerate(df_tmp.index)})\n",
    "            self.react.append(\n",
    "                df_tmp[[f\"reactivity_{i:04d}\" for i in range(1, 434)]].values.copy()\n",
    "            )\n",
    "            self.error.append(\n",
    "                df_tmp[\n",
    "                    [f\"reactivity_error_{i:04d}\" for i in range(1, 434)]\n",
    "                ].values.copy()\n",
    "            )\n",
    "\n",
    "        self.mask_only = mask_only\n",
    "        self.flip_always = flip_always\n",
    "        self.repeat = repeat\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq) * self.repeat\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx % 100000 == 0:\n",
    "            gc.collect()\n",
    "        idx = idx % len(self.seq)\n",
    "        seq = self.seq[idx]\n",
    "        L = len(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "\n",
    "        seq0 = np.array([*seq])\n",
    "        seq = np.zeros(L, dtype=np.int64)\n",
    "        for k in self.seq_map:\n",
    "            seq[seq0 == k] = self.seq_map[k]\n",
    "        seq = torch.from_numpy(seq)\n",
    "\n",
    "        react, error = [], []\n",
    "        seq_idx = self.sequence_id[idx]\n",
    "        for e in range(len(self.experiments)):\n",
    "            if seq_idx in self.mapping[e]:\n",
    "                i = self.mapping[e][seq_idx]\n",
    "                react.append(self.react[e][i])\n",
    "                error.append(self.error[e][i])\n",
    "            else:\n",
    "                react.append(np.full(self.Lmax, np.nan, dtype=np.float32))\n",
    "                error.append(np.full(self.Lmax, np.nan, dtype=np.float32))\n",
    "        react = torch.from_numpy(np.stack(react, -1))\n",
    "        error = torch.from_numpy(np.stack(error, -1))\n",
    "\n",
    "        data = np.load(self.extra_bpp_path / f\"{self.sequence_id[idx]}.npz\")\n",
    "\n",
    "        ss = torch.from_numpy(data[\"ss_vienna\"].astype(np.float32))\n",
    "        bpp = torch.from_numpy(data[\"eternafold\"].astype(np.float32))\n",
    "        bpp_extra = [\n",
    "            torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0)\n",
    "\n",
    "        if self.mode == \"train\" and random.random() > 0.5:\n",
    "            seq = seq.flip(-1)\n",
    "            bpp = bpp.flip(-1, -2)\n",
    "            bpp_extra = bpp_extra.flip(-1, -2)\n",
    "            ss = ss.flip(-1, -2)\n",
    "\n",
    "            react = react[:L].flip(0)\n",
    "            error = error[:L].flip(0)\n",
    "\n",
    "        if react.shape[0] != self.Lmax:\n",
    "            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)\n",
    "        if error.shape[0] != self.Lmax:\n",
    "            error = F.pad(error, (0, 0, 0, self.Lmax - error.shape[0]), value=torch.nan)\n",
    "\n",
    "        seq = F.pad(seq, (0, self.Lmax - L))\n",
    "        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "\n",
    "        return deepcopy(\n",
    "            {\n",
    "                \"seq\": seq,\n",
    "                \"mask\": mask,\n",
    "                \"ss_adj\": ss,\n",
    "                \"bb_matrix_full_prob\": bpp,\n",
    "                \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "            }\n",
    "        ), deepcopy(\n",
    "            {\n",
    "                \"react\": torch.full((self.Lmax, 2), torch.nan),\n",
    "                \"react_err\": torch.full((self.Lmax, 2), torch.nan),\n",
    "                \"react_ex\": react,\n",
    "                \"react_ex_err\": error,\n",
    "                \"mask\": mask,\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV6SAVEDwithFMPSD(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        orig_test_csv,\n",
    "        train_data,\n",
    "        folds_split,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp/comb\"),\n",
    "        extra_bpp=[\n",
    "            \"vienna_2\",\n",
    "            \"contrafold_2\",\n",
    "            \"rnaformer\",\n",
    "        ],\n",
    "        Lmax=457,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = Lmax\n",
    "\n",
    "        df_test = pd.read_parquet(orig_test_csv)[[\"sequence_id\", \"sequence\"]]\n",
    "        df_train = pd.read_parquet(train_data)[[\"sequence_id\", \"sequence\"]]\n",
    "        df = pd.concat([df_train, df_test])\n",
    "        df = df.drop_duplicates(subset=[\"sequence_id\"])\n",
    "\n",
    "        split = pd.read_csv(folds_split)\n",
    "        split = set(split.loc[~split.is_train, \"sequence_id\"])\n",
    "\n",
    "        df = df.loc[~df.sequence_id.isin(split)]\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.data = data\n",
    "\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx % 100000 == 0:\n",
    "            gc.collect()\n",
    "        idx, seq = self.df.loc[idx, [\"sequence_id\", \"sequence\"]]\n",
    "        L = len(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return deepcopy({\"mask\": mask}), deepcopy({\"mask\": mask})\n",
    "        seq0 = np.array([*seq])\n",
    "        seq = np.zeros(L, dtype=np.int64)\n",
    "        for k in self.seq_map:\n",
    "            seq[seq0 == k] = self.seq_map[k]\n",
    "        seq = torch.from_numpy(seq)\n",
    "\n",
    "        react, react_err = self.data[idx]\n",
    "        data = np.load(self.extra_bpp_path / f\"{idx}.npz\")\n",
    "        ss = torch.from_numpy(data[\"ss_vienna\"].astype(np.float32))\n",
    "        bpp = torch.from_numpy(data[\"bpp_org\"].astype(np.float32))\n",
    "        bpp_extra = [\n",
    "            torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp\n",
    "        ] + [\n",
    "            extra_bpp_from_numpy(\n",
    "                Path(\"../eda/bpp/rnafm\") / f\"{idx}.npy\", L, seq_len=L\n",
    "            )\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0)\n",
    "\n",
    "        seq = F.pad(seq, (0, self.Lmax - L))\n",
    "        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "\n",
    "        if react.shape[0] != self.Lmax:\n",
    "            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)\n",
    "        if react_err.shape[0] != self.Lmax:\n",
    "            react_err = F.pad(\n",
    "                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan\n",
    "            )\n",
    "\n",
    "        return deepcopy(\n",
    "            {\n",
    "                \"seq\": seq,\n",
    "                \"mask\": mask,\n",
    "                \"ss_adj\": ss,\n",
    "                \"bb_matrix_full_prob\": bpp,\n",
    "                \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "            }\n",
    "        ), deepcopy(\n",
    "            {\n",
    "                \"react\": react,\n",
    "                \"react_err\": react_err,\n",
    "                \"mask\": mask,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        \n",
    "class RNA_DatasetBaselineSplitssbppV6SAVEDwithnoFMPSD(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        orig_test_csv,\n",
    "        train_data,\n",
    "        folds_split,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp/comb\"),\n",
    "        extra_bpp=[\n",
    "            \"vienna_2\",\n",
    "            \"contrafold_2\",\n",
    "            \"rnaformer\",\n",
    "        ],\n",
    "        Lmax=457,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = Lmax\n",
    "\n",
    "        df_test = pd.read_parquet(orig_test_csv)[[\"sequence_id\", \"sequence\"]]\n",
    "        df_train = pd.read_parquet(train_data)[[\"sequence_id\", \"sequence\"]]\n",
    "        df = pd.concat([df_train, df_test])\n",
    "        df = df.drop_duplicates(subset=[\"sequence_id\"])\n",
    "\n",
    "        split = pd.read_csv(folds_split)\n",
    "        split = set(split.loc[~split.is_train, \"sequence_id\"])\n",
    "\n",
    "        df = df.loc[~df.sequence_id.isin(split)]\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.data = data\n",
    "\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx % 100000 == 0:\n",
    "            gc.collect()\n",
    "        idx, seq = self.df.loc[idx, [\"sequence_id\", \"sequence\"]]\n",
    "        L = len(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return deepcopy({\"mask\": mask}), deepcopy({\"mask\": mask})\n",
    "        seq0 = np.array([*seq])\n",
    "        seq = np.zeros(L, dtype=np.int64)\n",
    "        for k in self.seq_map:\n",
    "            seq[seq0 == k] = self.seq_map[k]\n",
    "        seq = torch.from_numpy(seq)\n",
    "\n",
    "        react, react_err = self.data[idx]\n",
    "        data = np.load(self.extra_bpp_path / f\"{idx}.npz\")\n",
    "        ss = torch.from_numpy(data[\"ss_vienna\"].astype(np.float32))\n",
    "        bpp = torch.from_numpy(data[\"bpp_org\"].astype(np.float32))\n",
    "        bpp_extra = [\n",
    "            torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp\n",
    "        ] \n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0)\n",
    "\n",
    "        seq = F.pad(seq, (0, self.Lmax - L))\n",
    "        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "\n",
    "        if react.shape[0] != self.Lmax:\n",
    "            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)\n",
    "        if react_err.shape[0] != self.Lmax:\n",
    "            react_err = F.pad(\n",
    "                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan\n",
    "            )\n",
    "\n",
    "        return deepcopy(\n",
    "            {\n",
    "                \"seq\": seq,\n",
    "                \"mask\": mask,\n",
    "                \"ss_adj\": ss,\n",
    "                \"bb_matrix_full_prob\": bpp,\n",
    "                \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "            }\n",
    "        ), deepcopy(\n",
    "            {\n",
    "                \"react\": react,\n",
    "                \"react_err\": react_err,\n",
    "                \"mask\": mask,\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "class RNA_DatasetBaselineSplitssbppV6SAVEDwithFMPSDExternal(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        orig_test_csv,\n",
    "        train_data,\n",
    "        folds_split,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp/comb\"),\n",
    "        extra_bpp=[\n",
    "            \"vienna_2\",\n",
    "            \"contrafold_2\",\n",
    "            \"rnaformer\",\n",
    "        ],\n",
    "        Lmax=457,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = Lmax\n",
    "\n",
    "        df_test = pd.read_parquet(orig_test_csv)[[\"sequence_id\", \"sequence\"]]\n",
    "        df_train = pd.read_parquet(train_data)[[\"sequence_id\", \"sequence\"]]\n",
    "        df = pd.concat([df_train, df_test])\n",
    "        df = df.drop_duplicates(subset=[\"sequence_id\"])\n",
    "\n",
    "        split = pd.read_csv(folds_split)\n",
    "        split = set(split.loc[~split.is_train, \"sequence_id\"])\n",
    "\n",
    "        df = df.loc[~df.sequence_id.isin(split)]\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.data = data\n",
    "\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx % 100000 == 0:\n",
    "            gc.collect()\n",
    "        idx, seq = self.df.loc[idx, [\"sequence_id\", \"sequence\"]]\n",
    "        L = len(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return deepcopy({\"mask\": mask}), deepcopy({\"mask\": mask})\n",
    "        seq0 = np.array([*seq])\n",
    "        seq = np.zeros(L, dtype=np.int64)\n",
    "        for k in self.seq_map:\n",
    "            seq[seq0 == k] = self.seq_map[k]\n",
    "        seq = torch.from_numpy(seq)\n",
    "\n",
    "        react, react_err = self.data[idx]\n",
    "        data = np.load(self.extra_bpp_path / f\"{idx}.npz\")\n",
    "        ss = torch.from_numpy(data[\"ss_vienna\"].astype(np.float32))\n",
    "        bpp = torch.from_numpy(data[\"bpp_org\"].astype(np.float32))\n",
    "        bpp_extra = [\n",
    "            torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp\n",
    "        ] + [\n",
    "            extra_bpp_from_numpy(\n",
    "                Path(\"../eda/bpp/rnafm\") / f\"{idx}.npy\", L, seq_len=L\n",
    "            )\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0)\n",
    "\n",
    "        seq = F.pad(seq, (0, self.Lmax - L))\n",
    "        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "\n",
    "        if react.shape[0] != self.Lmax:\n",
    "            react = F.pad(react, (0, 0, 0, self.Lmax - react.shape[0]), value=torch.nan)\n",
    "        if react_err.shape[0] != self.Lmax:\n",
    "            react_err = F.pad(\n",
    "                react_err, (0, 0, 0, self.Lmax - react_err.shape[0]), value=torch.nan\n",
    "            )\n",
    "\n",
    "        return deepcopy(\n",
    "            {\n",
    "                \"seq\": seq,\n",
    "                \"mask\": mask,\n",
    "                \"ss_adj\": ss,\n",
    "                \"bb_matrix_full_prob\": bpp,\n",
    "                \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "            }\n",
    "        ), deepcopy(\n",
    "            {\n",
    "                \n",
    "                \"react_ex\": torch.full((self.Lmax, 12), torch.nan),\n",
    "                \"react_ex_err\": torch.full((self.Lmax, 12), torch.nan),\n",
    "                \"react\": react,\n",
    "                \"react_err\": react_err,\n",
    "                \"mask\": mask,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(str(CFG.pl_data), \"rb\") as f: \n",
    "#     data = pickle.load(f)\n",
    "# orig_test_csv = CFG.path/'test_sequences.csv'\n",
    "# train_data = CFG.path/'train_data.parquet'\n",
    "# folds_split = CFG.split_id\n",
    "# ds = RNA_DatasetBaselineSplitssbppV6SAVEDwithFMPSD(data, orig_test_csv, train_data, folds_split, mode='train')\n",
    "\n",
    "# class CFG:\n",
    "#     path = Path(\"../data/\")\n",
    "#     pathbb = Path(\"../data/Ribonanza_bpp_files\")\n",
    "#     pathss = Path(\"../eda/train_ss_vienna_rna.parquet\")\n",
    "#     split_id = Path('../eda/fold_split.csv')\n",
    "#     pl_data = Path('../data/rna_files/final0_PLfolds_ft_tot.pickle')\n",
    "#     bs = 16\n",
    "#     num_workers = 8\n",
    "#     device = 'cpu'\n",
    "#     adjnact_prob = 0.5\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df = pd.read_parquet(CFG.path/'train_data.parquet')\n",
    "# split = pd.read_csv(CFG.split_id)\n",
    "# df = pd.merge(df, split, on='sequence_id')\n",
    "# df_train = df.query('is_train==True').reset_index(drop=True)\n",
    "# df_valid = df.query('is_train==False').reset_index(drop=True)\n",
    "# ds_val = RNA_DatasetBaselineSplitssbppV6SAVEDwithFMFlip(df_valid, mode='train')\n",
    "# ds_val_len = RNA_DatasetBaselineSplitssbppV6SAVEDwithFMFlip(df_valid, mode='train', mask_only=True)\n",
    "# sampler_val = torch.utils.data.SequentialSampler(ds_val_len)\n",
    "# len_sampler_val = LenMatchBatchSampler(sampler_val, batch_size=CFG.bs, \n",
    "#                drop_last=False)\n",
    "# dl_val= DeviceDataLoader(torch.utils.data.DataLoader(ds_val, \n",
    "#                batch_sampler=len_sampler_val, num_workers=CFG.num_workers), CFG.device)\n",
    "# batch = next(iter(dl_val))[0]\n",
    "# torch.save(batch, \"batch_ps.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CFG:\n",
    "#     path = Path(\"../data/\")\n",
    "#     pathbb = Path(\"../data/Ribonanza_bpp_files\")\n",
    "#     pathss = Path(\"../eda/train_ss_vienna_rna.parquet\")\n",
    "#     split_id = Path('../eda/fold_split.csv')\n",
    "#     bs = 16\n",
    "#     num_workers = 8\n",
    "#     device = 'cpu'\n",
    "#     adjnact_prob = 0.5\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# df = pd.read_parquet(CFG.path/'train_data.parquet')\n",
    "# split = pd.read_csv(CFG.split_id)\n",
    "# df = pd.merge(df, split, on='sequence_id')\n",
    "# df_train = df.query('is_train==True').reset_index(drop=True)\n",
    "# df_valid = df.query('is_train==False').reset_index(drop=True)\n",
    "# ds_val = RNA_DatasetBaselineSplitssbppV6SAVEDwithFMFlip(df_valid, mode='train')\n",
    "# ds_val_len = RNA_DatasetBaselineSplitssbppV6SAVEDwithFMFlip(df_valid, mode='train', mask_only=True)\n",
    "# sampler_val = torch.utils.data.SequentialSampler(ds_val_len)\n",
    "# len_sampler_val = LenMatchBatchSampler(sampler_val, batch_size=CFG.bs, \n",
    "#                drop_last=False)\n",
    "# dl_val= DeviceDataLoader(torch.utils.data.DataLoader(ds_val, \n",
    "#                batch_sampler=len_sampler_val, num_workers=CFG.num_workers), CFG.device)\n",
    "# batch = next(iter(dl_val))[0]\n",
    "# torch.save(batch, \"batch_ps.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RNA_Dataset_Test(Dataset):\n",
    "    def __init__(self, df, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask}, {\"ids\": ids}\n",
    "\n",
    "\n",
    "class RNA_Dataset_TestBpp(Dataset):\n",
    "    def __init__(self, df, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = self.df[\"bpp\"][idx]\n",
    "        bpp = (generate_base_pair_matrix(bpp, self.Lmax) > 0.5).int()\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": bpp}, {\n",
    "            \"ids\": ids\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_Dataset_Testss(Dataset):\n",
    "    def __init__(self, df, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "        self.ss = df[\"ss_roi\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = torch.tensor(dot_to_adjacency(self.ss[idx], self.Lmax)).int()\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": bpp}, {\n",
    "            \"ids\": ids\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_Dataset_TestBppSS(Dataset):\n",
    "    def __init__(self, df, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = self.df[\"bpp\"][idx]\n",
    "        bpp = (generate_base_pair_matrix(bpp, self.Lmax) > 0.5).int()\n",
    "        ss_adj = torch.tensor(dot_to_adjacency(self.df[\"ss_roi\"][idx], self.Lmax)).int()\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"adj_matrix\": bpp,\n",
    "            \"ss_adj\": ss_adj,\n",
    "        }, {\"ids\": ids}\n",
    "\n",
    "\n",
    "class RNA_Dataset_TestBppSSFullV0(Dataset):\n",
    "    def __init__(self, df, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = self.df[\"bpp\"][idx]\n",
    "        bb_matrix_full_prob = generate_base_pair_matrixv1(bpp, self.Lmax)\n",
    "        bpp = (bb_matrix_full_prob.clone() > 0.5).int()\n",
    "        ss_adj = torch.tensor(\n",
    "            dot_to_adjacencyv0(self.df[\"ss_full\"][idx], self.Lmax)\n",
    "        ).int()\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"adj_matrix\": bpp,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bb_matrix_full_prob,\n",
    "        }, {\"ids\": ids}\n",
    "\n",
    "\n",
    "class RNA_Dataset_TestBppSSFullV1(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mask_only=False,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = self.df[\"bpp\"][idx]\n",
    "        bpp_ = generate_base_pair_matrixv1(bpp, self.Lmax)\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(self.extra_bpp_path / f\"{i}/{bpp.stem}.npy\", self.Lmax)\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bb_matrix_full_prob = torch.stack([bpp_, *bpp_extra], dim=0).mean(0).float()\n",
    "\n",
    "        bpp = (bb_matrix_full_prob.clone() > 0.5).int()\n",
    "        ss_adj = torch.tensor(\n",
    "            dot_to_adjacencyv0(self.df[\"ss_full\"][idx], self.Lmax)\n",
    "        ).int()\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"adj_matrix\": bpp,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bb_matrix_full_prob,\n",
    "        }, {\"ids\": ids}\n",
    "        \n",
    "        \n",
    "class RNA_Dataset_TestBppSSFullV2(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mask_only=False,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\", \"rnaformer\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = self.df[\"bpp\"][idx]\n",
    "        bpp_ = generate_base_pair_matrixv1(bpp, self.Lmax)\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(self.extra_bpp_path / f\"{i}/{bpp.stem}.npy\", self.Lmax, seq_len=L )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()\n",
    "        bb_matrix_full_prob = bpp_.float()\n",
    "\n",
    "        bpp = (bb_matrix_full_prob.clone() > 0.5).int()\n",
    "        ss_adj = torch.tensor(\n",
    "            dot_to_adjacencyv0(self.df[\"ss_full\"][idx], self.Lmax)\n",
    "        ).int()\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"adj_matrix\": bpp,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bb_matrix_full_prob,\n",
    "            \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "        }, {\"ids\": ids}\n",
    "        \n",
    "class RNA_Dataset_TestBppSSFullV3(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mask_only=False,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"rnafm\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = self.df[\"bpp\"][idx]\n",
    "        bpp_ = generate_base_pair_matrixv1(bpp, self.Lmax)\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(self.extra_bpp_path / f\"{i}/{bpp.stem}.npy\", self.Lmax, seq_len=L )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()\n",
    "        bb_matrix_full_prob = bpp_.float()\n",
    "\n",
    "        bpp = (bb_matrix_full_prob.clone() > 0.5).int()\n",
    "        ss_adj = torch.tensor(\n",
    "            dot_to_adjacencyv0(self.df[\"ss_full\"][idx], self.Lmax)\n",
    "        ).int()\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"adj_matrix\": bpp,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bb_matrix_full_prob,\n",
    "            \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "        }, {\"ids\": ids}\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "class RNA_Dataset_TestBppSSFullV4(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mask_only=False,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"rnafm\", \"vienna_2\", \"contrafold_2\", \"rnaformer\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = self.df[\"bpp\"][idx]\n",
    "        bpp_ = generate_base_pair_matrixv1(bpp, self.Lmax)\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(self.extra_bpp_path / f\"{i}/{bpp.stem}.npy\", self.Lmax, seq_len=L )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()\n",
    "        bb_matrix_full_prob = bpp_.float()\n",
    "\n",
    "        bpp = (bb_matrix_full_prob.clone() > 0.5).int()\n",
    "        ss_adj = torch.tensor(\n",
    "            dot_to_adjacencyv0(self.df[\"ss_full\"][idx], self.Lmax)\n",
    "        ).int()\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"adj_matrix\": bpp,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bb_matrix_full_prob,\n",
    "            \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "        }, {\"ids\": ids}\n",
    "        \n",
    "        \n",
    "class RNA_Dataset_TestBppSSFullV5(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mask_only=False,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\", \"rnaformer\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = self.df[\"bpp\"][idx]\n",
    "        bpp_ = generate_base_pair_matrixv1(bpp, self.Lmax)\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(self.extra_bpp_path / f\"{i}/{bpp.stem}.npy\", self.Lmax, seq_len=L )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()\n",
    "        bb_matrix_full_prob = bpp_.float()\n",
    "\n",
    "        bpp = (bb_matrix_full_prob.clone() > 0.5).int()\n",
    "        ss_adj = torch.tensor(\n",
    "            dot_to_adjacencyv0(self.df[\"ss_full\"][idx], self.Lmax)\n",
    "        ).int()\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"adj_matrix\": bpp,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bb_matrix_full_prob,\n",
    "            \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "        }, {\"ids\": ids}\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "class RNA_Dataset_TestSavedV0(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mask_only=False,\n",
    "        extra_bpp_path=Path(\"../eda/bpp/comb\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\", \"rnaformer\",],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        data = np.load(self.extra_bpp_path/f'{self.df[\"bpp\"][idx].stem}.npz')\n",
    "        \n",
    "        ss =  torch.from_numpy(data['ss_vienna'].astype(np.float32))\n",
    "        bpp = torch.from_numpy(data['bpp_org'].astype(np.float32))\n",
    "        bpp_extra = torch.stack([torch.from_numpy(data[i].astype(np.float32)) for i in self.extra_bpp], dim=0).mean(0)\n",
    "        bpp = F.pad(bpp, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        bpp_extra = F.pad(bpp_extra, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "        ss = F.pad(ss, (0, self.Lmax - L, 0, self.Lmax - L))\n",
    "\n",
    "\n",
    "\n",
    "        return deepcopy({\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"adj_matrix\": bpp,\n",
    "            \"ss_adj\": ss,\n",
    "            \"bb_matrix_full_prob\": bpp,\n",
    "            \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "        }), deepcopy({\"ids\": ids})\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CFG:\n",
    "#     path = Path(\"../data/\")\n",
    "#     pathbb = Path(\"../data/Ribonanza_bpp_files\")\n",
    "#     pathss = Path(\"../eda/train_ss_vienna_rna.parquet\")\n",
    "#     split_id = Path('../eda/fold_split.csv')\n",
    "    \n",
    "# fns = list(CFG.pathbb.rglob(\"*.txt\"))\n",
    "# bpp_df = pd.DataFrame({\"bpp\": fns})\n",
    "# bpp_df['sequence_id'] = bpp_df['bpp'].apply(lambda x: x.stem)\n",
    "# bpp_df.drop_duplicates(subset = 'sequence_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([pd.read_parquet('../eda/train_ss_vienna_rna.parquet'),\n",
    "#                 pd.read_parquet('../eda/test_ss_vienna_rna.parquet')])\n",
    "# df = df.drop_duplicates(subset=['sequence_id']).reset_index(drop=True)\n",
    "# df = pd.merge(df, bpp_df, on='sequence_id')\n",
    "# df['L'] = df['sequence'].apply(len)\n",
    "# extra_bpp=[\"vienna_2\", \"contrafold_2\", \"rnaformerv1\", \"rnaformer\"]\n",
    "# extra_bpp_path=Path(\"../eda/bpp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# idx = 89\n",
    "# row = df.iloc[idx]\n",
    "# names = ['vienna_2', 'contrafold_2', 'rnaformerv1', \"rnaformer\", 'bpp_org', 'ss_vienna']\n",
    "# bpp_extra = [\n",
    "#             extra_bpp_from_numpy(extra_bpp_path / f\"{i}/{row.bpp.stem}.npy\", row.L, seq_len=row.L).numpy()\n",
    "#             for i in extra_bpp\n",
    "#         ] + [generate_base_pair_matrixv1(row['bpp'], row.L).numpy().astype(np.float16)] + [dot_to_adjacencyv0(row[\"ss_full\"], row.L)]\n",
    "# bpp_extra_d = {s : np.triu(d).astype(np.float16) for s,d in zip(names,bpp_extra)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot\n",
    "# fig, axs = plt.subplots(2,3, figsize=(15,10))\n",
    "# for i, ax in enumerate(axs.flatten()):\n",
    "#     ax.imshow(bpp_extra_d[names[i]])\n",
    "#     ax.set_title(names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(names)):\n",
    "#     print(names[i], np.all(np.maximum(bpp_extra_d[names[i]],bpp_extra_d[names[i]].T) == bpp_extra[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00_dataset.ipynb\t   01_models_graph.ipynb  03_models_exp.ipynb  test.pt\n",
      "00_generating_split.ipynb  01_modelsconv.ipynb\t  batch.pt\n",
      "01_models.ipynb\t\t   02_utils.ipynb\t  batch_ps.pt\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #function that reads csv and convert to paraquet\n",
    "# def convert_csv_to_parquet(path, out_path):\n",
    "#     df = pd.read_csv(path)\n",
    "#     df.to_parquet(out_path,  index=False)\n",
    "    \n",
    "# convert_csv_to_parquet('../train_data.csv', '../data/train_corrected.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
