{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.data import Data, DataLoader, Batch\n",
    "import torch\n",
    "import seaborn as sbn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def good_luck():\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |export \n",
    "class LenMatchBatchSampler(torch.utils.data.BatchSampler):\n",
    "    def __iter__(self):\n",
    "        buckets = [[]] * 100\n",
    "        yielded = 0\n",
    "\n",
    "        for idx in self.sampler:\n",
    "            s = self.sampler.data_source[idx]\n",
    "            if isinstance(s,tuple): L = s[0][\"mask\"].sum()\n",
    "            else: L = s[\"mask\"].sum()\n",
    "            L = max(1,L // 16) \n",
    "            if len(buckets[L]) == 0:  buckets[L] = []\n",
    "            buckets[L].append(idx)\n",
    "            \n",
    "            if len(buckets[L]) == self.batch_size:\n",
    "                batch = list(buckets[L])\n",
    "                yield batch\n",
    "                yielded += 1\n",
    "                buckets[L] = []\n",
    "                \n",
    "        batch = []\n",
    "        leftover = [idx for bucket in buckets for idx in bucket]\n",
    "\n",
    "        for idx in leftover:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yielded += 1\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yielded += 1\n",
    "            yield batch\n",
    "            \n",
    "def dict_to(x, device='cuda'):\n",
    "    return {k:x[k].to(device) for k in x}\n",
    "\n",
    "def to_device(x, device='cuda'):\n",
    "    return tuple(dict_to(e,device) for e in x)\n",
    "\n",
    "class DeviceDataLoader:\n",
    "    def __init__(self, dataloader, device='cuda'):\n",
    "        self.dataloader = dataloader\n",
    "        self.device = device\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataloader)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for batch in self.dataloader:\n",
    "            yield tuple(dict_to(x, self.device) for x in batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# |export\n",
    "def encode_rna_sequence(seq):\n",
    "    L = len(seq)\n",
    "\n",
    "    # Initialize the tensor with zeros\n",
    "    tensor = np.zeros((L, L, 8))\n",
    "\n",
    "    # Define valid base pairs\n",
    "    valid_pairs = [\n",
    "        (\"A\", \"U\"),\n",
    "        (\"U\", \"A\"),\n",
    "        (\"U\", \"G\"),\n",
    "        (\"G\", \"U\"),\n",
    "        (\"G\", \"C\"),\n",
    "        (\"C\", \"G\"),\n",
    "    ]\n",
    "\n",
    "    for i in range(L):\n",
    "        for j in range(L):\n",
    "            # Check for valid base pairs\n",
    "            if (seq[i], seq[j]) in valid_pairs:\n",
    "                channel = valid_pairs.index((seq[i], seq[j]))\n",
    "                tensor[i, j, channel] = 1\n",
    "            # Check for diagonal\n",
    "            elif i == j:\n",
    "                tensor[i, j, 6] = 1\n",
    "            # If not a valid pair and not on the diagonal, set the last channel\n",
    "            else:\n",
    "                tensor[i, j, 7] = 1\n",
    "\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def generate_edge_data(file_path):\n",
    "    # Read the file into a DataFrame\n",
    "    data = pd.read_csv(file_path, sep=\" \", header=None, names=[\"pos1\", \"pos2\", \"prob\"])\n",
    "\n",
    "    # Convert the pos1 and pos2 columns to 0-based indices and then to a tensor for edge index\n",
    "    edge_index = torch.tensor(\n",
    "        [data[\"pos1\"].values - 1, data[\"pos2\"].values - 1], dtype=torch.long\n",
    "    )\n",
    "\n",
    "    # Convert the prob column to a tensor for edge features\n",
    "    edge_features = torch.tensor(data[\"prob\"].values, dtype=torch.float).unsqueeze(\n",
    "        1\n",
    "    )  # Adding an extra dimension\n",
    "\n",
    "    return edge_index, edge_features\n",
    "\n",
    "\n",
    "class RNA_DatasetBaseline(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"]\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"]\n",
    "\n",
    "        split = list(\n",
    "            KFold(n_splits=nfolds, random_state=seed, shuffle=True).split(df_2A3)\n",
    "        )[fold][0 if mode == \"train\" else 1]\n",
    "        df_2A3 = df_2A3.iloc[split].reset_index(drop=True)\n",
    "        df_DMS = df_DMS.iloc[split].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplit(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetBaseline(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"]\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"]\n",
    "\n",
    "        split = list(\n",
    "            KFold(n_splits=nfolds, random_state=seed, shuffle=True).split(df_2A3)\n",
    "        )[fold][0 if mode == \"train\" else 1]\n",
    "        df_2A3 = df_2A3.iloc[split].reset_index(drop=True)\n",
    "        df_DMS = df_DMS.iloc[split].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetV0(Dataset):\n",
    "    def __init__(self, df, mask_only=False, prob_for_adj=0.5, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        self.prob_for_adj = prob_for_adj\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        adj_matrix = generate_adj_matrix(self.bpp[idx], self.Lmax, self.prob_for_adj)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": adj_matrix}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetV1(Dataset):\n",
    "    # same as v0 but not adj matrix\n",
    "    def __init__(self, df, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetV0G(Dataset):\n",
    "    def __init__(self, df, path_to_bpp_folder, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        edge_index, edge_features = generate_edge_data(self.bpp[idx])\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        return Data(\n",
    "            x=torch.from_numpy(seq),\n",
    "            edge_index=edge_index,\n",
    "            edge_features=edge_features,\n",
    "            y=react,\n",
    "            y_err=react_err,\n",
    "        )\n",
    "\n",
    "\n",
    "class LenMatchBatchSampler(torch.utils.data.BatchSampler):\n",
    "    def __iter__(self):\n",
    "        buckets = [[]] * 100\n",
    "        yielded = 0\n",
    "\n",
    "        for idx in self.sampler:\n",
    "            s = self.sampler.data_source[idx]\n",
    "            if isinstance(s, tuple):\n",
    "                L = s[0][\"mask\"].sum()\n",
    "            else:\n",
    "                L = s[\"mask\"].sum()\n",
    "            L = max(1, L // 16)\n",
    "            if len(buckets[L]) == 0:\n",
    "                buckets[L] = []\n",
    "            buckets[L].append(idx)\n",
    "\n",
    "            if len(buckets[L]) == self.batch_size:\n",
    "                batch = list(buckets[L])\n",
    "                yield batch\n",
    "                yielded += 1\n",
    "                buckets[L] = []\n",
    "\n",
    "        batch = []\n",
    "        leftover = [idx for bucket in buckets for idx in bucket]\n",
    "\n",
    "        for idx in leftover:\n",
    "            batch.append(idx)\n",
    "            if len(batch) == self.batch_size:\n",
    "                yielded += 1\n",
    "                yield batch\n",
    "                batch = []\n",
    "\n",
    "        if len(batch) > 0 and not self.drop_last:\n",
    "            yielded += 1\n",
    "            yield batch\n",
    "\n",
    "\n",
    "def generate_base_pair_matrix(file_path, L):\n",
    "    \"\"\"\n",
    "    Reads a TXT file of base pair probabilities and generates an n x n matrix.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the TXT file.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: An n x n matrix of base pair probabilities.\n",
    "    \"\"\"\n",
    "    # Read the data using pandas\n",
    "    data = pd.read_csv(file_path, sep=\" \", header=None, names=[\"pos1\", \"pos2\", \"prob\"])\n",
    "\n",
    "    # Find the largest position in the 'pos1' column\n",
    "    largest_position = data[\"pos1\"].max()\n",
    "\n",
    "    ids = torch.from_numpy(data[[\"pos1\", \"pos2\"]].values)\n",
    "    matrix = torch.zeros((L, L))\n",
    "    matrix[ids[:, 0] - 1, ids[:, 1] - 1] = torch.from_numpy(data[\"prob\"].values).float()\n",
    "    matrix[ids[:, 1] - 1, ids[:, 0] - 1] = torch.from_numpy(data[\"prob\"].values).float()\n",
    "\n",
    "    matrix[:26, :] = 0\n",
    "    matrix[:, :26] = 0\n",
    "\n",
    "    # Adjust the end based on the largest_position and set the last 21 positions to 0\n",
    "    adjusted_end = largest_position - 21\n",
    "    matrix[adjusted_end:, :] = 0\n",
    "    matrix[:, adjusted_end:] = 0\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitbppV0(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        bpp = (generate_base_pair_matrix(self.bpp[idx], self.Lmax) > 0.5).int()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": bpp}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "def generate_base_pair_matrixv1(file_path, L):\n",
    "    \"\"\"\n",
    "    Reads a TXT file of base pair probabilities and generates an n x n matrix.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the TXT file.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: An n x n matrix of base pair probabilities.\n",
    "    \"\"\"\n",
    "    # Read the data using pandas\n",
    "    data = pd.read_csv(file_path, sep=\" \", header=None, names=[\"pos1\", \"pos2\", \"prob\"])\n",
    "\n",
    "    # Find the largest position in the 'pos1' column\n",
    "    largest_position = data[\"pos1\"].max()\n",
    "\n",
    "    ids = torch.from_numpy(data[[\"pos1\", \"pos2\"]].values)\n",
    "    matrix = torch.zeros((L, L))\n",
    "    matrix[ids[:, 0] - 1, ids[:, 1] - 1] = torch.from_numpy(data[\"prob\"].values).float()\n",
    "    matrix[ids[:, 1] - 1, ids[:, 0] - 1] = torch.from_numpy(data[\"prob\"].values).float()\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitbppV1(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        bpp = (generate_base_pair_matrixv1(self.bpp[idx], self.Lmax) > 0.5).int()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": bpp}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "def dot_to_adjacency(dot_notation, n):\n",
    "    adjacency_matrix = np.zeros((n, n), dtype=int)\n",
    "    dot_notation = (26 * \".\") + dot_notation + (21 * \".\")\n",
    "    stack = []\n",
    "    for i, char in enumerate(dot_notation):\n",
    "        if char == \"(\":\n",
    "            stack.append(i)\n",
    "        elif char == \")\":\n",
    "            j = stack.pop()\n",
    "            adjacency_matrix[i][j] = adjacency_matrix[j][i] = 1\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssV0(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_roi\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        bpp = torch.tensor(dot_to_adjacency(self.ss[idx], self.Lmax)).int()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": bpp}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssV0(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_roi\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        bpp = torch.tensor(dot_to_adjacency(self.ss[idx], self.Lmax)).int()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": bpp}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssV1(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.ss_map = {\".\": 0, \"(\": 1, \")\": 2}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "\n",
    "        ss_seq = [self.ss_map[s] for s in self.ss[idx]]\n",
    "        ss_seq = np.array(ss_seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_seq = np.pad(ss_seq, (0, self.Lmax - len(ss_seq)))\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_seq\": torch.from_numpy(ss_seq),\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitbppV2(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax)\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"bpp\": bpp}, {\n",
    "            \"react\": react,\n",
    "            \"react_err\": react_err,\n",
    "            \"sn\": sn,\n",
    "            \"mask\": mask,\n",
    "        }\n",
    "\n",
    "\n",
    "def dot_to_adjacencyv0(dot_notation, n):\n",
    "    adjacency_matrix = np.zeros((n, n), dtype=int)\n",
    "    stack = []\n",
    "    for i, char in enumerate(dot_notation):\n",
    "        if char == \"(\":\n",
    "            stack.append(i)\n",
    "        elif char == \")\":\n",
    "            j = stack.pop()\n",
    "            adjacency_matrix[i][j] = adjacency_matrix[j][i] = 1\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV0(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = (generate_base_pair_matrixv1(self.bpp[idx], self.Lmax) > 0.5).int()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"adj_matrix\": bpp,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV1(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax)\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bpp,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "\n",
    "def load_rnafm(filename, seq_len, L_max):\n",
    "    \"\"\"\n",
    "    Load data from a .npy file and convert it to an N x N matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: Path to the .npy file.\n",
    "    - N: Dimension of the square matrix.\n",
    "\n",
    "    Returns:\n",
    "    - bpp_matrix: N x N matrix reconstructed from the input file.\n",
    "    \"\"\"\n",
    "    # Load the structured array from the .npy file\n",
    "    data = np.load(filename)\n",
    "\n",
    "    # Create an empty N x N matrix\n",
    "    bpp_matrix = np.zeros((seq_len, seq_len))\n",
    "\n",
    "    # Fill the matrix with the probabilities from the loaded data\n",
    "    bpp_matrix[data['pos_1'], data['pos_2']] = data['probabilities']\n",
    "    \n",
    "    bpp_matrix = bpp_matrix + bpp_matrix.T - np.diag(np.diag(bpp_matrix))\n",
    "    full = np.zeros((L_max, L_max))\n",
    "    full[:seq_len, :seq_len] = bpp_matrix\n",
    "    return torch.tensor(full)\n",
    "\n",
    "\n",
    "def extra_bpp_from_numpy(filename, N, seq_len=None):\n",
    "    \"\"\"\n",
    "    Load data from a .npy file and convert it to an N x N matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: Path to the .npy file.\n",
    "    - N: Dimension of the square matrix.\n",
    "\n",
    "    Returns:\n",
    "    - bpp_matrix: N x N matrix reconstructed from the input file.\n",
    "    \"\"\"\n",
    "    # Load the structured array from the .npy file\n",
    "    if filename.parent.stem == 'rnafm':\n",
    "        full =load_rnafm(filename, seq_len, N)\n",
    "    else:\n",
    "        data = np.load(filename)\n",
    "        # Create an empty N x N matrix\n",
    "        bpp_matrix = np.zeros((N, N))\n",
    "        # Fill the matrix with the probabilities from the loaded data\n",
    "        bpp_matrix[data[\"pos_1\"], data[\"pos_2\"]] = data[\"probabilities\"]\n",
    "        full = torch.tensor(bpp_matrix)\n",
    "\n",
    "    return full\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV1R(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"rnafm\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        \n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax)\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(\n",
    "                self.extra_bpp_path / f\"{i}/{self.bpp[idx].stem}.npy\", self.Lmax, seq_len=len(self.seq[idx])\n",
    "            )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp = torch.stack([*bpp_extra, bpp], dim=0).mean(0).float()\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bpp,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV2(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax)\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(\n",
    "                self.extra_bpp_path / f\"{i}/{self.bpp[idx].stem}.npy\", self.Lmax\n",
    "            )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp = torch.stack([bpp, *bpp_extra], dim=0).mean(0).float()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bpp,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "        \n",
    "        \n",
    "class RNA_DatasetBaselineSplitssbppV3(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\", \"rnaformer\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax).float()\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(\n",
    "                self.extra_bpp_path / f\"{i}/{self.bpp[idx].stem}.npy\", self.Lmax, seq_len=len(self.seq[idx])\n",
    "            )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bpp,\n",
    "            \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineSplitssbppV4(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"rnafm\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = np.pad(seq, (0, self.Lmax - len(seq)))\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax).float()\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(\n",
    "                self.extra_bpp_path / f\"{i}/{self.bpp[idx].stem}.npy\", self.Lmax, seq_len=len(self.seq[idx])\n",
    "            )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bpp,\n",
    "            \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}\n",
    "\n",
    "\n",
    "class RNA_DatasetBaselineFM(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mode=\"train\",\n",
    "        seed=2023,\n",
    "        fold=0,\n",
    "        nfolds=4,\n",
    "        mask_only=False,\n",
    "        sn_train=True,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        short sequence without adapters\n",
    "        \"\"\"\n",
    "        self.seq_map = {\"S\": 0, \"E\": 2, \"A\": 4, \"U\": 7, \"C\": 5, \"G\": 6}\n",
    "        self.Lmax = 206\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        df_2A3 = df.loc[df.experiment_type == \"2A3_MaP\"].reset_index(drop=True)\n",
    "        df_DMS = df.loc[df.experiment_type == \"DMS_MaP\"].reset_index(drop=True)\n",
    "\n",
    "        if mode != \"train\" or sn_train:\n",
    "            m = (df_2A3[\"SN_filter\"].values > 0) & (df_DMS[\"SN_filter\"].values > 0)\n",
    "            df_2A3 = df_2A3.loc[m].reset_index(drop=True)\n",
    "            df_DMS = df_DMS.loc[m].reset_index(drop=True)\n",
    "\n",
    "        self.bpp = df_2A3[\"bpp\"].values\n",
    "        self.seq = df_2A3[\"sequence\"].values\n",
    "        self.ss = df_2A3[\"ss_full\"].values\n",
    "        self.L = df_2A3[\"L\"].values\n",
    "        self.react_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_2A3 = df_2A3[\n",
    "            [c for c in df_2A3.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.react_err_DMS = df_DMS[\n",
    "            [c for c in df_DMS.columns if \"reactivity_error_0\" in c]\n",
    "        ].values\n",
    "        self.sn_2A3 = df_2A3[\"signal_to_noise\"].values\n",
    "        self.sn_DMS = df_DMS[\"signal_to_noise\"].values\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.seq)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.seq[idx]\n",
    "        if self.mask_only:\n",
    "            mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "            mask[: len(seq)] = True\n",
    "            return {\"mask\": mask}, {\"mask\": mask}\n",
    "\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        mask[: len(seq)] = True\n",
    "        seq = [self.seq_map[s] for s in \"S\" + seq + \"E\"]\n",
    "        seq = np.array(seq)\n",
    "        seq_holder = np.ones(self.Lmax + 2, dtype=int)\n",
    "        seq_holder[: len(seq)] = seq\n",
    "\n",
    "        ss_adj = torch.tensor(dot_to_adjacencyv0(self.ss[idx], self.Lmax)).int()\n",
    "        bpp = generate_base_pair_matrixv1(self.bpp[idx], self.Lmax).float()\n",
    "\n",
    "        react = torch.from_numpy(\n",
    "            np.stack([self.react_2A3[idx], self.react_DMS[idx]], -1)\n",
    "        )\n",
    "        react_err = torch.from_numpy(\n",
    "            np.stack([self.react_err_2A3[idx], self.react_err_DMS[idx]], -1)\n",
    "        )\n",
    "        sn = torch.FloatTensor([self.sn_2A3[idx], self.sn_DMS[idx]])\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq_holder),\n",
    "            \"mask\": mask,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bpp,\n",
    "        }, {\"react\": react, \"react_err\": react_err, \"sn\": sn, \"mask\": mask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CFG:\n",
    "#     path = Path(\"../data/\")\n",
    "#     pathbb = Path(\"../data/Ribonanza_bpp_files\")\n",
    "#     pathss = Path(\"../eda/train_ss_vienna_rna.parquet\")\n",
    "#     split_id = Path('../eda/fold_split.csv')\n",
    "#     bs = 16\n",
    "#     num_workers = 8\n",
    "#     device = 'cpu'\n",
    "#     adjnact_prob = 0.5\n",
    "    \n",
    "\n",
    "\n",
    "# fns = list(CFG.pathbb.rglob(\"*.txt\"))\n",
    "# bpp_df = pd.DataFrame({\"bpp\": fns})\n",
    "# bpp_df['sequence_id'] = bpp_df['bpp'].apply(lambda x: x.stem)\n",
    "# ss = pd.read_parquet(CFG.pathss)[[\"sequence_id\", \"ss_full\"]]\n",
    "# df = pd.read_parquet(CFG.path/'train_data.parquet')\n",
    "# split = pd.read_csv(CFG.split_id)\n",
    "# df = pd.merge(df, split, on='sequence_id')\n",
    "# df = pd.merge(df, bpp_df, on='sequence_id')\n",
    "# df = pd.merge(df, ss, on='sequence_id')\n",
    "# df_train = df.query('is_train==True').reset_index(drop=True)\n",
    "# df_valid = df.query('is_train==False').reset_index(drop=True)\n",
    "# ds_val = RNA_DatasetBaselineSplitssbppV1R(df_valid, mode='eval', extra_bpp=[\"rnafm\"])\n",
    "# ds_val_len = RNA_DatasetBaselineSplitssbppV1R(df_valid, mode='eval', mask_only=True)\n",
    "# sampler_val = torch.utils.data.SequentialSampler(ds_val_len)\n",
    "# len_sampler_val = LenMatchBatchSampler(sampler_val, batch_size=CFG.bs, \n",
    "#                drop_last=False)\n",
    "# dl_val= DeviceDataLoader(torch.utils.data.DataLoader(ds_val, \n",
    "#                batch_sampler=len_sampler_val, num_workers=CFG.num_workers), CFG.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class RNA_Dataset_Test(Dataset):\n",
    "    def __init__(self, df, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask}, {\"ids\": ids}\n",
    "\n",
    "\n",
    "class RNA_Dataset_TestBpp(Dataset):\n",
    "    def __init__(self, df, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = self.df[\"bpp\"][idx]\n",
    "        bpp = (generate_base_pair_matrix(bpp, self.Lmax) > 0.5).int()\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": bpp}, {\n",
    "            \"ids\": ids\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_Dataset_Testss(Dataset):\n",
    "    def __init__(self, df, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "        self.ss = df[\"ss_roi\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = torch.tensor(dot_to_adjacency(self.ss[idx], self.Lmax)).int()\n",
    "\n",
    "        return {\"seq\": torch.from_numpy(seq), \"mask\": mask, \"adj_matrix\": bpp}, {\n",
    "            \"ids\": ids\n",
    "        }\n",
    "\n",
    "\n",
    "class RNA_Dataset_TestBppSS(Dataset):\n",
    "    def __init__(self, df, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = self.df[\"bpp\"][idx]\n",
    "        bpp = (generate_base_pair_matrix(bpp, self.Lmax) > 0.5).int()\n",
    "        ss_adj = torch.tensor(dot_to_adjacency(self.df[\"ss_roi\"][idx], self.Lmax)).int()\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"adj_matrix\": bpp,\n",
    "            \"ss_adj\": ss_adj,\n",
    "        }, {\"ids\": ids}\n",
    "\n",
    "\n",
    "class RNA_Dataset_TestBppSSFullV0(Dataset):\n",
    "    def __init__(self, df, mask_only=False, **kwargs):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = self.df[\"bpp\"][idx]\n",
    "        bb_matrix_full_prob = generate_base_pair_matrixv1(bpp, self.Lmax)\n",
    "        bpp = (bb_matrix_full_prob.clone() > 0.5).int()\n",
    "        ss_adj = torch.tensor(\n",
    "            dot_to_adjacencyv0(self.df[\"ss_full\"][idx], self.Lmax)\n",
    "        ).int()\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"adj_matrix\": bpp,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bb_matrix_full_prob,\n",
    "        }, {\"ids\": ids}\n",
    "\n",
    "\n",
    "class RNA_Dataset_TestBppSSFullV1(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mask_only=False,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = self.df[\"bpp\"][idx]\n",
    "        bpp_ = generate_base_pair_matrixv1(bpp, self.Lmax)\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(self.extra_bpp_path / f\"{i}/{bpp.stem}.npy\", self.Lmax)\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bb_matrix_full_prob = torch.stack([bpp_, *bpp_extra], dim=0).mean(0).float()\n",
    "\n",
    "        bpp = (bb_matrix_full_prob.clone() > 0.5).int()\n",
    "        ss_adj = torch.tensor(\n",
    "            dot_to_adjacencyv0(self.df[\"ss_full\"][idx], self.Lmax)\n",
    "        ).int()\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"adj_matrix\": bpp,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bb_matrix_full_prob,\n",
    "        }, {\"ids\": ids}\n",
    "        \n",
    "        \n",
    "class RNA_Dataset_TestBppSSFullV2(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,\n",
    "        mask_only=False,\n",
    "        extra_bpp_path=Path(\"../eda/bpp\"),\n",
    "        extra_bpp=[\"vienna_2\", \"contrafold_2\", \"rnaformer\"],\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.seq_map = {\"A\": 0, \"C\": 1, \"G\": 2, \"U\": 3}\n",
    "        df[\"L\"] = df.sequence.apply(len)\n",
    "        self.Lmax = df[\"L\"].max()\n",
    "        self.df = df\n",
    "        self.mask_only = mask_only\n",
    "        self.extra_bpp = extra_bpp\n",
    "        self.extra_bpp_path = extra_bpp_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id_min, id_max, seq = self.df.loc[idx, [\"id_min\", \"id_max\", \"sequence\"]]\n",
    "        mask = torch.zeros(self.Lmax, dtype=torch.bool)\n",
    "        L = len(seq)\n",
    "        mask[:L] = True\n",
    "        if self.mask_only:\n",
    "            return {\"mask\": mask}, {}\n",
    "        ids = np.arange(id_min, id_max + 1)\n",
    "        seq = [self.seq_map[s] for s in seq]\n",
    "        seq = np.array(seq)\n",
    "        seq = np.pad(seq, (0, self.Lmax - L))\n",
    "        ids = np.pad(ids, (0, self.Lmax - L), constant_values=-1)\n",
    "        bpp = self.df[\"bpp\"][idx]\n",
    "        bpp_ = generate_base_pair_matrixv1(bpp, self.Lmax)\n",
    "        bpp_extra = [\n",
    "            extra_bpp_from_numpy(self.extra_bpp_path / f\"{i}/{bpp.stem}.npy\", self.Lmax, seq_len=L )\n",
    "            for i in self.extra_bpp\n",
    "        ]\n",
    "        bpp_extra = torch.stack([*bpp_extra], dim=0).mean(0).float()\n",
    "        bb_matrix_full_prob = bpp_.float()\n",
    "\n",
    "        bpp = (bb_matrix_full_prob.clone() > 0.5).int()\n",
    "        ss_adj = torch.tensor(\n",
    "            dot_to_adjacencyv0(self.df[\"ss_full\"][idx], self.Lmax)\n",
    "        ).int()\n",
    "\n",
    "        return {\n",
    "            \"seq\": torch.from_numpy(seq),\n",
    "            \"mask\": mask,\n",
    "            \"adj_matrix\": bpp,\n",
    "            \"ss_adj\": ss_adj,\n",
    "            \"bb_matrix_full_prob\": bb_matrix_full_prob,\n",
    "            \"bb_matrix_full_prob_extra\": bpp_extra,\n",
    "        }, {\"ids\": ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = list(Path('../data/supplementary_silico_predictions/').glob('*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70064/2976445033.py:1: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  pd.read_csv(fns[0])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rowID</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>body</th>\n",
       "      <th>sequence</th>\n",
       "      <th>title</th>\n",
       "      <th>vienna2_mfe</th>\n",
       "      <th>vienna2_time</th>\n",
       "      <th>contrafold2_mfe</th>\n",
       "      <th>contrafold2_time</th>\n",
       "      <th>...</th>\n",
       "      <th>nupack[threshknot]</th>\n",
       "      <th>nupack[threshknot]_time</th>\n",
       "      <th>nupack[hungarian]</th>\n",
       "      <th>nupack[hungarian]_time</th>\n",
       "      <th>nupack-pk[threshknot]</th>\n",
       "      <th>nupack-pk[threshknot]_time</th>\n",
       "      <th>nupack-pk[hungarian]</th>\n",
       "      <th>nupack-pk[hungarian]_time</th>\n",
       "      <th>shapify-hfold</th>\n",
       "      <th>shapify-hfold_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11844837</td>\n",
       "      <td>Merida</td>\n",
       "      <td>Modified previous design</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGGAGAGUUUAGUAAAAUAUA...</td>\n",
       "      <td>No sock</td>\n",
       "      <td>.....((((((.....)))))).........((((........(((...</td>\n",
       "      <td>0.388069</td>\n",
       "      <td>.....((((((.....)))))).....................(((...</td>\n",
       "      <td>0.241375</td>\n",
       "      <td>...</td>\n",
       "      <td>.....((((((.....)))))).....................(((...</td>\n",
       "      <td>1.346570</td>\n",
       "      <td>.....((((((.....)))))).....................(((...</td>\n",
       "      <td>1.085448</td>\n",
       "      <td>.....((((((.....)))))).....................(((...</td>\n",
       "      <td>1392.271822</td>\n",
       "      <td>.....((((((.....))))))......................((...</td>\n",
       "      <td>1392.013173</td>\n",
       "      <td>.....[[[[[[.....]]]]]].......[[[..[[[[[....[[[...</td>\n",
       "      <td>30.332876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11844835</td>\n",
       "      <td>Merida</td>\n",
       "      <td>Modified previous design</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGGAGAGUUUAGUAAAAUAUA...</td>\n",
       "      <td>Windsock 8</td>\n",
       "      <td>.....((((((.....)))))).........((((..............</td>\n",
       "      <td>0.088197</td>\n",
       "      <td>.....((((((.....))))))...................(((.....</td>\n",
       "      <td>0.172300</td>\n",
       "      <td>...</td>\n",
       "      <td>.....((((((.....)))))).....................(((...</td>\n",
       "      <td>1.237194</td>\n",
       "      <td>.....((((((.....))))))...........................</td>\n",
       "      <td>0.978989</td>\n",
       "      <td>.....((((((.....))))))......................((...</td>\n",
       "      <td>1270.632311</td>\n",
       "      <td>.....((((((.....))))))...........................</td>\n",
       "      <td>1270.416410</td>\n",
       "      <td>.....[[[[[[.....]]]]]]...........................</td>\n",
       "      <td>29.568014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11844833</td>\n",
       "      <td>Merida</td>\n",
       "      <td>Modified previous design</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGGAGAGGAAAGUAAAAUAUA...</td>\n",
       "      <td>Windsock 7</td>\n",
       "      <td>.....((((((.....)))))).....((((((((..............</td>\n",
       "      <td>0.074533</td>\n",
       "      <td>.....((((((.....)))))).....((((((((..............</td>\n",
       "      <td>0.113422</td>\n",
       "      <td>...</td>\n",
       "      <td>.....((((((.....)))))).....((((((((..............</td>\n",
       "      <td>1.307606</td>\n",
       "      <td>.....((((((.....)))))).....((((((((..............</td>\n",
       "      <td>1.016065</td>\n",
       "      <td>.....((((((.....)))))).....((((((((..............</td>\n",
       "      <td>1323.665772</td>\n",
       "      <td>.....((((((.....)))))).....((((((((..............</td>\n",
       "      <td>1323.332391</td>\n",
       "      <td>.....[[[[[[.....]]]]]].....((((((((.....[[[[[....</td>\n",
       "      <td>27.488272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11844831</td>\n",
       "      <td>Merida</td>\n",
       "      <td>Modified previous design</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGGAGAGGAAAGUACAAUAUA...</td>\n",
       "      <td>Windsock 6</td>\n",
       "      <td>.....((((((.....)))))).....((((((((..............</td>\n",
       "      <td>0.076538</td>\n",
       "      <td>.....((((((.....)))))).....((((((((.(((((((......</td>\n",
       "      <td>0.109473</td>\n",
       "      <td>...</td>\n",
       "      <td>.....((((((.....)))))).....((((((((..(((...(((...</td>\n",
       "      <td>1.524313</td>\n",
       "      <td>.....((((((.....)))))).....((((((((..(((...(((...</td>\n",
       "      <td>1.239788</td>\n",
       "      <td>.....((((((.....)))))).....((((((((...[[[[[[.....</td>\n",
       "      <td>1296.099273</td>\n",
       "      <td>.....((((((.....)))))).....((((((((...[[[[[[.....</td>\n",
       "      <td>1295.817735</td>\n",
       "      <td>.....[[[[[[.....]]]]]].....((((((((...[[[[[[[....</td>\n",
       "      <td>25.737695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11844829</td>\n",
       "      <td>amybarish</td>\n",
       "      <td>https://www.ncbi.nlm.nih.gov/nuccore/NC_00220...</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAUCUUGGAGAUUUCAAAACCA...</td>\n",
       "      <td>Influenza B virus (B/Lee/1940) segment 2 2121...</td>\n",
       "      <td>.....((((((.....))))))....((((((((.((((((..((....</td>\n",
       "      <td>0.061118</td>\n",
       "      <td>.....((((((.....))))))....((.....))((((((..((....</td>\n",
       "      <td>0.089928</td>\n",
       "      <td>...</td>\n",
       "      <td>.....((((((.....))))))....((((((((.((((((..((....</td>\n",
       "      <td>1.324285</td>\n",
       "      <td>.....((((((.....))))))....((((((...((((((..((....</td>\n",
       "      <td>1.034621</td>\n",
       "      <td>.....((((((.....)))))).............((((((..((....</td>\n",
       "      <td>1089.907709</td>\n",
       "      <td>.....((((((.....)))))).............((((((..((....</td>\n",
       "      <td>1089.612172</td>\n",
       "      <td>[[...[[[[[[.....]]]]]]....[[[[[[...[[[[[[..[[....</td>\n",
       "      <td>21.801687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>119995</td>\n",
       "      <td>RF03087:ROOL_RNA:URS0000D6A43E_12908/1-580:51-150</td>\n",
       "      <td>Eterna</td>\n",
       "      <td>title = RF03087:ROOL RNA:URS0000D6A43E_12908/1...</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAUUUCCGUAAAUUGCCUGUAA...</td>\n",
       "      <td>RF03087:ROOL RNA:URS0000D6A43E_12908/1-580:51-150</td>\n",
       "      <td>(((((((((((.....))))))....))))).......((((.......</td>\n",
       "      <td>0.101556</td>\n",
       "      <td>(((((((((((.....))))))....)))))..................</td>\n",
       "      <td>0.086174</td>\n",
       "      <td>...</td>\n",
       "      <td>(((((((((((.....))))))....))))).....((((((.......</td>\n",
       "      <td>1.192680</td>\n",
       "      <td>(((((((((((.....))))))....))))).....((((((.......</td>\n",
       "      <td>0.945760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.[[[[[[[[[[.....]]]]]].....]]]].....((((((.......</td>\n",
       "      <td>23.977213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>119996</td>\n",
       "      <td>RF03087:ROOL_RNA:URS0000D6A43E_12908/1-580:61-160</td>\n",
       "      <td>Eterna</td>\n",
       "      <td>title = RF03087:ROOL RNA:URS0000D6A43E_12908/1...</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAUUGCCUGUAAGUCAGAUAAG...</td>\n",
       "      <td>RF03087:ROOL RNA:URS0000D6A43E_12908/1-580:61-160</td>\n",
       "      <td>((.((((((((.....))))))....)).))....((((((((..(...</td>\n",
       "      <td>0.171337</td>\n",
       "      <td>.....((((((.....))))))............(((((((((..(...</td>\n",
       "      <td>0.106900</td>\n",
       "      <td>...</td>\n",
       "      <td>.....((((((.....))))))....((((((............))...</td>\n",
       "      <td>1.196731</td>\n",
       "      <td>.....((((((.....))))))....((((((............))...</td>\n",
       "      <td>0.944219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.....[[[[[[.....]]]]]]......[[[[............]]...</td>\n",
       "      <td>22.852790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>119997</td>\n",
       "      <td>RF03087:ROOL_RNA:URS0000D6A43E_12908/1-580:71-170</td>\n",
       "      <td>Eterna</td>\n",
       "      <td>title = RF03087:ROOL RNA:URS0000D6A43E_12908/1...</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGUCAGAUAAGGCGAACAGCA...</td>\n",
       "      <td>RF03087:ROOL RNA:URS0000D6A43E_12908/1-580:71-170</td>\n",
       "      <td>.....((((((.....)))))).((((((((((..((.((((((((...</td>\n",
       "      <td>0.078128</td>\n",
       "      <td>.....((((((.....)))))).((((((((((..((.((((((((...</td>\n",
       "      <td>0.090706</td>\n",
       "      <td>...</td>\n",
       "      <td>.....((((((.....)))))).((((((.(((..((.((((((((...</td>\n",
       "      <td>1.210194</td>\n",
       "      <td>.....((((((.....))))))..(((((.(((..((.((((((((...</td>\n",
       "      <td>0.967172</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.....[[[[[[.....]]]]]]....[[[......]]]..[[[[[[...</td>\n",
       "      <td>23.079496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>119998</td>\n",
       "      <td>RF03087:ROOL_RNA:URS0000D6A43E_12908/1-580:81-180</td>\n",
       "      <td>Eterna</td>\n",
       "      <td>title = RF03087:ROOL RNA:URS0000D6A43E_12908/1...</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAGCGAACAGCAAGGAUACCUG...</td>\n",
       "      <td>RF03087:ROOL RNA:URS0000D6A43E_12908/1-580:81-180</td>\n",
       "      <td>.....((((((.....))))))...((.((((((((.((...))))...</td>\n",
       "      <td>0.139295</td>\n",
       "      <td>.....((((((.....))))))...((.((((((((.(....).))...</td>\n",
       "      <td>0.092917</td>\n",
       "      <td>...</td>\n",
       "      <td>.....((((((.....))))))...((.((((((((.((...))))...</td>\n",
       "      <td>1.186094</td>\n",
       "      <td>.....((((((.....))))))...((.((((((((.((...))))...</td>\n",
       "      <td>0.938252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.....[[[[[[.....]]]]]]......[[[[[[[[.[[...]]]]...</td>\n",
       "      <td>23.301605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>119999</td>\n",
       "      <td>RF03087:ROOL_RNA:URS0000D6A43E_12908/1-580:91-190</td>\n",
       "      <td>Eterna</td>\n",
       "      <td>title = RF03087:ROOL RNA:URS0000D6A43E_12908/1...</td>\n",
       "      <td>GGGAACGACUCGAGUAGAGUCGAAAAAGGAUACCUGCUGUUUUCUG...</td>\n",
       "      <td>RF03087:ROOL RNA:URS0000D6A43E_12908/1-580:91-190</td>\n",
       "      <td>.....((((((.....))))))............((.(((((((((...</td>\n",
       "      <td>0.097339</td>\n",
       "      <td>.....((((((.....))))))...................(((((...</td>\n",
       "      <td>0.103055</td>\n",
       "      <td>...</td>\n",
       "      <td>.....((((((.....)))))).....(((..((((....((((((...</td>\n",
       "      <td>1.210017</td>\n",
       "      <td>.....((((((.....)))))).....(((..((((....((((((...</td>\n",
       "      <td>0.960829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>.....[[[[[[.....]]]]]].....[[[..[[[[....[[[[[[...</td>\n",
       "      <td>25.022766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120000 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rowID                                                 id        name  \\\n",
       "0            0                                           11844837      Merida   \n",
       "1            1                                           11844835      Merida   \n",
       "2            2                                           11844833      Merida   \n",
       "3            3                                           11844831      Merida   \n",
       "4            4                                           11844829   amybarish   \n",
       "...        ...                                                ...         ...   \n",
       "119995  119995  RF03087:ROOL_RNA:URS0000D6A43E_12908/1-580:51-150      Eterna   \n",
       "119996  119996  RF03087:ROOL_RNA:URS0000D6A43E_12908/1-580:61-160      Eterna   \n",
       "119997  119997  RF03087:ROOL_RNA:URS0000D6A43E_12908/1-580:71-170      Eterna   \n",
       "119998  119998  RF03087:ROOL_RNA:URS0000D6A43E_12908/1-580:81-180      Eterna   \n",
       "119999  119999  RF03087:ROOL_RNA:URS0000D6A43E_12908/1-580:91-190      Eterna   \n",
       "\n",
       "                                                     body  \\\n",
       "0                                Modified previous design   \n",
       "1                                Modified previous design   \n",
       "2                                Modified previous design   \n",
       "3                                Modified previous design   \n",
       "4        https://www.ncbi.nlm.nih.gov/nuccore/NC_00220...   \n",
       "...                                                   ...   \n",
       "119995  title = RF03087:ROOL RNA:URS0000D6A43E_12908/1...   \n",
       "119996  title = RF03087:ROOL RNA:URS0000D6A43E_12908/1...   \n",
       "119997  title = RF03087:ROOL RNA:URS0000D6A43E_12908/1...   \n",
       "119998  title = RF03087:ROOL RNA:URS0000D6A43E_12908/1...   \n",
       "119999  title = RF03087:ROOL RNA:URS0000D6A43E_12908/1...   \n",
       "\n",
       "                                                 sequence  \\\n",
       "0       GGGAACGACUCGAGUAGAGUCGAAAAGGAGAGUUUAGUAAAAUAUA...   \n",
       "1       GGGAACGACUCGAGUAGAGUCGAAAAGGAGAGUUUAGUAAAAUAUA...   \n",
       "2       GGGAACGACUCGAGUAGAGUCGAAAAGGAGAGGAAAGUAAAAUAUA...   \n",
       "3       GGGAACGACUCGAGUAGAGUCGAAAAGGAGAGGAAAGUACAAUAUA...   \n",
       "4       GGGAACGACUCGAGUAGAGUCGAAAAUCUUGGAGAUUUCAAAACCA...   \n",
       "...                                                   ...   \n",
       "119995  GGGAACGACUCGAGUAGAGUCGAAAAUUUCCGUAAAUUGCCUGUAA...   \n",
       "119996  GGGAACGACUCGAGUAGAGUCGAAAAUUGCCUGUAAGUCAGAUAAG...   \n",
       "119997  GGGAACGACUCGAGUAGAGUCGAAAAGUCAGAUAAGGCGAACAGCA...   \n",
       "119998  GGGAACGACUCGAGUAGAGUCGAAAAGCGAACAGCAAGGAUACCUG...   \n",
       "119999  GGGAACGACUCGAGUAGAGUCGAAAAAGGAUACCUGCUGUUUUCUG...   \n",
       "\n",
       "                                                    title  \\\n",
       "0                                                 No sock   \n",
       "1                                              Windsock 8   \n",
       "2                                              Windsock 7   \n",
       "3                                              Windsock 6   \n",
       "4        Influenza B virus (B/Lee/1940) segment 2 2121...   \n",
       "...                                                   ...   \n",
       "119995  RF03087:ROOL RNA:URS0000D6A43E_12908/1-580:51-150   \n",
       "119996  RF03087:ROOL RNA:URS0000D6A43E_12908/1-580:61-160   \n",
       "119997  RF03087:ROOL RNA:URS0000D6A43E_12908/1-580:71-170   \n",
       "119998  RF03087:ROOL RNA:URS0000D6A43E_12908/1-580:81-180   \n",
       "119999  RF03087:ROOL RNA:URS0000D6A43E_12908/1-580:91-190   \n",
       "\n",
       "                                              vienna2_mfe  vienna2_time  \\\n",
       "0       .....((((((.....)))))).........((((........(((...      0.388069   \n",
       "1       .....((((((.....)))))).........((((..............      0.088197   \n",
       "2       .....((((((.....)))))).....((((((((..............      0.074533   \n",
       "3       .....((((((.....)))))).....((((((((..............      0.076538   \n",
       "4       .....((((((.....))))))....((((((((.((((((..((....      0.061118   \n",
       "...                                                   ...           ...   \n",
       "119995  (((((((((((.....))))))....))))).......((((.......      0.101556   \n",
       "119996  ((.((((((((.....))))))....)).))....((((((((..(...      0.171337   \n",
       "119997  .....((((((.....)))))).((((((((((..((.((((((((...      0.078128   \n",
       "119998  .....((((((.....))))))...((.((((((((.((...))))...      0.139295   \n",
       "119999  .....((((((.....))))))............((.(((((((((...      0.097339   \n",
       "\n",
       "                                          contrafold2_mfe  contrafold2_time  \\\n",
       "0       .....((((((.....)))))).....................(((...          0.241375   \n",
       "1       .....((((((.....))))))...................(((.....          0.172300   \n",
       "2       .....((((((.....)))))).....((((((((..............          0.113422   \n",
       "3       .....((((((.....)))))).....((((((((.(((((((......          0.109473   \n",
       "4       .....((((((.....))))))....((.....))((((((..((....          0.089928   \n",
       "...                                                   ...               ...   \n",
       "119995  (((((((((((.....))))))....)))))..................          0.086174   \n",
       "119996  .....((((((.....))))))............(((((((((..(...          0.106900   \n",
       "119997  .....((((((.....)))))).((((((((((..((.((((((((...          0.090706   \n",
       "119998  .....((((((.....))))))...((.((((((((.(....).))...          0.092917   \n",
       "119999  .....((((((.....))))))...................(((((...          0.103055   \n",
       "\n",
       "        ...                                 nupack[threshknot]  \\\n",
       "0       ...  .....((((((.....)))))).....................(((...   \n",
       "1       ...  .....((((((.....)))))).....................(((...   \n",
       "2       ...  .....((((((.....)))))).....((((((((..............   \n",
       "3       ...  .....((((((.....)))))).....((((((((..(((...(((...   \n",
       "4       ...  .....((((((.....))))))....((((((((.((((((..((....   \n",
       "...     ...                                                ...   \n",
       "119995  ...  (((((((((((.....))))))....))))).....((((((.......   \n",
       "119996  ...  .....((((((.....))))))....((((((............))...   \n",
       "119997  ...  .....((((((.....)))))).((((((.(((..((.((((((((...   \n",
       "119998  ...  .....((((((.....))))))...((.((((((((.((...))))...   \n",
       "119999  ...  .....((((((.....)))))).....(((..((((....((((((...   \n",
       "\n",
       "        nupack[threshknot]_time  \\\n",
       "0                      1.346570   \n",
       "1                      1.237194   \n",
       "2                      1.307606   \n",
       "3                      1.524313   \n",
       "4                      1.324285   \n",
       "...                         ...   \n",
       "119995                 1.192680   \n",
       "119996                 1.196731   \n",
       "119997                 1.210194   \n",
       "119998                 1.186094   \n",
       "119999                 1.210017   \n",
       "\n",
       "                                        nupack[hungarian]  \\\n",
       "0       .....((((((.....)))))).....................(((...   \n",
       "1       .....((((((.....))))))...........................   \n",
       "2       .....((((((.....)))))).....((((((((..............   \n",
       "3       .....((((((.....)))))).....((((((((..(((...(((...   \n",
       "4       .....((((((.....))))))....((((((...((((((..((....   \n",
       "...                                                   ...   \n",
       "119995  (((((((((((.....))))))....))))).....((((((.......   \n",
       "119996  .....((((((.....))))))....((((((............))...   \n",
       "119997  .....((((((.....))))))..(((((.(((..((.((((((((...   \n",
       "119998  .....((((((.....))))))...((.((((((((.((...))))...   \n",
       "119999  .....((((((.....)))))).....(((..((((....((((((...   \n",
       "\n",
       "        nupack[hungarian]_time  \\\n",
       "0                     1.085448   \n",
       "1                     0.978989   \n",
       "2                     1.016065   \n",
       "3                     1.239788   \n",
       "4                     1.034621   \n",
       "...                        ...   \n",
       "119995                0.945760   \n",
       "119996                0.944219   \n",
       "119997                0.967172   \n",
       "119998                0.938252   \n",
       "119999                0.960829   \n",
       "\n",
       "                                    nupack-pk[threshknot]  \\\n",
       "0       .....((((((.....)))))).....................(((...   \n",
       "1       .....((((((.....))))))......................((...   \n",
       "2       .....((((((.....)))))).....((((((((..............   \n",
       "3       .....((((((.....)))))).....((((((((...[[[[[[.....   \n",
       "4       .....((((((.....)))))).............((((((..((....   \n",
       "...                                                   ...   \n",
       "119995                                                NaN   \n",
       "119996                                                NaN   \n",
       "119997                                                NaN   \n",
       "119998                                                NaN   \n",
       "119999                                                NaN   \n",
       "\n",
       "        nupack-pk[threshknot]_time  \\\n",
       "0                      1392.271822   \n",
       "1                      1270.632311   \n",
       "2                      1323.665772   \n",
       "3                      1296.099273   \n",
       "4                      1089.907709   \n",
       "...                            ...   \n",
       "119995                         NaN   \n",
       "119996                         NaN   \n",
       "119997                         NaN   \n",
       "119998                         NaN   \n",
       "119999                         NaN   \n",
       "\n",
       "                                     nupack-pk[hungarian]  \\\n",
       "0       .....((((((.....))))))......................((...   \n",
       "1       .....((((((.....))))))...........................   \n",
       "2       .....((((((.....)))))).....((((((((..............   \n",
       "3       .....((((((.....)))))).....((((((((...[[[[[[.....   \n",
       "4       .....((((((.....)))))).............((((((..((....   \n",
       "...                                                   ...   \n",
       "119995                                                NaN   \n",
       "119996                                                NaN   \n",
       "119997                                                NaN   \n",
       "119998                                                NaN   \n",
       "119999                                                NaN   \n",
       "\n",
       "        nupack-pk[hungarian]_time  \\\n",
       "0                     1392.013173   \n",
       "1                     1270.416410   \n",
       "2                     1323.332391   \n",
       "3                     1295.817735   \n",
       "4                     1089.612172   \n",
       "...                           ...   \n",
       "119995                        NaN   \n",
       "119996                        NaN   \n",
       "119997                        NaN   \n",
       "119998                        NaN   \n",
       "119999                        NaN   \n",
       "\n",
       "                                            shapify-hfold  shapify-hfold_time  \n",
       "0       .....[[[[[[.....]]]]]].......[[[..[[[[[....[[[...           30.332876  \n",
       "1       .....[[[[[[.....]]]]]]...........................           29.568014  \n",
       "2       .....[[[[[[.....]]]]]].....((((((((.....[[[[[....           27.488272  \n",
       "3       .....[[[[[[.....]]]]]].....((((((((...[[[[[[[....           25.737695  \n",
       "4       [[...[[[[[[.....]]]]]]....[[[[[[...[[[[[[..[[....           21.801687  \n",
       "...                                                   ...                 ...  \n",
       "119995  .[[[[[[[[[[.....]]]]]].....]]]].....((((((.......           23.977213  \n",
       "119996  .....[[[[[[.....]]]]]]......[[[[............]]...           22.852790  \n",
       "119997  .....[[[[[[.....]]]]]]....[[[......]]]..[[[[[[...           23.079496  \n",
       "119998  .....[[[[[[.....]]]]]]......[[[[[[[[.[[...]]]]...           23.301605  \n",
       "119999  .....[[[[[[.....]]]]]].....[[[..[[[[....[[[[[[...           25.022766  \n",
       "\n",
       "[120000 rows x 44 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(fns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
