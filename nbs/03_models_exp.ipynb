{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_266327/287943212.py:23: UserWarning: \u001b[35mCould not import flash_attn\u001b[0m\n",
      "  warnings.warn(colored(\"Could not import flash_attn\", \"magenta\"))\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence = df['sequence'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IGNORE_INDEX = -100\n",
    "# PAD_INDEX = 0\n",
    "# input_samples = []\n",
    "# for seq in sequence:\n",
    "#     length = len(seq)\n",
    "#     seq_vocab = ['A', 'C', 'G', 'U', 'N']\n",
    "#     seq_stoi = dict(zip(seq_vocab, range(len(seq_vocab))))\n",
    "#     int_sequence = list(map(seq_stoi.get, seq))\n",
    "#     input_sample = torch.LongTensor(int_sequence)\n",
    "#     input_sample = {'src_seq': input_sample, 'length': torch.LongTensor([len(input_sample)])[0]}\n",
    "#     input_samples.append(input_sample)\n",
    "# collator = CollatorRNA(PAD_INDEX, IGNORE_INDEX)\n",
    "# batch = collator(input_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair_mask = make_pair_mask(batch['src_seq'], batch['length'])\n",
    "# pair_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair_latent = EmbedSequence2Matrix(CONFIG)(batch['src_seq'])\n",
    "# pair_latent.masked_fill_(pair_mask[:, :, :, None], 0.0)\n",
    "# pair_latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "import pandas as pd\n",
    "from rnacomp.dataset import LenMatchBatchSampler, RNA_DatasetBaselineSplitbppV0, DeviceDataLoader, RNA_DatasetBaselineSplitssV1\n",
    "\n",
    "class CFG:\n",
    "    path = Path(\"../data/\")\n",
    "    pathbb = Path(\"../data/Ribonanza_bpp_files\")\n",
    "    split_id = Path('../eda/fold_split.csv')\n",
    "    pathss = Path(\"../eda/train_ss_vienna_rna.parquet\")\n",
    "    bs = 4\n",
    "    num_workers = 8\n",
    "    device = 'cpu'\n",
    "    adjnact_prob = 0.5\n",
    "\n",
    "\n",
    "\n",
    "fns = list(CFG.pathbb.rglob(\"*.txt\"))\n",
    "bpp_df = pd.DataFrame({\"bpp\": fns})\n",
    "bpp_df['sequence_id'] = bpp_df['bpp'].apply(lambda x: x.stem)\n",
    "ss = pd.read_parquet(CFG.pathss)[[\"sequence_id\", \"ss_full\"]]\n",
    "df = pd.read_parquet(CFG.path/'train_data.parquet')\n",
    "split = pd.read_csv(CFG.split_id)\n",
    "df = pd.merge(df, split, on='sequence_id')\n",
    "df = pd.merge(df, bpp_df, on='sequence_id')\n",
    "df = pd.merge(df, ss, on='sequence_id')\n",
    "df_train = df.query('is_train==True').reset_index(drop=True)\n",
    "df_valid = df.query('is_train==False').reset_index(drop=True)\n",
    "\n",
    "ds_val = RNA_DatasetBaselineSplitssV1(df_valid, mode='eval')\n",
    "ds_val_len = RNA_DatasetBaselineSplitssV1(df_valid, mode='eval', mask_only=True)\n",
    "sampler_val = torch.utils.data.SequentialSampler(ds_val_len)\n",
    "len_sampler_val = LenMatchBatchSampler(sampler_val, batch_size=CFG.bs, \n",
    "               drop_last=False)\n",
    "dl_val= DeviceDataLoader(torch.utils.data.DataLoader(ds_val, \n",
    "               batch_sampler=len_sampler_val, num_workers=CFG.num_workers), CFG.device)\n",
    "\n",
    "batch = next(iter(dl_val))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched weights: 118\n",
      "Unmatched weights: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:31: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\"None of the inputs have requires_grad=True. Gradients will be None\")\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    md = CustomRnaFormer(CONFIG)\n",
    "    load_matching_weights(md, '/opt/slh/rna/eda/rna_former.pth')\n",
    "    out = md(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 206, 2])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 175, 175])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5906, 4.1488, 3.2550,  ..., 2.4507, 0.6470, 2.0523],\n",
       "        [1.6022, 3.6314, 2.8822,  ..., 2.2289, 0.9459, 2.8971],\n",
       "        [1.9657, 4.1061, 2.8121,  ..., 2.5689, 1.0332, 2.0962],\n",
       "        ...,\n",
       "        [  -inf,   -inf,   -inf,  ...,   -inf,   -inf,   -inf],\n",
       "        [  -inf,   -inf,   -inf,  ...,   -inf,   -inf,   -inf],\n",
       "        [  -inf,   -inf,   -inf,  ...,   -inf,   -inf,   -inf]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
