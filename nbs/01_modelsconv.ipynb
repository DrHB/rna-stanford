{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp modelsconv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "from einops import rearrange, repeat\n",
    "from rotary_embedding_torch import RotaryEmbedding, apply_rotary_emb\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "import math\n",
    "from timm.models.layers import drop_path, to_2tuple, trunc_normal_\n",
    "from torch_sparse import SparseTensor, matmul\n",
    "from torch_geometric.utils import degree\n",
    "from torch_geometric.data import Data, Batch\n",
    "import numpy as np\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "from x_transformers import ContinuousTransformerWrapper, Encoder, TransformerWrapper\n",
    "from torch_geometric.nn import GATConv, GCNConv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def good_luck():\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super(conv_block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class up_conv(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super(up_conv, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class U_Net(nn.Module):\n",
    "    def __init__(self, img_ch=3, output_ch=1, CH_FOLD2=1):\n",
    "        super(U_Net, self).__init__()\n",
    "\n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(ch_in=img_ch, ch_out=int(32 * CH_FOLD2))\n",
    "        self.Conv2 = conv_block(ch_in=int(32 * CH_FOLD2), ch_out=int(64 * CH_FOLD2))\n",
    "        self.Conv3 = conv_block(ch_in=int(64 * CH_FOLD2), ch_out=int(128 * CH_FOLD2))\n",
    "        self.Conv4 = conv_block(ch_in=int(128 * CH_FOLD2), ch_out=int(256 * CH_FOLD2))\n",
    "        self.Conv5 = conv_block(ch_in=int(256 * CH_FOLD2), ch_out=int(512 * CH_FOLD2))\n",
    "\n",
    "        self.Up5 = up_conv(ch_in=int(512 * CH_FOLD2), ch_out=int(256 * CH_FOLD2))\n",
    "        self.Up_conv5 = conv_block(\n",
    "            ch_in=int(512 * CH_FOLD2), ch_out=int(256 * CH_FOLD2)\n",
    "        )\n",
    "\n",
    "        self.Up4 = up_conv(ch_in=int(256 * CH_FOLD2), ch_out=int(128 * CH_FOLD2))\n",
    "        self.Up_conv4 = conv_block(\n",
    "            ch_in=int(256 * CH_FOLD2), ch_out=int(128 * CH_FOLD2)\n",
    "        )\n",
    "\n",
    "        self.Up3 = up_conv(ch_in=int(128 * CH_FOLD2), ch_out=int(64 * CH_FOLD2))\n",
    "        self.Up_conv3 = conv_block(ch_in=int(128 * CH_FOLD2), ch_out=int(64 * CH_FOLD2))\n",
    "\n",
    "        self.Up2 = up_conv(ch_in=int(64 * CH_FOLD2), ch_out=int(32 * CH_FOLD2))\n",
    "        self.Up_conv2 = conv_block(ch_in=int(64 * CH_FOLD2), ch_out=int(32 * CH_FOLD2))\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(\n",
    "            int(32 * CH_FOLD2), output_ch, kernel_size=1, stride=1, padding=0\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoding path\n",
    "        x1 = self.Conv1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.Conv2(x2)\n",
    "\n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.Conv3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.Conv4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.Conv5(x5)\n",
    "\n",
    "        # decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        d5 = torch.cat((x4, d5), dim=1)\n",
    "\n",
    "        d5 = self.Up_conv5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((x3, d4), dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((x2, d3), dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        d2 = torch.cat((x1, d2), dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "        d1 = d1.squeeze(1)\n",
    "        out = torch.transpose(d1, -1, -2) * d1\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class UnetWrapper2D(nn.Module):\n",
    "    def __init__(self, md, output_chans=2):\n",
    "        super().__init__()\n",
    "        self.md = md\n",
    "        self.output_chans = output_chans\n",
    "\n",
    "    def do_forward(self, x, crop16, crop):\n",
    "        out = torch.zeros(\n",
    "            x.shape[0], self.output_chans, x.shape[2], x.shape[3], device=x.device\n",
    "        )\n",
    "        res = self.md(x[:, :, :crop16, :crop16])\n",
    "        out[:, :, :crop, :crop] = res[:, :, :crop, :crop]\n",
    "        return out\n",
    "\n",
    "    def forward(self, xs, crop_to_16, crop_original, original_order):\n",
    "        res = []\n",
    "        for x, crop16, crop in zip(xs, crop_to_16, crop_original):\n",
    "            res.append(self.do_forward(x, crop16, crop))\n",
    "        return torch.cat(res)[original_order]\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_batches(tensor, nn_out):\n",
    "    # Sort the tensor\n",
    "    if tensor.unique().shape[0] == 1:\n",
    "        return [nn_out], torch.arange(len(tensor), device=tensor.device)\n",
    "    sorted_tensor, order = tensor.sort()\n",
    "    nn_out = nn_out.index_select(0, order)\n",
    "\n",
    "    # Find the change points\n",
    "    diff = torch.cat([torch.tensor([1]), torch.diff(sorted_tensor)])\n",
    "    change_indices = torch.where(diff != 0)[0]\n",
    "    change_indices = torch.cat([change_indices, torch.tensor([len(tensor)])])\n",
    "    b = [\n",
    "        nn_out[change_indices[i] : change_indices[i + 1]]\n",
    "        for i in range(len(change_indices) - 1)\n",
    "    ]\n",
    "    return b, order.argsort()\n",
    "\n",
    "\n",
    "def make_pair_mask(seq, seq_len):\n",
    "    encode_mask = torch.arange(seq.shape[1], device=seq.device).expand(\n",
    "        seq.shape[:2]\n",
    "    ) < seq_len.unsqueeze(1)\n",
    "    pair_mask = encode_mask[:, None, :] * encode_mask[:, :, None]\n",
    "    assert isinstance(pair_mask, torch.BoolTensor) or isinstance(\n",
    "        pair_mask, torch.cuda.BoolTensor\n",
    "    )\n",
    "    return torch.bitwise_not(pair_mask)\n",
    "\n",
    "\n",
    "class ScaledSinuEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.scale = nn.Parameter(\n",
    "            torch.ones(\n",
    "                1,\n",
    "            )\n",
    "        )\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        self.register_buffer(\"inv_freq\", inv_freq)\n",
    "\n",
    "    def forward(self, x):\n",
    "        n, device = x.shape[1], x.device\n",
    "        t = torch.arange(n, device=device).type_as(self.inv_freq)\n",
    "        sinu = einsum(\"i , j -> i j\", t, self.inv_freq)\n",
    "        emb = torch.cat((sinu.sin(), sinu.cos()), dim=-1)\n",
    "        return emb * self.scale\n",
    "\n",
    "\n",
    "class CustomEmbedding(nn.Module):\n",
    "    def __init__(self, dim, vocab=4):\n",
    "        super().__init__()\n",
    "        self.embed_seq = nn.Embedding(vocab, dim)\n",
    "        self.pos_enc = ScaledSinuEmbedding(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed_seq(x)\n",
    "        x = x + self.pos_enc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SeqToImage(nn.Module):\n",
    "    def __init__(self, dim, vocab=4):\n",
    "        super().__init__()\n",
    "        self.embed_h = CustomEmbedding(dim=dim, vocab=vocab)\n",
    "        self.embed_w = CustomEmbedding(dim=dim, vocab=vocab)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, seq, mask):\n",
    "        seq_h = self.embed_h(seq)\n",
    "        seq_w = self.embed_w(seq)\n",
    "        x = seq_h.unsqueeze(1) + seq_w.unsqueeze(2)\n",
    "        x = self.norm(x)\n",
    "        x.masked_fill_(mask[:, :, :, None], 0.0)  # bs, h, w, dim\n",
    "        x = x.permute(0, 3, 1, 2)  # bs, dim, h, w\n",
    "        return x\n",
    "\n",
    "\n",
    "class Attn_pool(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(n, n, 1)\n",
    "        self.attn = nn.Conv2d(n, n, 1)\n",
    "\n",
    "    def forward(self, x, key_padding_mask=None):\n",
    "        emb = self.conv(x)\n",
    "        attn = self.attn(x)\n",
    "\n",
    "        # Apply the mask to attention scores before softmax\n",
    "        if key_padding_mask is not None:\n",
    "            attn = attn.masked_fill(key_padding_mask.unsqueeze(1), float(\"-inf\"))\n",
    "        # attn = torch.clamp(attn, min=-1e9, max=1e9)\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        x = (emb * attn).sum(-1)\n",
    "        return x, attn\n",
    "\n",
    "\n",
    "class FeedForwardV5(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.2, out=2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, out),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class RnaModelConvV0(nn.Module):\n",
    "    def __init__(self, embed_size, conv_out=8, vecob_size=4):\n",
    "        super().__init__()\n",
    "        self.seq_to_image = SeqToImage(embed_size, vocab=vecob_size)\n",
    "        self.md = UnetWrapper2D(U_Net(embed_size, conv_out), conv_out)\n",
    "        self.attnpool = Attn_pool(conv_out)\n",
    "        self.out = FeedForwardV5(conv_out, conv_out, out=2)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        L_seq = batch[\"mask\"].sum(1)\n",
    "        L0 = batch[\"mask\"].shape[1]\n",
    "\n",
    "        crop_to_original = L_seq.unique()  # unique lengths\n",
    "        crop_to_16 = [\n",
    "            ((i // 16) + 1) * 16 for i in crop_to_original\n",
    "        ]  # for each unique length, find the nearest 16 miltip\n",
    "        seq = batch[\"seq\"][:, : crop_to_16[-1]]  # shortening to largest 16 multiple\n",
    "\n",
    "        # make a square mask [bs, crop_to_16[-1], crop_to_16[-1]]  #crop_to_16[-1] is the largest 16 multiple\n",
    "        square_mask = make_pair_mask(seq, L_seq)\n",
    "\n",
    "        x = self.seq_to_image(seq, square_mask)\n",
    "        x, idc = generate_batches(L_seq, x)\n",
    "        x = self.md(x, crop_to_16, crop_to_original, idc)\n",
    "        x, attn = self.attnpool(x, square_mask)\n",
    "        x = self.out(x.permute(0, 2, 1))\n",
    "        x = F.pad(x, (0, 0, 0, L0 - x.shape[1], 0, 0))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 32, 128, 128])\n",
      "torch.Size([10, 32, 128, 128])\n",
      "torch.Size([14, 32, 160, 160])\n",
      "torch.Size([14, 32, 160, 160])\n",
      "torch.Size([8, 32, 176, 176])\n",
      "torch.Size([8, 32, 176, 176])\n"
     ]
    }
   ],
   "source": [
    "embed_size = 16\n",
    "out_chan_unet = 32\n",
    "md = RnaModelConvV0(embed_size=embed_size, conv_out=out_chan_unet).eval()\n",
    "batch = torch.load(\"batch.pt\")\n",
    "with torch.no_grad():\n",
    "    out = md(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3950, -0.0395],\n",
       "         [-0.3943, -0.0402],\n",
       "         [-0.3931, -0.0413],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.3950, -0.0395],\n",
       "         [-0.3943, -0.0402],\n",
       "         [-0.3931, -0.0413],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.3950, -0.0395],\n",
       "         [-0.3943, -0.0402],\n",
       "         [-0.3931, -0.0413],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.3951, -0.0393],\n",
       "         [-0.3944, -0.0401],\n",
       "         [-0.3933, -0.0412],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.3951, -0.0394],\n",
       "         [-0.3944, -0.0401],\n",
       "         [-0.3933, -0.0412],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.3951, -0.0393],\n",
       "         [-0.3944, -0.0401],\n",
       "         [-0.3933, -0.0411],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 256, 256])\n",
      "torch.Size([1, 2, 256, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 6.9599e-02,  2.0665e-02,  3.2410e-02,  ...,  4.6228e-04,\n",
       "           -1.1477e-01,  8.5805e-02],\n",
       "          [ 2.0665e-02,  3.3128e-03,  2.3444e-02,  ...,  4.2860e-03,\n",
       "            8.9023e-02, -1.6158e-02],\n",
       "          [ 3.2410e-02,  2.3444e-02,  5.2872e-01,  ...,  7.1295e-02,\n",
       "           -3.9363e-02,  1.4245e-01],\n",
       "          ...,\n",
       "          [ 4.6228e-04,  4.2860e-03,  7.1295e-02,  ...,  1.9310e-02,\n",
       "            2.4313e-02,  1.9723e-02],\n",
       "          [-1.1477e-01,  8.9023e-02, -3.9363e-02,  ...,  2.4313e-02,\n",
       "            2.7535e-01, -6.4474e-02],\n",
       "          [ 8.5805e-02, -1.6158e-02,  1.4245e-01,  ...,  1.9723e-02,\n",
       "           -6.4474e-02,  3.3966e-02]],\n",
       "\n",
       "         [[ 6.8054e-04,  2.6302e-02, -2.7471e-02,  ...,  6.0433e-02,\n",
       "            1.6723e-01,  4.9745e-02],\n",
       "          [ 2.6302e-02,  1.8257e-01,  8.9803e-02,  ...,  9.4198e-02,\n",
       "            8.6957e-01, -1.5848e-02],\n",
       "          [-2.7471e-02,  8.9803e-02,  5.0949e-02,  ...,  2.9446e-01,\n",
       "            1.5864e-01, -9.6408e-02],\n",
       "          ...,\n",
       "          [ 6.0433e-02,  9.4198e-02,  2.9446e-01,  ...,  1.7272e-02,\n",
       "            5.8082e-02, -8.5843e-03],\n",
       "          [ 1.6723e-01,  8.6957e-01,  1.5864e-01,  ...,  5.8082e-02,\n",
       "            2.8058e-01,  2.0968e-01],\n",
       "          [ 4.9745e-02, -1.5848e-02, -9.6408e-02,  ..., -8.5843e-03,\n",
       "            2.0968e-01,  4.1795e-02]]]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U_Net(3, 2)(torch.rand(1, 3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 256, 256])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " torch.transpose(torch.rand(1, 3, 256, 256), -1, -2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(4).view(1, 1, 2, 2) + 1\n",
    "y = torch.arange(4).view(1, 1, 2, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 2],\n",
       "          [3, 4]]]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0, 1],\n",
       "          [2, 3]]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.transpose(x, -1, -2) * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  3],\n",
       "        [ 4, 12]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 3],\n",
       "          [2, 4]]]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(x, -1, -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
