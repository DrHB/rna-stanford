{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# |default_exp models_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from torch_geometric.datasets import MoleculeNet\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch.utils.data import Subset\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "\n",
    "from typing import Tuple, Dict, List, Union\n",
    "from torch.multiprocessing import spawn\n",
    "\n",
    "import networkx as nx\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.utils.convert import to_networkx\n",
    "from torch_geometric.utils import to_dense_batch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def decrease_to_max_value(x, max_value):\n",
    "    x[x > max_value] = max_value\n",
    "    return x\n",
    "\n",
    "class CentralityEncoding(nn.Module):\n",
    "    def __init__(self, max_in_degree: int, max_out_degree: int, node_dim: int):\n",
    "        \"\"\"\n",
    "        :param max_in_degree: max in degree of nodes\n",
    "        :param max_out_degree: max in degree of nodes\n",
    "        :param node_dim: hidden dimensions of node features\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.max_in_degree = max_in_degree\n",
    "        self.max_out_degree = max_out_degree\n",
    "        self.node_dim = node_dim\n",
    "        self.z_in = nn.Parameter(torch.randn((max_in_degree, node_dim)))\n",
    "        self.z_out = nn.Parameter(torch.randn((max_out_degree, node_dim)))\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_index: torch.LongTensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param x: node feature matrix\n",
    "        :param edge_index: edge_index of graph (adjacency list)\n",
    "        :return: torch.Tensor, node embeddings after Centrality encoding\n",
    "        \"\"\"\n",
    "        num_nodes = x.shape[0]\n",
    "\n",
    "        in_degree = decrease_to_max_value(degree(index=edge_index[1], num_nodes=num_nodes).long(), self.max_in_degree)\n",
    "        out_degree = decrease_to_max_value(degree(index=edge_index[0], num_nodes=num_nodes).long(), self.max_out_degree)\n",
    "\n",
    "        x += self.z_in[in_degree] + self.z_out[out_degree]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SpatialEncoding(nn.Module):\n",
    "    def __init__(self, max_path_distance: int):\n",
    "        \"\"\"\n",
    "        :param max_path_distance: max pairwise distance between nodes\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.max_path_distance = max_path_distance\n",
    "\n",
    "        self.b = nn.Parameter(torch.randn(self.max_path_distance))\n",
    "\n",
    "    def forward(self, x: torch.Tensor, paths) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param x: node feature matrix\n",
    "        :param paths: pairwise node paths\n",
    "        :return: torch.Tensor, spatial Encoding matrix\n",
    "        \"\"\"\n",
    "        spatial_matrix = torch.zeros((x.shape[0], x.shape[0])).to(next(self.parameters()).device)\n",
    "        for src in paths:\n",
    "            for dst in paths[src]:\n",
    "                spatial_matrix[src][dst] = self.b[min(len(paths[src][dst]), self.max_path_distance) - 1]\n",
    "\n",
    "        return spatial_matrix\n",
    "\n",
    "\n",
    "def dot_product(x1, x2) -> torch.Tensor:\n",
    "    return (x1 * x2).sum(dim=1)\n",
    "\n",
    "\n",
    "class EdgeEncoding(nn.Module):\n",
    "    def __init__(self, edge_dim: int, max_path_distance: int):\n",
    "        \"\"\"\n",
    "        :param edge_dim: edge feature matrix number of dimension\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.edge_dim = edge_dim\n",
    "        self.max_path_distance = max_path_distance\n",
    "        self.edge_vector = nn.Parameter(torch.randn(self.max_path_distance, self.edge_dim))\n",
    "\n",
    "    def forward(self, x: torch.Tensor, edge_attr: torch.Tensor, edge_paths) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param x: node feature matrix\n",
    "        :param edge_attr: edge feature matrix\n",
    "        :param edge_paths: pairwise node paths in edge indexes\n",
    "        :return: torch.Tensor, Edge Encoding matrix\n",
    "        \"\"\"\n",
    "        cij = torch.zeros((x.shape[0], x.shape[0])).to(next(self.parameters()).device)\n",
    "\n",
    "        for src in edge_paths:\n",
    "            for dst in edge_paths[src]:\n",
    "                path_ij = edge_paths[src][dst][:self.max_path_distance]\n",
    "                weight_inds = [i for i in range(len(path_ij))]\n",
    "                cij[src][dst] = dot_product(self.edge_vector[weight_inds], edge_attr[path_ij]).mean()\n",
    "\n",
    "        cij = torch.nan_to_num(cij)\n",
    "        return cij\n",
    "\n",
    "\n",
    "class GraphormerAttentionHead(nn.Module):\n",
    "    def __init__(self, dim_in: int, dim_q: int, dim_k: int, edge_dim: int, max_path_distance: int):\n",
    "        \"\"\"\n",
    "        :param dim_in: node feature matrix input number of dimension\n",
    "        :param dim_q: query node feature matrix input number dimension\n",
    "        :param dim_k: key node feature matrix input number of dimension\n",
    "        :param edge_dim: edge feature matrix number of dimension\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.edge_encoding = EdgeEncoding(edge_dim, max_path_distance)\n",
    "\n",
    "        self.q = nn.Linear(dim_in, dim_q)\n",
    "        self.k = nn.Linear(dim_in, dim_k)\n",
    "        self.v = nn.Linear(dim_in, dim_k)\n",
    "\n",
    "    def forward(self,\n",
    "                query: torch.Tensor,\n",
    "                key: torch.Tensor,\n",
    "                value: torch.Tensor,\n",
    "                edge_attr: torch.Tensor,\n",
    "                b: torch.Tensor,\n",
    "                edge_paths,\n",
    "                ptr) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param query: node feature matrix\n",
    "        :param key: node feature matrix\n",
    "        :param value: node feature matrix\n",
    "        :param edge_attr: edge feature matrix\n",
    "        :param b: spatial Encoding matrix\n",
    "        :param edge_paths: pairwise node paths in edge indexes\n",
    "        :param ptr: batch pointer that shows graph indexes in batch of graphs\n",
    "        :return: torch.Tensor, node embeddings after attention operation\n",
    "        \"\"\"\n",
    "        batch_mask_neg_inf = torch.full(size=(query.shape[0], query.shape[0]), fill_value=-1e6).to(next(self.parameters()).device)\n",
    "        batch_mask_zeros = torch.zeros(size=(query.shape[0], query.shape[0])).to(next(self.parameters()).device)\n",
    "\n",
    "        # OPTIMIZE: get rid of slices: rewrite to torch\n",
    "        if type(ptr) == type(None):\n",
    "            batch_mask_neg_inf = torch.ones(size=(query.shape[0], query.shape[0])).to(next(self.parameters()).device)\n",
    "            batch_mask_zeros += 1\n",
    "        else:\n",
    "            for i in range(len(ptr) - 1):\n",
    "                batch_mask_neg_inf[ptr[i]:ptr[i + 1], ptr[i]:ptr[i + 1]] = 1\n",
    "                batch_mask_zeros[ptr[i]:ptr[i + 1], ptr[i]:ptr[i + 1]] = 1\n",
    "\n",
    "        query = self.q(query)\n",
    "        key = self.k(key)\n",
    "        value = self.v(value)\n",
    "\n",
    "        c = self.edge_encoding(query, edge_attr, edge_paths)\n",
    "        a = query.mm(key.transpose(0, 1)) / query.size(-1) ** 0.5\n",
    "        a = (a + b + c) * batch_mask_neg_inf\n",
    "        softmax = torch.softmax(a, dim=-1) * batch_mask_zeros\n",
    "        x = softmax.mm(value)\n",
    "        return x\n",
    "\n",
    "\n",
    "# FIX: sparse attention instead of regular attention, due to specificity of GNNs(all nodes in batch will exchange attention)\n",
    "class GraphormerMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads: int, dim_in: int, dim_q: int, dim_k: int, edge_dim: int, max_path_distance: int):\n",
    "        \"\"\"\n",
    "        :param num_heads: number of attention heads\n",
    "        :param dim_in: node feature matrix input number of dimension\n",
    "        :param dim_q: query node feature matrix input number dimension\n",
    "        :param dim_k: key node feature matrix input number of dimension\n",
    "        :param edge_dim: edge feature matrix number of dimension\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [GraphormerAttentionHead(dim_in, dim_q, dim_k, edge_dim, max_path_distance) for _ in range(num_heads)]\n",
    "        )\n",
    "        self.linear = nn.Linear(num_heads * dim_k, dim_in)\n",
    "\n",
    "    def forward(self,\n",
    "                x: torch.Tensor,\n",
    "                edge_attr: torch.Tensor,\n",
    "                b: torch.Tensor,\n",
    "                edge_paths,\n",
    "                ptr) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param x: node feature matrix\n",
    "        :param edge_attr: edge feature matrix\n",
    "        :param b: spatial Encoding matrix\n",
    "        :param edge_paths: pairwise node paths in edge indexes\n",
    "        :param ptr: batch pointer that shows graph indexes in batch of graphs\n",
    "        :return: torch.Tensor, node embeddings after all attention heads\n",
    "        \"\"\"\n",
    "        return self.linear(\n",
    "            torch.cat([\n",
    "                attention_head(x, x, x, edge_attr, b, edge_paths, ptr) for attention_head in self.heads\n",
    "            ], dim=-1)\n",
    "        )\n",
    "\n",
    "\n",
    "class GraphormerEncoderLayer(nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, n_heads, max_path_distance):\n",
    "        \"\"\"\n",
    "        :param node_dim: node feature matrix input number of dimension\n",
    "        :param edge_dim: edge feature matrix input number of dimension\n",
    "        :param n_heads: number of attention heads\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.node_dim = node_dim\n",
    "        self.edge_dim = edge_dim\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        self.attention = GraphormerMultiHeadAttention(\n",
    "            dim_in=node_dim,\n",
    "            dim_k=node_dim,\n",
    "            dim_q=node_dim,\n",
    "            num_heads=n_heads,\n",
    "            edge_dim=edge_dim,\n",
    "            max_path_distance=max_path_distance,\n",
    "        )\n",
    "        self.ln_1 = nn.LayerNorm(node_dim)\n",
    "        self.ln_2 = nn.LayerNorm(node_dim)\n",
    "        self.ff = nn.Linear(node_dim, node_dim)\n",
    "\n",
    "    def forward(self,\n",
    "                x: torch.Tensor,\n",
    "                edge_attr: torch.Tensor,\n",
    "                b: torch,\n",
    "                edge_paths,\n",
    "                ptr) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        h′(l) = MHA(LN(h(l−1))) + h(l−1)\n",
    "        h(l) = FFN(LN(h′(l))) + h′(l)\n",
    "\n",
    "        :param x: node feature matrix\n",
    "        :param edge_attr: edge feature matrix\n",
    "        :param b: spatial Encoding matrix\n",
    "        :param edge_paths: pairwise node paths in edge indexes\n",
    "        :param ptr: batch pointer that shows graph indexes in batch of graphs\n",
    "        :return: torch.Tensor, node embeddings after Graphormer layer operations\n",
    "        \"\"\"\n",
    "        x_prime = self.attention(self.ln_1(x), edge_attr, b, edge_paths, ptr) + x\n",
    "        x_new = self.ff(self.ln_2(x_prime)) + x_prime\n",
    "\n",
    "        return x_new\n",
    "\n",
    "\n",
    "\n",
    "def floyd_warshall_source_to_all(G, source, cutoff=None):\n",
    "    if source not in G:\n",
    "        raise nx.NodeNotFound(\"Source {} not in G\".format(source))\n",
    "\n",
    "    edges = {edge: i for i, edge in enumerate(G.edges())}\n",
    "\n",
    "    level = 0  # the current level\n",
    "    nextlevel = {source: 1}  # list of nodes to check at next level\n",
    "    node_paths = {source: [source]}  # paths dictionary  (paths to key from source)\n",
    "    edge_paths = {source: []}\n",
    "\n",
    "    while nextlevel:\n",
    "        thislevel = nextlevel\n",
    "        nextlevel = {}\n",
    "        for v in thislevel:\n",
    "            for w in G[v]:\n",
    "                if w not in node_paths:\n",
    "                    node_paths[w] = node_paths[v] + [w]\n",
    "                    edge_paths[w] = edge_paths[v] + [edges[tuple(node_paths[w][-2:])]]\n",
    "                    nextlevel[w] = 1\n",
    "\n",
    "        level = level + 1\n",
    "\n",
    "        if (cutoff is not None and cutoff <= level):\n",
    "            break\n",
    "\n",
    "    return node_paths, edge_paths\n",
    "\n",
    "\n",
    "def all_pairs_shortest_path(G) -> Tuple[Dict[int, List[int]], Dict[int, List[int]]]:\n",
    "    paths = {n: floyd_warshall_source_to_all(G, n) for n in G}\n",
    "    node_paths = {n: paths[n][0] for n in paths}\n",
    "    edge_paths = {n: paths[n][1] for n in paths}\n",
    "    return node_paths, edge_paths\n",
    "\n",
    "\n",
    "def shortest_path_distance(data: Data) -> Tuple[Dict[int, List[int]], Dict[int, List[int]]]:\n",
    "    G = to_networkx(data)\n",
    "    node_paths, edge_paths = all_pairs_shortest_path(G)\n",
    "    return node_paths, edge_paths\n",
    "\n",
    "\n",
    "def batched_shortest_path_distance(data) -> Tuple[Dict[int, List[int]], Dict[int, List[int]]]:\n",
    "    graphs = [to_networkx(sub_data) for sub_data in data.to_data_list()]\n",
    "    relabeled_graphs = []\n",
    "    shift = 0\n",
    "    for i in range(len(graphs)):\n",
    "        num_nodes = graphs[i].number_of_nodes()\n",
    "        relabeled_graphs.append(nx.relabel_nodes(graphs[i], {i: i + shift for i in range(num_nodes)}))\n",
    "        shift += num_nodes\n",
    "\n",
    "    paths = [all_pairs_shortest_path(G) for G in relabeled_graphs]\n",
    "    node_paths = {}\n",
    "    edge_paths = {}\n",
    "\n",
    "    for path in paths:\n",
    "        for k, v in path[0].items():\n",
    "            node_paths[k] = v\n",
    "        for k, v in path[1].items():\n",
    "            edge_paths[k] = v\n",
    "\n",
    "    return node_paths, edge_paths\n",
    "\n",
    "\n",
    "\n",
    "class Graphormer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_layers: int,\n",
    "                 node_dim: int,\n",
    "                 input_edge_dim: int,\n",
    "                 edge_dim: int,\n",
    "                 n_heads: int,\n",
    "                 max_in_degree: int,\n",
    "                 max_out_degree: int,\n",
    "                 max_path_distance: int):\n",
    "        \"\"\"\n",
    "        :param num_layers: number of Graphormer layers\n",
    "        :param input_node_dim: input dimension of node features\n",
    "        :param node_dim: hidden dimensions of node features\n",
    "        :param input_edge_dim: input dimension of edge features\n",
    "        :param edge_dim: hidden dimensions of edge features\n",
    "        :param output_dim: number of output node features\n",
    "        :param n_heads: number of attention heads\n",
    "        :param max_in_degree: max in degree of nodes\n",
    "        :param max_out_degree: max in degree of nodes\n",
    "        :param max_path_distance: max pairwise distance between two nodes\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.node_dim = node_dim\n",
    "        self.input_edge_dim = input_edge_dim\n",
    "        self.edge_dim = edge_dim\n",
    "        self.n_heads = n_heads\n",
    "        self.max_in_degree = max_in_degree\n",
    "        self.max_out_degree = max_out_degree\n",
    "        self.max_path_distance = max_path_distance\n",
    "\n",
    "        self.edge_in_lin = nn.Linear(self.input_edge_dim, self.edge_dim)\n",
    "\n",
    "        self.centrality_encoding = CentralityEncoding(\n",
    "            max_in_degree=self.max_in_degree,\n",
    "            max_out_degree=self.max_out_degree,\n",
    "            node_dim=self.node_dim\n",
    "        )\n",
    "\n",
    "        self.spatial_encoding = SpatialEncoding(\n",
    "            max_path_distance=max_path_distance,\n",
    "        )\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            GraphormerEncoderLayer(\n",
    "                node_dim=self.node_dim,\n",
    "                edge_dim=self.edge_dim,\n",
    "                n_heads=self.n_heads,\n",
    "                max_path_distance=self.max_path_distance) for _ in range(self.num_layers)\n",
    "        ])\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, data: Union[Data]) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        :param data: input graph of batch of graphs\n",
    "        :return: torch.Tensor, output node embeddings\n",
    "        \"\"\"\n",
    "        x = data.x.float()\n",
    "        edge_index = data.edge_index.long()\n",
    "        edge_attr = data.edge_attr.float()\n",
    "\n",
    "        if type(data) == Data:\n",
    "            ptr = None\n",
    "            node_paths, edge_paths = shortest_path_distance(data)\n",
    "        else:\n",
    "            ptr = data.ptr\n",
    "            node_paths, edge_paths = batched_shortest_path_distance(data)\n",
    "\n",
    "\n",
    "        edge_attr = self.edge_in_lin(edge_attr)\n",
    "\n",
    "        x = self.centrality_encoding(x, edge_index)\n",
    "        b = self.spatial_encoding(x, node_paths)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, edge_attr, b, edge_paths, ptr)\n",
    "\n",
    "\n",
    "\n",
    "        return x\n",
    "        \n",
    "\n",
    "def to_graph_batch_edge_attr(seq, mask, adj_matrix, p=0.49):\n",
    "    res = []\n",
    "    for i in range(len(seq)):\n",
    "        m = adj_matrix[i] > p\n",
    "        res.append(Data(x=seq[i][mask[i]], edge_index=m.nonzero().T, edge_attr=adj_matrix[i][m].view(-1, 1)))\n",
    "    return Batch.from_data_list(res)\n",
    "\n",
    "\n",
    "class PytorchBatchWrapper(nn.Module):\n",
    "    def __init__(self, md):\n",
    "        super().__init__()\n",
    "        self.md = md\n",
    "\n",
    "    def forward(self, seq, mask, adj_matrix):\n",
    "        batch = to_graph_batch_edge_attr(seq, mask, adj_matrix)\n",
    "        out = self.md(batch)\n",
    "        out, _ = to_dense_batch(out, batch.batch)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Conv1D(nn.Conv1d):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.src_key_padding_mask = None\n",
    "\n",
    "    def forward(self, x, src_key_padding_mask=None):\n",
    "        if src_key_padding_mask is not None:\n",
    "            self.src_key_padding_mask = src_key_padding_mask\n",
    "        if self.src_key_padding_mask is not None:\n",
    "            x = torch.where(\n",
    "                self.src_key_padding_mask.unsqueeze(-1)\n",
    "                .expand(-1, -1, x.shape[-1])\n",
    "                .bool(),\n",
    "                torch.zeros_like(x),\n",
    "                x,\n",
    "            )\n",
    "        return super().forward(x.permute(0, 2, 1)).permute(0, 2, 1)\n",
    "\n",
    "\n",
    "class ResBlock(nn.Sequential):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__(\n",
    "            nn.LayerNorm(d_model), nn.GELU(), Conv1D(d_model, d_model, 3, padding=1)\n",
    "        )\n",
    "        self.src_key_padding_mask = None\n",
    "\n",
    "    def forward(self, x, src_key_padding_mask=None):\n",
    "        self[-1].src_key_padding_mask = (\n",
    "            src_key_padding_mask\n",
    "            if src_key_padding_mask is not None\n",
    "            else self.src_key_padding_mask\n",
    "        )\n",
    "        return x + super().forward(x)\n",
    "\n",
    "\n",
    "class Extractor(nn.Sequential):\n",
    "    def __init__(self, d_model, in_ch=4):\n",
    "        super().__init__(\n",
    "            nn.Embedding(in_ch, d_model // 4),\n",
    "            Conv1D(d_model // 4, d_model, 7, padding=3),\n",
    "            ResBlock(d_model),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, src_key_padding_mask=None):\n",
    "        for i in [1, 2]:\n",
    "            self[i].src_key_padding_mask = src_key_padding_mask\n",
    "        return super().forward(x)\n",
    "    \n",
    "    \n",
    "class GraphformerV0(nn.Module):\n",
    "    def __init__(self, dim=192, depth=12, head_size=32, graph_layers=4, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.extractor = Extractor(dim)\n",
    "        self.graph_layers =PytorchBatchWrapper(\n",
    "                    Graphormer(\n",
    "                    num_layers=graph_layers,\n",
    "                    node_dim=dim,\n",
    "                    input_edge_dim=1,\n",
    "                    edge_dim=8,\n",
    "                    n_heads=4,\n",
    "                    max_in_degree=5,\n",
    "                    max_out_degree=5,\n",
    "                    max_path_distance=5,\n",
    "                    )\n",
    "        )\n",
    "\n",
    "        self.proj_out = nn.Linear(dim, 2)\n",
    "\n",
    "    def forward(self, x0):\n",
    "        mask = x0[\"mask\"]\n",
    "        L0 = mask.shape[1]\n",
    "        Lmax = mask.sum(-1).max()\n",
    "        mask = mask[:, :Lmax]\n",
    "        x = x0[\"seq\"][:, :Lmax]\n",
    "        x = self.extractor(x, src_key_padding_mask=~mask)\n",
    "        x = self.graph_layers(x, mask, x0[\"bpp\"])\n",
    "        x = self.proj_out(x)\n",
    "        x = F.pad(x, (0, 0, 0, L0 - Lmax, 0, 0))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "#|eval: false\n",
    "from nbdev.doclinks import nbdev_export\n",
    "nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import sys\n",
    "# sys.path.append('..')\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# from rnacomp.dataset import LenMatchBatchSampler, RNA_DatasetBaselineSplitbppV0, DeviceDataLoader, RNA_DatasetBaselineSplitssV1, RNA_DatasetBaselineSplit, RNA_DatasetBaselineSplitbppV2\n",
    "\n",
    "# class CFG:\n",
    "#     path = Path(\"../data/\")\n",
    "#     pathbb = Path(\"../data/Ribonanza_bpp_files\")\n",
    "#     split_id = Path('../eda/fold_split.csv')\n",
    "#     pathss = Path(\"../eda/train_ss_vienna_rna.parquet\")\n",
    "#     bs = 16\n",
    "#     num_workers = 8\n",
    "#     device = 'cpu'\n",
    "#     adjnact_prob = 0.5\n",
    "\n",
    "\n",
    "\n",
    "# fns = list(CFG.pathbb.rglob(\"*.txt\"))\n",
    "# bpp_df = pd.DataFrame({\"bpp\": fns})\n",
    "# bpp_df['sequence_id'] = bpp_df['bpp'].apply(lambda x: x.stem)\n",
    "# ss = pd.read_parquet(CFG.pathss)[[\"sequence_id\", \"ss_full\"]]\n",
    "# df = pd.read_parquet(CFG.path/'train_data.parquet')\n",
    "# split = pd.read_csv(CFG.split_id)\n",
    "# df = pd.merge(df, split, on='sequence_id')\n",
    "# df = pd.merge(df, bpp_df, on='sequence_id')\n",
    "# df = pd.merge(df, ss, on='sequence_id')\n",
    "# df_train = df.query('is_train==True').reset_index(drop=True)\n",
    "# df_valid = df.query('is_train==False').reset_index(drop=True)\n",
    "\n",
    "# ds_val = RNA_DatasetBaselineSplitbppV2(df_valid, mode='eval')\n",
    "# ds_val_len = RNA_DatasetBaselineSplitbppV2(df_valid, mode='eval', mask_only=True)\n",
    "# sampler_val = torch.utils.data.SequentialSampler(ds_val_len)\n",
    "# len_sampler_val = LenMatchBatchSampler(sampler_val, batch_size=CFG.bs, \n",
    "#                drop_last=False)\n",
    "# dl_val= DeviceDataLoader(torch.utils.data.DataLoader(ds_val, \n",
    "#                batch_sampler=len_sampler_val, num_workers=CFG.num_workers), CFG.device)\n",
    "\n",
    "# batch = next(iter(dl_val))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#      out =  GraphformerV0()(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
