{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import arnie\n",
    "# import matplotlib.pyplot as plt\n",
    "# from arnie.bpps import bpps\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from pathlib import Path\n",
    "# import os\n",
    "# from tqdm import tqdm\n",
    "# import torch\n",
    "# import random\n",
    "# def matrix_to_three_columns_np(bpp_matrix):\n",
    "#     pos_1, pos_2 = np.nonzero(bpp_matrix)\n",
    "#     probabilities = bpp_matrix[pos_1, pos_2]\n",
    "#     result = np.column_stack((pos_1 + 1, pos_2 + 1, probabilities))\n",
    "#     return result.astype('float16')\n",
    "\n",
    "# def get_bpp(sequnce, package):\n",
    "#     return bpps(sequnce, package=package)\n",
    "\n",
    "\n",
    "# def save_bpp(row, save_dir, package):\n",
    "#     name = save_dir/f\"{row.sequence_id}.npy\"\n",
    "#     bpp = get_bpp(row.sequence, package)\n",
    "#     np.save(name, matrix_to_three_columns_np(bpp))\n",
    "    \n",
    "# pkg_name = \"contrafold_2\" #\"vienna_2\" #\n",
    "# path = Path('/mnt/e22b12fe-f946-49d6-be2c-4bd0bb62c767/slh/rna/eda/')\n",
    "# save_dir = path/f'bpp/{pkg_name}/'\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "# df = pd.read_parquet(path/'train_ss_vienna_rna.parquet')[['sequence_id', 'sequence']]\n",
    "# df\n",
    "\n",
    "# for i in tqdm(range(df.shape[0])):\n",
    "#     save_bpp(df.iloc[i], save_dir, pkg_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exx/.conda/envs/myenv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import random\n",
    "from scipy.sparse import coo_matrix\n",
    "import arnie\n",
    "import matplotlib.pyplot as plt\n",
    "from arnie.bpps import bpps\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.io import mmwrite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [04:33<00:00, 29.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def matrix_to_three_columns_np(bpp_matrix):\n",
    "    pos_1, pos_2 = np.nonzero(bpp_matrix)\n",
    "    probabilities = bpp_matrix[pos_1, pos_2]\n",
    "    # Create an empty structured array with desired data types for each column\n",
    "    if bpp_matrix.shape[-1] > 255:\n",
    "        dt = np.dtype([('pos_1', 'int'), ('pos_2', 'int'), ('probabilities', 'float16')])\n",
    "    else:\n",
    "        dt = np.dtype([('pos_1', 'uint8'), ('pos_2', 'uint8'), ('probabilities', 'float16')])\n",
    "        \n",
    "    result = np.zeros(len(pos_1), dtype=dt)\n",
    "    # Fill the structured array with values\n",
    "    result['pos_1'] = pos_1\n",
    "    result['pos_2'] = pos_2 \n",
    "    result['probabilities'] = probabilities\n",
    "    return result\n",
    "\n",
    "def get_bpp(sequnce, package):\n",
    "    return bpps(sequnce, package=package)\n",
    "\n",
    "def save_bpp(row, save_dir, package):\n",
    "    name = save_dir/f\"{row.sequence_id}.npy\"\n",
    "    try:\n",
    "        bpp = get_bpp(row.sequence, package)\n",
    "        np.save(name, matrix_to_three_columns_np(bpp))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "names = []\n",
    "def save_png(row, save_dir, package):\n",
    "    name = save_dir/f\"{row.sequence_id}.png\"\n",
    "    try:\n",
    "        bpp = get_bpp(row.sequence, package)\n",
    "        Image.fromarray((bpp* 255).astype('uint8')).save(name)\n",
    "    except:\n",
    "        names.append(name)\n",
    "        \n",
    "# def save_sparse(row, save_dir, package):\n",
    "#     name = save_dir/f\"{row.sequence_id}.mtx\"\n",
    "#     try:\n",
    "#         bpp = get_bpp(row.sequence, package).astype('float16')\n",
    "#         sparse = coo_matrix(bpp)\n",
    "#         mmwrite(name, sparse)\n",
    "#     except:\n",
    "#         names.append(name)\n",
    "        \n",
    "    \n",
    "pkg_name = \"contrafold_2\" \n",
    "path = Path('/mnt/e22b12fe-f946-49d6-be2c-4bd0bb62c767/slh/rna/eda/')\n",
    "save_dir = path/f'bpp/{pkg_name}/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "df = pd.read_parquet(path/'test_ss_vienna_rna.parquet')[['sequence_id', 'sequence']]\n",
    "df[\"L\"] = df['sequence'].map(len)\n",
    "df = df.query('L>250')\n",
    "df.sort_values(by='L',ascending=False, inplace=True)\n",
    "\n",
    "# Using joblib to parallelize the tasks\n",
    "results = Parallel(n_jobs=16)(delayed(save_bpp)(row, save_dir, pkg_name) for _, row in tqdm(df.iterrows(), total=df.shape[0]))\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8000 [00:00<?, ?it/s]100%|██████████| 8000/8000 [00:01<00:00, 6075.23it/s]\n"
     ]
    }
   ],
   "source": [
    "#fns = list(save_dir.glob('*.npy'))\n",
    "import shutil\n",
    "pkg_name = \"contrafold_2\" \n",
    "path = Path('/mnt/e22b12fe-f946-49d6-be2c-4bd0bb62c767/slh/rna/eda/')\n",
    "save_dir = path/f'bpp/{pkg_name}/'\n",
    "fns = [save_dir/f\"{i}.npy\" for i in df['sequence_id'].to_list()]\n",
    "new_dir  = path/f'bpp/{pkg_name}_8000/'\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "for fn in tqdm(fns):\n",
    "    shutil.copy(fn, new_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns = list(new_dir.glob('*.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_convert(filename, N):\n",
    "    \"\"\"\n",
    "    Load data from a .npy file and convert it to an N x N matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: Path to the .npy file.\n",
    "    - N: Dimension of the square matrix.\n",
    "\n",
    "    Returns:\n",
    "    - bpp_matrix: N x N matrix reconstructed from the input file.\n",
    "    \"\"\"\n",
    "    # Load the structured array from the .npy file\n",
    "    data = np.load(filename)\n",
    "\n",
    "    # Create an empty N x N matrix\n",
    "    bpp_matrix = np.zeros((N, N))\n",
    "\n",
    "    # Fill the matrix with the probabilities from the loaded data\n",
    "    bpp_matrix[data['pos_1'], data['pos_2']] = data['probabilities']\n",
    "\n",
    "    return bpp_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
