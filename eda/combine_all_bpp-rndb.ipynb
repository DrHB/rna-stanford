{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_rnafm(filename, seq_len, L_max):\n",
    "    \"\"\"\n",
    "    Load data from a .npy file and convert it to an N x N matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: Path to the .npy file.\n",
    "    - N: Dimension of the square matrix.\n",
    "\n",
    "    Returns:\n",
    "    - bpp_matrix: N x N matrix reconstructed from the input file.\n",
    "    \"\"\"\n",
    "    # Load the structured array from the .npy file\n",
    "    data = np.load(filename)\n",
    "\n",
    "    # Create an empty N x N matrix\n",
    "    bpp_matrix = np.zeros((seq_len, seq_len))\n",
    "\n",
    "    # Fill the matrix with the probabilities from the loaded data\n",
    "    bpp_matrix[data[\"pos_1\"], data[\"pos_2\"]] = data[\"probabilities\"]\n",
    "\n",
    "    bpp_matrix = bpp_matrix + bpp_matrix.T - np.diag(np.diag(bpp_matrix))\n",
    "    full = np.zeros((L_max, L_max))\n",
    "    full[:seq_len, :seq_len] = bpp_matrix\n",
    "    return torch.tensor(full)\n",
    "\n",
    "\n",
    "def generate_base_pair_matrixv1(file_path, L):\n",
    "    \"\"\"\n",
    "    Reads a TXT file of base pair probabilities and generates an n x n matrix.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the TXT file.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: An n x n matrix of base pair probabilities.\n",
    "    \"\"\"\n",
    "    # Read the data using pandas\n",
    "    data = pd.read_csv(file_path, sep=\" \", header=None, names=[\"pos1\", \"pos2\", \"prob\"])\n",
    "\n",
    "    # Find the largest position in the 'pos1' column\n",
    "    largest_position = data[\"pos1\"].max()\n",
    "\n",
    "    ids = torch.from_numpy(data[[\"pos1\", \"pos2\"]].values.astype(int))\n",
    "    matrix = torch.zeros((L, L))\n",
    "    matrix[ids[:, 0] - 1, ids[:, 1] - 1] = torch.from_numpy(data[\"prob\"].values).float()\n",
    "    matrix[ids[:, 1] - 1, ids[:, 0] - 1] = torch.from_numpy(data[\"prob\"].values).float()\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def extra_bpp_from_numpy(filename, N, seq_len=None):\n",
    "    \"\"\"\n",
    "    Load data from a .npy file and convert it to an N x N matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: Path to the .npy file.\n",
    "    - N: Dimension of the square matrix.\n",
    "\n",
    "    Returns:\n",
    "    - bpp_matrix: N x N matrix reconstructed from the input file.\n",
    "    \"\"\"\n",
    "    # Load the structured array from the .npy file\n",
    "    if filename.parent.stem in [\"rnafm\", \"rnaformerv1\"]:\n",
    "        full = load_rnafm(filename, seq_len, N)\n",
    "    else:\n",
    "        data = np.load(filename)\n",
    "        # Create an empty N x N matrix\n",
    "        bpp_matrix = np.zeros((N, N))\n",
    "        # Fill the matrix with the probabilities from the loaded data\n",
    "        bpp_matrix[data[\"pos_1\"], data[\"pos_2\"]] = data[\"probabilities\"]\n",
    "        full = torch.tensor(bpp_matrix)\n",
    "\n",
    "    return full\n",
    "\n",
    "def dot_to_adjacencyv0(dot_notation, n):\n",
    "    adjacency_matrix = np.zeros((n, n), dtype=int)\n",
    "    stack = []\n",
    "    for i, char in enumerate(dot_notation):\n",
    "        if char == \"(\":\n",
    "            stack.append(i)\n",
    "        elif char == \")\":\n",
    "            j = stack.pop()\n",
    "            adjacency_matrix[i][j] = adjacency_matrix[j][i] = 1\n",
    "\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    pathss = Path(\"../eda/rmdb_data.v1.3.0_ss.parquet\")\n",
    "    split_id = Path('../eda/fold_split.csv')\n",
    "    \n",
    "df = pd.read_parquet('rmdb_data.v1.3.0_ss.parquet')\n",
    "df['L'] = df['sequence'].apply(len)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence</th>\n",
       "      <th>ss_full</th>\n",
       "      <th>ss_full_mfe</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b2c4f7dfcbeb</td>\n",
       "      <td>GGGAAACUGCCUGAUGGAGGGGGAUAACUACUGGAAACGGUAGCUA...</td>\n",
       "      <td>(((..((...(((((((.(.((..((.((((((....)))))).))...</td>\n",
       "      <td>-35.500000</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c917ebd9ebb1</td>\n",
       "      <td>CGGAAACUGCCUGAUGGAGGGGGAUAACUACUGGAAACGGUAGCUA...</td>\n",
       "      <td>.((..((...(((((((.(.((..((.((((((....)))))).))...</td>\n",
       "      <td>-33.599998</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>85d63477c1f0</td>\n",
       "      <td>GCGAAACUGCCUGAUGGAGGGGGAUAACUACUGGAAACGGUAGCUA...</td>\n",
       "      <td>(((....)))(((((((.(.((..((.((((((....)))))).))...</td>\n",
       "      <td>-32.900002</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>362b98907e64</td>\n",
       "      <td>GGCAAACUGCCUGAUGGAGGGGGAUAACUACUGGAAACGGUAGCUA...</td>\n",
       "      <td>((((......(((((((.(.((..((.((((((....)))))).))...</td>\n",
       "      <td>-36.400002</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9735bca2a802</td>\n",
       "      <td>GGGUAACUGCCUGAUGGAGGGGGAUAACUACUGGAAACGGUAGCUA...</td>\n",
       "      <td>(((((....((.(((((.(.((..((.((((((....)))))).))...</td>\n",
       "      <td>-37.599998</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66818</th>\n",
       "      <td>49ab4913e71d</td>\n",
       "      <td>AAUAAGAGAGUGUAUCUAGGGUUCCGGUCAAUAGAUGUCUGGUCCG...</td>\n",
       "      <td>.....((((.((((((...((..((((.((.....)).)))).))....</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66819</th>\n",
       "      <td>086ef0f2e5ec</td>\n",
       "      <td>AAUAAGAGAGUGUAUCUAGGGUUCCGGUCAAUAGAUGUCUGGUCCG...</td>\n",
       "      <td>.....((((.((((((...((..((((.((.....)).)))).))....</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66820</th>\n",
       "      <td>2750b76343ee</td>\n",
       "      <td>AAUAAGAGAGUGUAUCUAGGGUUCCGGUCAAUAGAUGUCUGGUCCG...</td>\n",
       "      <td>......(((.....))).(..(((((((..(((..((((((........</td>\n",
       "      <td>-54.099998</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66821</th>\n",
       "      <td>412de5b993a1</td>\n",
       "      <td>AAUAAGAGAGUGUAUCUAGGGUUCCGGUCAAUAGAUGUCUGGUCCG...</td>\n",
       "      <td>......(((.....))).(..(((((((..(((..((((((........</td>\n",
       "      <td>-54.099998</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66822</th>\n",
       "      <td>70c85f27f478</td>\n",
       "      <td>AAUAAGAGAGUGUAUCUAGGGUUCCGGUCAAUAGAUGUCUGGUCCG...</td>\n",
       "      <td>......(((.....))).(..(((((((..(((..((((((........</td>\n",
       "      <td>-54.099998</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66823 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sequence_id                                           sequence  \\\n",
       "0      b2c4f7dfcbeb  GGGAAACUGCCUGAUGGAGGGGGAUAACUACUGGAAACGGUAGCUA...   \n",
       "1      c917ebd9ebb1  CGGAAACUGCCUGAUGGAGGGGGAUAACUACUGGAAACGGUAGCUA...   \n",
       "2      85d63477c1f0  GCGAAACUGCCUGAUGGAGGGGGAUAACUACUGGAAACGGUAGCUA...   \n",
       "3      362b98907e64  GGCAAACUGCCUGAUGGAGGGGGAUAACUACUGGAAACGGUAGCUA...   \n",
       "4      9735bca2a802  GGGUAACUGCCUGAUGGAGGGGGAUAACUACUGGAAACGGUAGCUA...   \n",
       "...             ...                                                ...   \n",
       "66818  49ab4913e71d  AAUAAGAGAGUGUAUCUAGGGUUCCGGUCAAUAGAUGUCUGGUCCG...   \n",
       "66819  086ef0f2e5ec  AAUAAGAGAGUGUAUCUAGGGUUCCGGUCAAUAGAUGUCUGGUCCG...   \n",
       "66820  2750b76343ee  AAUAAGAGAGUGUAUCUAGGGUUCCGGUCAAUAGAUGUCUGGUCCG...   \n",
       "66821  412de5b993a1  AAUAAGAGAGUGUAUCUAGGGUUCCGGUCAAUAGAUGUCUGGUCCG...   \n",
       "66822  70c85f27f478  AAUAAGAGAGUGUAUCUAGGGUUCCGGUCAAUAGAUGUCUGGUCCG...   \n",
       "\n",
       "                                                 ss_full  ss_full_mfe    L  \n",
       "0      (((..((...(((((((.(.((..((.((((((....)))))).))...   -35.500000  110  \n",
       "1      .((..((...(((((((.(.((..((.((((((....)))))).))...   -33.599998  110  \n",
       "2      (((....)))(((((((.(.((..((.((((((....)))))).))...   -32.900002  110  \n",
       "3      ((((......(((((((.(.((..((.((((((....)))))).))...   -36.400002  110  \n",
       "4      (((((....((.(((((.(.((..((.((((((....)))))).))...   -37.599998  110  \n",
       "...                                                  ...          ...  ...  \n",
       "66818  .....((((.((((((...((..((((.((.....)).)))).))....   -53.000000  179  \n",
       "66819  .....((((.((((((...((..((((.((.....)).)))).))....   -53.000000  180  \n",
       "66820  ......(((.....))).(..(((((((..(((..((((((........   -54.099998  181  \n",
       "66821  ......(((.....))).(..(((((((..(((..((((((........   -54.099998  182  \n",
       "66822  ......(((.....))).(..(((((((..(((..((((((........   -54.099998  183  \n",
       "\n",
       "[66823 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT = Path('bpp/rmdb_data/comb')\n",
    "os.makedirs(OUT, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 66823/66823 [03:05<00:00, 360.15it/s]\n"
     ]
    }
   ],
   "source": [
    "def convert(row):\n",
    "    L = row.L\n",
    "    bpp_fn = row.sequence_id  # You might need to convert this to Path object if it's not already.\n",
    "    ss_full = row.ss_full\n",
    "\n",
    "    extra_bpp = [\"vienna_2\", \"contrafold_2\", \"rnaformerv1\", 'eternafold', 'rnafm']\n",
    "    extra_bpp_path = Path(\"bpp/rmdb_data\")\n",
    "    names = [\"vienna_2\", \"contrafold_2\", \"rnaformerv1\", 'eternafold', 'rnafm', 'ss_vienna']\n",
    "\n",
    "    bpp_extra = [\n",
    "        extra_bpp_from_numpy(extra_bpp_path / f\"{i}/{bpp_fn}.npy\", L, seq_len=L).numpy()\n",
    "        for i in extra_bpp\n",
    "    ]  + [dot_to_adjacencyv0(ss_full, L)]\n",
    "    \n",
    "    bpp_extra_d = {s : np.array(d).astype(np.float16) for s, d in zip(names, bpp_extra)}\n",
    "\n",
    "    # Assuming OUT is a predefined path\n",
    "    np.savez_compressed(OUT / f\"{row.sequence_id}.npz\", **bpp_extra_d)\n",
    "\n",
    "# This function will be used by Pool.map which expects a single-argument function\n",
    "def worker(index):\n",
    "    row = df.iloc[index]\n",
    "    convert(row)\n",
    "    \n",
    "with Pool(processes=16) as pool:\n",
    "    max_ = df.shape[0]\n",
    "    with tqdm(total=max_) as pbar:\n",
    "        for _ in pool.imap_unordered(worker, range(max_)):\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_dict(row):\n",
    "    L = row.L\n",
    "    bpp_fn = row.sequence_id  # You might need to convert this to Path object if it's not already.\n",
    "    ss_full = row.ss_full\n",
    "\n",
    "    extra_bpp = [\"vienna_2\", \"contrafold_2\", \"rnaformerv1\", 'eternafold', 'rnafm']\n",
    "    extra_bpp_path = Path(\"bpp/rmdb_data\")\n",
    "    names = [\"vienna_2\", \"contrafold_2\", \"rnaformerv1\", 'eternafold', 'rnafm', 'ss_vienna']\n",
    "\n",
    "    bpp_extra = [\n",
    "        extra_bpp_from_numpy(extra_bpp_path / f\"{i}/{bpp_fn}.npy\", L, seq_len=L).numpy()\n",
    "        for i in extra_bpp\n",
    "    ]  + [dot_to_adjacencyv0(ss_full, L)]\n",
    "    \n",
    "    bpp_extra_d = {s : np.array(d).astype(np.float16) for s, d in zip(names, bpp_extra)}\n",
    "    return bpp_extra_d\n",
    "\n",
    "def get_saved(row):\n",
    "    L = row.L\n",
    "    bpp_fn = row.sequence_id  # You might need to convert this to Path object if it's not already.\n",
    "    ss_full = row.ss_full\n",
    "\n",
    "    extra_bpp = [\"vienna_2\", \"contrafold_2\", \"rnaformerv\", 'eternafold', 'rnafm', 'ss_vienna']\n",
    "    OUT = Path('bpp/rmdb_data/comb')  # replace with your actual output path\n",
    "    data = np.load(OUT / f\"{row.sequence_id}.npz\")\n",
    "    return {i: data[i] for i in extra_bpp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_original_dict(df.iloc[1491])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"L>300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in data.keys():\n",
    "    print(i)\n",
    "    plt.imshow(data[i])\n",
    "    plt.pause(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(saved, original):\n",
    "    assert (np.all([np.allclose(saved[k], original[k]) for k in saved.keys()]))\n",
    "    \n",
    "indexs = np.random.choice(np.arange(df.shape[0]), 100)\n",
    "for index in tqdm(indexs):\n",
    "    row = df.iloc[index]\n",
    "    saved = get_saved(row)\n",
    "    original = get_original_dict(row)\n",
    "    compare(saved, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.choice"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
