{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_rnafm(filename, seq_len, L_max):\n",
    "    \"\"\"\n",
    "    Load data from a .npy file and convert it to an N x N matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: Path to the .npy file.\n",
    "    - N: Dimension of the square matrix.\n",
    "\n",
    "    Returns:\n",
    "    - bpp_matrix: N x N matrix reconstructed from the input file.\n",
    "    \"\"\"\n",
    "    # Load the structured array from the .npy file\n",
    "    data = np.load(filename)\n",
    "\n",
    "    # Create an empty N x N matrix\n",
    "    bpp_matrix = np.zeros((seq_len, seq_len))\n",
    "\n",
    "    # Fill the matrix with the probabilities from the loaded data\n",
    "    bpp_matrix[data[\"pos_1\"], data[\"pos_2\"]] = data[\"probabilities\"]\n",
    "\n",
    "    bpp_matrix = bpp_matrix + bpp_matrix.T - np.diag(np.diag(bpp_matrix))\n",
    "    full = np.zeros((L_max, L_max))\n",
    "    full[:seq_len, :seq_len] = bpp_matrix\n",
    "    return torch.tensor(full)\n",
    "\n",
    "\n",
    "def generate_base_pair_matrixv1(file_path, L):\n",
    "    \"\"\"\n",
    "    Reads a TXT file of base pair probabilities and generates an n x n matrix.\n",
    "\n",
    "    Args:\n",
    "    - file_path (str): Path to the TXT file.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: An n x n matrix of base pair probabilities.\n",
    "    \"\"\"\n",
    "    # Read the data using pandas\n",
    "    data = pd.read_csv(file_path, sep=\" \", header=None, names=[\"pos1\", \"pos2\", \"prob\"])\n",
    "\n",
    "    # Find the largest position in the 'pos1' column\n",
    "    largest_position = data[\"pos1\"].max()\n",
    "\n",
    "    ids = torch.from_numpy(data[[\"pos1\", \"pos2\"]].values.astype(int))\n",
    "    matrix = torch.zeros((L, L))\n",
    "    matrix[ids[:, 0] - 1, ids[:, 1] - 1] = torch.from_numpy(data[\"prob\"].values).float()\n",
    "    matrix[ids[:, 1] - 1, ids[:, 0] - 1] = torch.from_numpy(data[\"prob\"].values).float()\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def extra_bpp_from_numpy(filename, N, seq_len=None):\n",
    "    \"\"\"\n",
    "    Load data from a .npy file and convert it to an N x N matrix.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: Path to the .npy file.\n",
    "    - N: Dimension of the square matrix.\n",
    "\n",
    "    Returns:\n",
    "    - bpp_matrix: N x N matrix reconstructed from the input file.\n",
    "    \"\"\"\n",
    "    # Load the structured array from the .npy file\n",
    "    if filename.parent.stem in [\"rnafm\", \"rnaformerv1\"]:\n",
    "        full = load_rnafm(filename, seq_len, N)\n",
    "    else:\n",
    "        data = np.load(filename)\n",
    "        # Create an empty N x N matrix\n",
    "        bpp_matrix = np.zeros((N, N))\n",
    "        # Fill the matrix with the probabilities from the loaded data\n",
    "        bpp_matrix[data[\"pos_1\"], data[\"pos_2\"]] = data[\"probabilities\"]\n",
    "        full = torch.tensor(bpp_matrix)\n",
    "\n",
    "    return full\n",
    "\n",
    "def dot_to_adjacencyv0(dot_notation, n):\n",
    "    adjacency_matrix = np.zeros((n, n), dtype=int)\n",
    "    stack = []\n",
    "    for i, char in enumerate(dot_notation):\n",
    "        if char == \"(\":\n",
    "            stack.append(i)\n",
    "        elif char == \")\":\n",
    "            j = stack.pop()\n",
    "            adjacency_matrix[i][j] = adjacency_matrix[j][i] = 1\n",
    "\n",
    "    return adjacency_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    path = Path(\"../data/\")\n",
    "    pathbb = Path(\"../data/Ribonanza_bpp_files\")\n",
    "    pathss = Path(\"../eda/train_ss_vienna_rna.parquet\")\n",
    "    split_id = Path('../eda/fold_split.csv')\n",
    "    \n",
    "fns = list(CFG.pathbb.rglob(\"*.txt\"))\n",
    "bpp_df = pd.DataFrame({\"bpp\": fns})\n",
    "bpp_df['sequence_id'] = bpp_df['bpp'].apply(lambda x: x.stem)\n",
    "bpp_df.drop_duplicates(subset = 'sequence_id', inplace=True)\n",
    "df = pd.concat([pd.read_parquet('../eda/train_ss_vienna_rna.parquet'),\n",
    "                pd.read_parquet('../eda/test_ss_vienna_rna.parquet')])\n",
    "df = df.drop_duplicates(subset=['sequence_id']).reset_index(drop=True)\n",
    "df = pd.merge(df, bpp_df, on='sequence_id')\n",
    "df['L'] = df['sequence'].apply(len)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUT = Path('bpp/comb')\n",
    "# os.makedirs(OUT, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert(row):\n",
    "#     L = row.L\n",
    "#     bpp_fn = row.bpp  # You might need to convert this to Path object if it's not already.\n",
    "#     ss_full = row.ss_full\n",
    "\n",
    "#     extra_bpp = [\"vienna_2\", \"contrafold_2\", \"rnaformerv1\", \"rnaformer\"]\n",
    "#     extra_bpp_path = Path(\"bpp\")\n",
    "#     names = ['vienna_2', 'contrafold_2', 'rnaformerv1', \"rnaformer\", 'bpp_org', 'ss_vienna']\n",
    "\n",
    "#     bpp_extra = [\n",
    "#         extra_bpp_from_numpy(extra_bpp_path / f\"{i}/{bpp_fn.stem}.npy\", L, seq_len=L).numpy()\n",
    "#         for i in extra_bpp\n",
    "#     ] + [generate_base_pair_matrixv1(bpp_fn, L).numpy().astype(np.float16)] + [dot_to_adjacencyv0(ss_full, L)]\n",
    "\n",
    "#     bpp_extra_d = {s : np.array(d).astype(np.float16) for s, d in zip(names, bpp_extra)}\n",
    "\n",
    "#     # Assuming OUT is a predefined path\n",
    "#     OUT = Path('bpp/comb')  # replace with your actual output path\n",
    "#     np.savez_compressed(OUT / f\"{row.sequence_id}.npz\", **bpp_extra_d)\n",
    "\n",
    "# # This function will be used by Pool.map which expects a single-argument function\n",
    "# def worker(index):\n",
    "#     row = df.iloc[index]\n",
    "#     convert(row)\n",
    "    \n",
    "# # with Pool(processes=cpu_count()) as pool:\n",
    "# #     max_ = df.shape[0]\n",
    "# #     with tqdm(total=max_) as pbar:\n",
    "# #         for _ in pool.imap_unordered(worker, range(max_)):\n",
    "# #             pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# worker(766614)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_dict(row):\n",
    "    L = row.L\n",
    "    bpp_fn = row.bpp  # You might need to convert this to Path object if it's not already.\n",
    "    ss_full = row.ss_full\n",
    "\n",
    "    extra_bpp = [\"vienna_2\", \"contrafold_2\", \"rnaformerv1\", \"rnaformer\"]\n",
    "    extra_bpp_path = Path(\"bpp\")\n",
    "    names = ['vienna_2', 'contrafold_2', 'rnaformerv1', \"rnaformer\", 'bpp_org', 'ss_vienna']\n",
    "\n",
    "    bpp_extra = [\n",
    "        extra_bpp_from_numpy(extra_bpp_path / f\"{i}/{bpp_fn.stem}.npy\", L, seq_len=L).numpy()\n",
    "        for i in extra_bpp\n",
    "    ] + [generate_base_pair_matrixv1(bpp_fn, L).numpy().astype(np.float16)] + [dot_to_adjacencyv0(ss_full, L)]\n",
    "\n",
    "    bpp_extra_d = {s : np.array(d).astype(np.float16) for s, d in zip(names, bpp_extra)}\n",
    "    return bpp_extra_d\n",
    "\n",
    "def get_saved(row):\n",
    "    L = row.L\n",
    "    bpp_fn = row.bpp  # You might need to convert this to Path object if it's not already.\n",
    "    ss_full = row.ss_full\n",
    "\n",
    "    extra_bpp = [\"vienna_2\", \"contrafold_2\", \"rnaformerv1\", \"rnaformer\"]\n",
    "    OUT = Path('bpp/comb')  # replace with your actual output path\n",
    "    data = np.load(OUT / f\"{row.sequence_id}.npz\")\n",
    "    return {i: data[i] for i in extra_bpp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saved: {len(saved)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 74685/100000 [21:02<07:08, 59.14it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/opt/slh/rna/eda/combine_all_bpp.ipynb Cell 17\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6772617068222c2273657474696e6773223a7b22686f7374223a227373683a2f2f31302e302e302e323533227d7d/opt/slh/rna/eda/combine_all_bpp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m saved \u001b[39m=\u001b[39m get_saved(row)\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6772617068222c2273657474696e6773223a7b22686f7374223a227373683a2f2f31302e302e302e323533227d7d/opt/slh/rna/eda/combine_all_bpp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m original \u001b[39m=\u001b[39m get_original_dict(row)\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6772617068222c2273657474696e6773223a7b22686f7374223a227373683a2f2f31302e302e302e323533227d7d/opt/slh/rna/eda/combine_all_bpp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m compare(saved, original)\n",
      "\u001b[1;32m/opt/slh/rna/eda/combine_all_bpp.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6772617068222c2273657474696e6773223a7b22686f7374223a227373683a2f2f31302e302e302e323533227d7d/opt/slh/rna/eda/combine_all_bpp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompare\u001b[39m(saved, original):\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6772617068222c2273657474696e6773223a7b22686f7374223a227373683a2f2f31302e302e302e323533227d7d/opt/slh/rna/eda/combine_all_bpp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39massert\u001b[39;00m (np\u001b[39m.\u001b[39mall([np\u001b[39m.\u001b[39mallclose(saved[k], original[k]) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m saved\u001b[39m.\u001b[39mkeys()]))\n",
      "\u001b[1;32m/opt/slh/rna/eda/combine_all_bpp.ipynb Cell 17\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6772617068222c2273657474696e6773223a7b22686f7374223a227373683a2f2f31302e302e302e323533227d7d/opt/slh/rna/eda/combine_all_bpp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompare\u001b[39m(saved, original):\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6772617068222c2273657474696e6773223a7b22686f7374223a227373683a2f2f31302e302e302e323533227d7d/opt/slh/rna/eda/combine_all_bpp.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39massert\u001b[39;00m (np\u001b[39m.\u001b[39mall([np\u001b[39m.\u001b[39;49mallclose(saved[k], original[k]) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m saved\u001b[39m.\u001b[39mkeys()]))\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mallclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/numeric.py:2265\u001b[0m, in \u001b[0;36mallclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2194\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_allclose_dispatcher)\n\u001b[1;32m   2195\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mallclose\u001b[39m(a, b, rtol\u001b[39m=\u001b[39m\u001b[39m1.e-5\u001b[39m, atol\u001b[39m=\u001b[39m\u001b[39m1.e-8\u001b[39m, equal_nan\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   2196\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2197\u001b[0m \u001b[39m    Returns True if two arrays are element-wise equal within a tolerance.\u001b[39;00m\n\u001b[1;32m   2198\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2263\u001b[0m \n\u001b[1;32m   2264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2265\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mall\u001b[39m(isclose(a, b, rtol\u001b[39m=\u001b[39;49mrtol, atol\u001b[39m=\u001b[39;49matol, equal_nan\u001b[39m=\u001b[39;49mequal_nan))\n\u001b[1;32m   2266\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(res)\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36misclose\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/numeric.py:2375\u001b[0m, in \u001b[0;36misclose\u001b[0;34m(a, b, rtol, atol, equal_nan)\u001b[0m\n\u001b[1;32m   2373\u001b[0m yfin \u001b[39m=\u001b[39m isfinite(y)\n\u001b[1;32m   2374\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(xfin) \u001b[39mand\u001b[39;00m \u001b[39mall\u001b[39m(yfin):\n\u001b[0;32m-> 2375\u001b[0m     \u001b[39mreturn\u001b[39;00m within_tol(x, y, atol, rtol)\n\u001b[1;32m   2376\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2377\u001b[0m     finite \u001b[39m=\u001b[39m xfin \u001b[39m&\u001b[39m yfin\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/core/numeric.py:2356\u001b[0m, in \u001b[0;36misclose.<locals>.within_tol\u001b[0;34m(x, y, atol, rtol)\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwithin_tol\u001b[39m(x, y, atol, rtol):\n\u001b[1;32m   2355\u001b[0m     \u001b[39mwith\u001b[39;00m errstate(invalid\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m-> 2356\u001b[0m         \u001b[39mreturn\u001b[39;00m less_equal(\u001b[39mabs\u001b[39;49m(x\u001b[39m-\u001b[39;49my), atol \u001b[39m+\u001b[39m rtol \u001b[39m*\u001b[39m \u001b[39mabs\u001b[39m(y))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def compare(saved, original):\n",
    "    assert (np.all([np.allclose(saved[k], original[k]) for k in saved.keys()]))\n",
    "    \n",
    "indexs = np.random.choice(np.arange(df.shape[0]), 100000, replace=False)\n",
    "for index in tqdm(indexs):\n",
    "    row = df.iloc[index]\n",
    "    saved = get_saved(row)\n",
    "    original = get_original_dict(row)\n",
    "    compare(saved, original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(row):\n",
    "    L = row.L\n",
    "    bpp_fn = row.bpp  # You might need to convert this to Path object if it's not already.\n",
    "    ss_full = row.ss_full\n",
    "\n",
    "    extra_bpp = [\"vienna_2\", \"contrafold_2\", \"rnaformerv1\", \"rnaformer\"]\n",
    "    extra_bpp_path = Path(\"bpp\")\n",
    "    names = ['vienna_2', 'contrafold_2', 'rnaformerv1', \"rnaformer\", 'bpp_org', 'ss_vienna']\n",
    "\n",
    "    bpp_extra = [\n",
    "        extra_bpp_from_numpy(extra_bpp_path / f\"{i}/{bpp_fn.stem}.npy\", L, seq_len=L).numpy()\n",
    "        for i in extra_bpp\n",
    "    ] + [generate_base_pair_matrixv1(bpp_fn, L).numpy().astype(np.float16)] + [dot_to_adjacencyv0(ss_full, L)]\n",
    "\n",
    "    bpp_extra_d = {s : np.array(d).astype(np.float16) for s, d in zip(names, bpp_extra)}\n",
    "\n",
    "    # Assuming OUT is a predefined path\n",
    "    OUT = Path('bpp/comb')  # replace with your actual output path\n",
    "    np.savez_compressed(OUT / f\"{row.sequence_id}.npz\", **bpp_extra_d)\n",
    "\n",
    "# This function will be used by Pool.map which expects a single-argument function\n",
    "def worker(index):\n",
    "    row = df.iloc[index]\n",
    "    print(row)\n",
    "    convert(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_id                                         f67c23ccfa8c\n",
      "sequence       GGGAACGACUCGAGUAGAGUCGAAAAGGCAGGGCCGGAGGUGAUGG...\n",
      "ss_full        .....((((((.....))))))....(((...))).(((.((((((...\n",
      "ss_full_mfe                                           -78.900002\n",
      "ss_roi         (((...))).(((.(((((((((((...((((.((((...)))).)...\n",
      "ss_roi_mfe                                            -69.400002\n",
      "bpp            ../data/Ribonanza_bpp_files/extra_data/2/4/f/f...\n",
      "L                                                            177\n",
      "Name: 308050, dtype: object\n"
     ]
    }
   ],
   "source": [
    "worker(308050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
