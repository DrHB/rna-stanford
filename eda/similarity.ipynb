{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import torch \n",
    "import random\n",
    "import os\n",
    "import seaborn as sbn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed_everything(2023)\n",
    "\n",
    "\n",
    "def parquet_to_fasta(parquet_file_path, fasta_file_path):\n",
    "    # Read the parquet file using Polars\n",
    "    df = pl.read_parquet(parquet_file_path)\n",
    "    \n",
    "    # Check if the required columns are present in the DataFrame\n",
    "\n",
    "\n",
    "    # Convert to Pandas DataFrame\n",
    "    df_pandas = df.to_pandas().drop_duplicates(subset=['sequence_id'])\n",
    "    \n",
    "    # Open a file to write the FASTA format\n",
    "    with open(fasta_file_path, 'w') as fasta_file:\n",
    "        # Iterate through each row in the Pandas DataFrame\n",
    "        for _, row in tqdm(df_pandas.iterrows()):\n",
    "            sequence_id = row['sequence_id']\n",
    "            sequence = row['sequence']\n",
    "            sequence = sequence[26:-21]\n",
    "            fasta_file.write(f\">{sequence_id}\\n{sequence}\\n\")\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "#code to convert output to pandas dataframe\n",
    "# Initialize an empty list to collect rows\n",
    "def read_clstr(fn = \"similar_to_test.clstr\"):\n",
    "    rows = []\n",
    "\n",
    "    # Read the cluster file\n",
    "    with open(fn, \"r\") as f:\n",
    "        current_cluster = None\n",
    "        for line in f:\n",
    "            if line.startswith(\">Cluster\"):\n",
    "                current_cluster = int(line.split()[-1])\n",
    "            else:\n",
    "                # Parse the sequence line\n",
    "                parts = line.strip().split(\"\\t\")\n",
    "                index = int(parts[0])\n",
    "                length = int(parts[1].split(\"nt,\")[0])\n",
    "                seq_id = parts[1].split(\">\")[-1].split(\"...\")[0]\n",
    "                is_rep = \"*\" in line\n",
    "                identity = float(parts[-1].split(\"/\")[-1].rstrip(\"%\")) if \"at\" in line else 100.0\n",
    "\n",
    "                # Append this as a row\n",
    "                rows.append({\n",
    "                    \"cluster\": current_cluster,\n",
    "                    \"index\": index,\n",
    "                    \"length\": length,\n",
    "                    \"sequence_id\": seq_id,\n",
    "                    \"is_Representative\": is_rep,\n",
    "                    \"identity_To_Rep\": identity\n",
    "                })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Convert to a DataFrame\n",
    "\n",
    "def read_fasta_ids(filename):\n",
    "    seq_ids = set()\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('>'):\n",
    "                # Extract the sequence ID from the line; adjust the parsing based on your specific ID format\n",
    "                seq_id = line.split()[0].lstrip('>')\n",
    "                seq_ids.add(seq_id)\n",
    "    return seq_ids\n",
    "\n",
    "def filter_clusters(group):\n",
    "    return ('Train' in group['source'].values) and ('Test' in group['source'].values) and len(group) > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a file in `fasta` format. I'll use `train_ss` for this, as it already contains unique `sequence_id` and `sequence` columns. If you prefer to use the original file, make sure to adjust the `code` to eliminate duplicate, I also removed adapter sequnces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parquet_file_path = \"train_ss_vienna_rna.parquet\"\n",
    "fasta_file_path = \"train_seq.fasta\"\n",
    "parquet_to_fasta(parquet_file_path, fasta_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parquet_file_path = \"test_ss_vienna_rna.parquet\"\n",
    "fasta_file_path = \"test_seq.fasta\"\n",
    "parquet_to_fasta(parquet_file_path, fasta_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have `train_seq.fasta` and `test_seq.fasta` files. Let's run the clustering command next. The output will include two files named `similar_to_test`, but we are mainly interested in the `.clstr` file. This file clusters the `train` and `test` sequences that are, in our case, `85%` similar. Some clusters may be empty, while others will contain `sequence_ids`. Each cluster will also have a representative sequence. Additionally, there will be a column called `Identity_To_Re`p, which indicates how identical the sequences within the cluster are to the `representative` sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-M memoery -T threads\n",
    "#sudo cd-hit-est-2d -i test_seq.fasta -i2 train_seq.fasta -c 0.88 -o similar_to_test -T 32 -M 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df = read_clstr()\n",
    "train_ids = read_fasta_ids('train_seq.fasta')\n",
    "test_ids = read_fasta_ids('test_seq.fasta')\n",
    "#lets add column source which will iclude if sequnce belong to train or to test\n",
    "df['source'] = df['sequence_ID'].apply(lambda x: 'Train' if x in train_ids else ('Test' if x in test_ids else 'Unknown'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lets eliminate all single clusters .. and only keep clusters that has atelast one train and test sequences in them \n",
    "filtered_df = df.groupby('cluster').filter(filter_clusters)\n",
    "#lest count how many sequnces are from train and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df[\"source\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPLIT GENERATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets try to develop validatiaon dataset, we gonna cluster train with cut off 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!sudo cd-hit-est -i train_seq.fasta -c 0.80 -o clustered_train -T 44 -M 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(806573, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read the clusterd file \n",
    "df = read_clstr('clustered_train.clstr')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>index</th>\n",
       "      <th>length</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>is_Representative</th>\n",
       "      <th>identity_To_Rep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>d62116c4c8f0</td>\n",
       "      <td>False</td>\n",
       "      <td>83.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>2e291021606c</td>\n",
       "      <td>False</td>\n",
       "      <td>82.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>9c4e99a4c2ba</td>\n",
       "      <td>False</td>\n",
       "      <td>89.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>cc2c6b77b4bf</td>\n",
       "      <td>False</td>\n",
       "      <td>83.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>f2eb45fbe514</td>\n",
       "      <td>False</td>\n",
       "      <td>86.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806568</th>\n",
       "      <td>317733</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>4eb60e538293</td>\n",
       "      <td>True</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806569</th>\n",
       "      <td>317734</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>21d1734994ca</td>\n",
       "      <td>True</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806570</th>\n",
       "      <td>317735</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>a8404fb3410c</td>\n",
       "      <td>True</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806571</th>\n",
       "      <td>317736</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>230e324ae8dc</td>\n",
       "      <td>True</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806572</th>\n",
       "      <td>317737</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>d65fe31114e0</td>\n",
       "      <td>True</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>806573 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cluster  index  length   sequence_id  is_Representative  \\\n",
       "0             0      0     130  d62116c4c8f0              False   \n",
       "1             0      1     130  2e291021606c              False   \n",
       "2             0      2     130  9c4e99a4c2ba              False   \n",
       "3             0      3     130  cc2c6b77b4bf              False   \n",
       "4             0      4     130  f2eb45fbe514              False   \n",
       "...         ...    ...     ...           ...                ...   \n",
       "806568   317733      0      68  4eb60e538293               True   \n",
       "806569   317734      0      68  21d1734994ca               True   \n",
       "806570   317735      0      68  a8404fb3410c               True   \n",
       "806571   317736      0      68  230e324ae8dc               True   \n",
       "806572   317737      0      68  d65fe31114e0               True   \n",
       "\n",
       "        identity_To_Rep  \n",
       "0                 83.85  \n",
       "1                 82.31  \n",
       "2                 89.23  \n",
       "3                 83.85  \n",
       "4                 86.92  \n",
       "...                 ...  \n",
       "806568           100.00  \n",
       "806569           100.00  \n",
       "806570           100.00  \n",
       "806571           100.00  \n",
       "806572           100.00  \n",
       "\n",
       "[806573 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_number_of_clusters: (93029,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"unique_number_of_clusters: {df['cluster'].value_counts()[df['cluster'].value_counts() > 1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([130, 159, 123, 108,  68])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"length\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lest get SNR data \n",
    "sr_df = pd.read_parquet('../data/train_data.parquet')\n",
    "sr_df[\"L\"] = sr_df[\"sequence\"].map(len)\n",
    "sr_df = sr_df.groupby(\"sequence_id\")[[\"SN_filter\", \"L\"]].agg(\"mean\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>SN_filter</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00005a0b365f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00006c296445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000c9fe9c6f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0000d87cab97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000dadc9e14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806568</th>\n",
       "      <td>ffffde700333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806569</th>\n",
       "      <td>ffffe6075b10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806570</th>\n",
       "      <td>ffffea5adcdc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806571</th>\n",
       "      <td>fffff1a0b9c7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806572</th>\n",
       "      <td>fffff856246f</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>806573 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sequence_id  SN_filter      L\n",
       "0       00005a0b365f        0.0  177.0\n",
       "1       00006c296445        0.0  177.0\n",
       "2       0000c9fe9c6f        0.0  177.0\n",
       "3       0000d87cab97        1.0  177.0\n",
       "4       0000dadc9e14        0.0  177.0\n",
       "...              ...        ...    ...\n",
       "806568  ffffde700333        0.5  177.0\n",
       "806569  ffffe6075b10        0.0  177.0\n",
       "806570  ffffea5adcdc        0.0  177.0\n",
       "806571  fffff1a0b9c7        0.5  177.0\n",
       "806572  fffff856246f        0.0  177.0\n",
       "\n",
       "[806573 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge cluster df and snr df\n",
    "df = pd.merge(df, sr_df, on=\"sequence_id\")\n",
    "df.drop(columns=[\"index\", \"length\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>is_Representative</th>\n",
       "      <th>identity_To_Rep</th>\n",
       "      <th>SN_filter</th>\n",
       "      <th>L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>d62116c4c8f0</td>\n",
       "      <td>False</td>\n",
       "      <td>83.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2e291021606c</td>\n",
       "      <td>False</td>\n",
       "      <td>82.31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9c4e99a4c2ba</td>\n",
       "      <td>False</td>\n",
       "      <td>89.23</td>\n",
       "      <td>0.5</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>cc2c6b77b4bf</td>\n",
       "      <td>False</td>\n",
       "      <td>83.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>f2eb45fbe514</td>\n",
       "      <td>False</td>\n",
       "      <td>86.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806568</th>\n",
       "      <td>317733</td>\n",
       "      <td>4eb60e538293</td>\n",
       "      <td>True</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806569</th>\n",
       "      <td>317734</td>\n",
       "      <td>21d1734994ca</td>\n",
       "      <td>True</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806570</th>\n",
       "      <td>317735</td>\n",
       "      <td>a8404fb3410c</td>\n",
       "      <td>True</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.9</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806571</th>\n",
       "      <td>317736</td>\n",
       "      <td>230e324ae8dc</td>\n",
       "      <td>True</td>\n",
       "      <td>100.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806572</th>\n",
       "      <td>317737</td>\n",
       "      <td>d65fe31114e0</td>\n",
       "      <td>True</td>\n",
       "      <td>100.00</td>\n",
       "      <td>0.9</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>806573 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cluster   sequence_id  is_Representative  identity_To_Rep  SN_filter  \\\n",
       "0             0  d62116c4c8f0              False            83.85        1.0   \n",
       "1             0  2e291021606c              False            82.31        1.0   \n",
       "2             0  9c4e99a4c2ba              False            89.23        0.5   \n",
       "3             0  cc2c6b77b4bf              False            83.85        0.0   \n",
       "4             0  f2eb45fbe514              False            86.92        0.0   \n",
       "...         ...           ...                ...              ...        ...   \n",
       "806568   317733  4eb60e538293               True           100.00        1.0   \n",
       "806569   317734  21d1734994ca               True           100.00        1.0   \n",
       "806570   317735  a8404fb3410c               True           100.00        0.9   \n",
       "806571   317736  230e324ae8dc               True           100.00        1.0   \n",
       "806572   317737  d65fe31114e0               True           100.00        0.9   \n",
       "\n",
       "            L  \n",
       "0       177.0  \n",
       "1       177.0  \n",
       "2       177.0  \n",
       "3       177.0  \n",
       "4       177.0  \n",
       "...       ...  \n",
       "806568  115.0  \n",
       "806569  115.0  \n",
       "806570  115.0  \n",
       "806571  115.0  \n",
       "806572  115.0  \n",
       "\n",
       "[806573 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_split(df):\n",
    "    splits = []\n",
    "    for _ in range(5):\n",
    "        # Getting unique clusters\n",
    "        unique_clusters = df['cluster'].unique()\n",
    "\n",
    "        # Splitting unique clusters into train and test\n",
    "        train_clusters, valid_clusters = train_test_split(unique_clusters, test_size=0.14, random_state=None)\n",
    "\n",
    "        # Splitting the original df based on train and test clusters\n",
    "        train_df = df[df['cluster'].isin(train_clusters)]\n",
    "        valid_df = df[df['cluster'].isin(valid_clusters)]\n",
    "\n",
    "        splits.append((train_df, valid_df))\n",
    "    return splits\n",
    "\n",
    "splits = generate_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___\n",
      "Train: (688989, 6), Valid: (117584, 6)\n",
      "Train L: [170. 177. 206. 155. 115.], Valid L: [177. 206. 170. 155. 115.]\n",
      "Train SNR: 206939, Valid SNR: 35632\n",
      "Train SNR and L: [170. 177. 206. 155. 115.], Valid SNR and L: [177. 206. 170. 155. 115.]\n",
      "___\n",
      "Train: (697349, 6), Valid: (109224, 6)\n",
      "Train L: [177. 206. 170. 155. 115.], Valid L: [170. 177. 206. 155. 115.]\n",
      "Train SNR: 208483, Valid SNR: 34088\n",
      "Train SNR and L: [177. 206. 170. 155. 115.], Valid SNR and L: [170. 177. 206. 155. 115.]\n",
      "___\n",
      "Train: (686176, 6), Valid: (120397, 6)\n",
      "Train L: [177. 206. 170. 155. 115.], Valid L: [170. 177. 206. 155. 115.]\n",
      "Train SNR: 206297, Valid SNR: 36274\n",
      "Train SNR and L: [177. 206. 170. 155. 115.], Valid SNR and L: [170. 177. 206. 155. 115.]\n",
      "___\n",
      "Train: (699889, 6), Valid: (106684, 6)\n",
      "Train L: [177. 206. 170. 155. 115.], Valid L: [177. 170. 155. 115.]\n",
      "Train SNR: 210973, Valid SNR: 31598\n",
      "Train SNR and L: [177. 206. 170. 155. 115.], Valid SNR and L: [177. 170. 155. 115.]\n",
      "___\n",
      "Train: (690096, 6), Valid: (116477, 6)\n",
      "Train L: [177. 206. 170. 155. 115.], Valid L: [177. 170. 155. 115.]\n",
      "Train SNR: 208203, Valid SNR: 34368\n",
      "Train SNR and L: [177. 206. 170. 155. 115.], Valid SNR and L: [177. 170. 155. 115.]\n"
     ]
    }
   ],
   "source": [
    "for split in splits:\n",
    "    t, v = split\n",
    "    print('___')\n",
    "    print(f\"Train: {t.shape}, Valid: {v.shape}\")\n",
    "    print(f\"Train L: {t['L'].unique()}, Valid L: {v['L'].unique()}\")\n",
    "    print(f\"Train SNR: {t.query('SN_filter>0.48').shape[0]}, Valid SNR: {v.query('SN_filter>0.48').shape[0]}\")\n",
    "    print(f\"Train SNR and L: {t.query('SN_filter>0.48')['L'].unique()}, Valid SNR and L: {v.query('SN_filter>0.48')['L'].unique()}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to read a fasta file into a DataFrame\n",
    "def read_fasta_to_df(fasta_file):\n",
    "    records = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        records.append({\"sequence_id\": record.id, \"sequence\": str(record.seq)})\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "# Function to write a DataFrame into a fasta file\n",
    "def write_to_fasta(df, fasta_file):\n",
    "    with open(fasta_file, 'w') as f:\n",
    "        for _, row in df.iterrows():\n",
    "            f.write(f\">{row['sequence_id']}\\n\")\n",
    "            f.write(f\"{row['sequence']}\\n\")\n",
    "\n",
    "full_fasta_df = read_fasta_to_df(\"train_seq.fasta\")\n",
    "train_df, valid_df = splits[0]\n",
    "train_df_merged = pd.merge(train_df, full_fasta_df, on=\"sequence_id\", how=\"left\")\n",
    "valid_df_merged = pd.merge(valid_df, full_fasta_df, on=\"sequence_id\", how=\"left\")\n",
    "write_to_fasta(train_df_merged, \"train_split_fold_0.fasta\")\n",
    "write_to_fasta(valid_df_merged, \"valid_split_fold_0.fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets run train and vlid sequnce comparison to find if we have idividual ids that are closer to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sudo cd-hit-est-2d -i train_split_fold_0.fasta -i2 valid_split_fold_0.fasta -c 0.85 -o similar_sequences_split -T 32 -M 32000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_split_clusters = read_clstr('similar_sequences_split.clstr')\n",
    "train_ids = read_fasta_ids('train_split_fold_0.fasta')\n",
    "valid_ids = read_fasta_ids('valid_split_fold_0.fasta')\n",
    "#lets add column source which will iclude if sequnce belong to train or to test\n",
    "df_split_clusters['source'] = df_split_clusters['sequence_id'].apply(lambda x: 'Train' if x in train_ids else ('Test' if x in valid_ids else 'Unknown'))\n",
    "filtered_df_split = df_split_clusters.groupby('cluster').filter(filter_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Test     27538\n",
       "Train    14007\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df_split[\"source\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it seems like we haver some sequences that are similar .. we will take the training ids and add them to valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ids = read_fasta_ids('train_split_fold_0.fasta')\n",
    "valid_ids = read_fasta_ids('valid_split_fold_0.fasta')\n",
    "valid_ids = list(valid_ids) + filtered_df_split.query(\"source=='Train'\")[\"sequence_id\"].to_list()\n",
    "train_ids = pd.DataFrame({\"sequence_id\":list(train_ids)}).set_index(\"sequence_id\")\n",
    "train_ids = train_ids.drop(filtered_df_split.query(\"source=='Train'\")[\"sequence_id\"].to_list()).reset_index()\n",
    "train_ids[\"is_train\"] = True\n",
    "valid_ids = pd.DataFrame({\"sequence_id\":valid_ids})\n",
    "valid_ids[\"is_train\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.concat([train_ids, valid_ids], ignore_index=True).to_csv(\"fold_split.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../data/train_data.parquet')\n",
    "df[\"L\"] = df[\"sequence\"].map(len)   \n",
    "split = pd.read_csv(\"fold_split.csv\")\n",
    "df = pd.merge(df, split, on='sequence_id')\n",
    "df_train = df.query('is_train==True').reset_index(drop=True)\n",
    "df_valid = df.query('is_train==False').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1375474, 421), (268206, 421))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177    99636\n",
       "155      142\n",
       "115      136\n",
       "170       79\n",
       "206       13\n",
       "Name: L, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.query('SN_filter<1').query(\"experiment_type=='2A3_MaP'\")[\"L\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177    254358\n",
       "170      5518\n",
       "115      4450\n",
       "155      2196\n",
       "206      1684\n",
       "Name: L, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid[\"L\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_train[\"sequence_id\"].to_list()).intersection(set(df_valid[\"sequence_id\"].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = set(pd.read_parquet('../data/train_data.parquet')['sequence_id'].unique())\n",
    "df_test = set(pd.read_csv('../data/test_sequences.csv')['sequence_id'].unique())\n",
    "combined = list(df_train.intersection(df_test))\n",
    "split = pd.read_csv('fold_split.csv')\n",
    "split.set_index('sequence_id', inplace=True)\n",
    "split.drop(combined, inplace=True)\n",
    "split.reset_index(inplace=True)\n",
    "split = pd.concat([split, pd.DataFrame({\"sequence_id\": combined, \"is_train\" : False})], ignore_index=True)\n",
    "split.to_csv(\"fold_split.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.797718\n",
       "False    0.202282\n",
       "Name: is_train, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split['is_train'].value_counts()/split.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
